{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "Python_Glue_Session",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "pygments_lexer": "python3",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# # read data from S3 to DataFrame\n",
    "# # input: S3\n",
    "# # output df['ROW_ID', 'BOS_FILE_EXTRACT', 'file_path', 'COLUMN_DEF']\n",
    "# def read_s3_to_df(day_path):\n",
    "#\n",
    "#     # parameter\n",
    "#     i = 0 # flag for initialize dataframe\n",
    "#\n",
    "#     # boto3 client\n",
    "#     s3 = boto3.client('s3')\n",
    "#     conn = client('s3')  # again assumes boto.cfg setup, assume AWS S3\n",
    "#\n",
    "#     # read data file by file\n",
    "#     for key in conn.list_objects(Bucket='bos-etl')['Contents']:\n",
    "#         path_key = key['Key']\n",
    "#         if path_key.endswith('cleansed'):\n",
    "#             if day_path in path_key:\n",
    "#                 file = s3.get_object(Bucket='bos-etl', Key=path_key)\n",
    "#                 txt = (file['Body'].read().decode('latin1'))\n",
    "#                 #st_re = txt.replace(\"\", \",\")\n",
    "#                 st_re_newline = txt.replace(\"!!! EOS !!!\", \"\\n\")\n",
    "#                 st_re_split = st_re_newline.split(\"\\n\")\n",
    "#                 df = pd.DataFrame(st_re_split)\n",
    "#                 df.index.name = 'ROW_ID'\n",
    "#                 df.rename({0:'BOS_FILE_EXTRACT'},axis='columns',inplace=True)\n",
    "#                 df[\"COLUMN_DEF\"]=df['BOS_FILE_EXTRACT'].replace(regex=r\"\\.*\",value=\"\")\n",
    "#                 # rslt_dfRFT_temp = df[df['COLUMN_DEF'] =='PAT'].head(10)\n",
    "#                 rslt_dfRFT_temp = df\n",
    "#                 if ~rslt_dfRFT_temp.empty:\n",
    "#                     # print(path_key)\n",
    "#                     rslt_dfRFT_temp.insert(0,'tax_on_commission', path_key)\n",
    "#                     if (i ==0):\n",
    "#                         rslt_dfRFT = rslt_dfRFT_temp\n",
    "#                         i = 1\n",
    "#                     else:\n",
    "#                         rslt_dfRFT = pd.concat([rslt_dfRFT,rslt_dfRFT_temp])\n",
    "#     return rslt_dfRFT\n",
    "#\n",
    "#\n",
    "# # read data as DataFrame\n",
    "# #select day\n",
    "# day_path = 'date=2023-06-17'\n",
    "# # select current system day\n",
    "# # day_path = time.strftime('%Y-%m-%d')\n",
    "# rslt_dfRFT = read_s3_to_df(day_path)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# len(rslt_dfRFT)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "text": "20\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# import sys\n",
    "# from awsglue.transforms import *\n",
    "# from awsglue.utils import getResolvedOptions\n",
    "# from pyspark.context import SparkContext\n",
    "# from awsglue.context import GlueContext\n",
    "# from awsglue.job import Job\n",
    "#\n",
    "# ## @params: [JOB_NAME]\n",
    "# args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "#\n",
    "# sc = SparkContext()\n",
    "# glueContext = GlueContext(sc)\n",
    "# spark = glueContext.spark_session\n",
    "# job = Job(glueContext)\n",
    "# job.init(args['JOB_NAME'], args)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "text": "GlueArgumentError: the following arguments are required: --JOB_NAME\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import csv\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.sql.functions import udf\n",
    "import re\n",
    "import time\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import length,col, explode, upper, to_date, date_sub, lag, coalesce, lit, array_sort, when, arrays_zip, size, date_format, explode_outer, from_json, concat, expr, array\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from operator import itemgetter\n",
    "import datetime, re, requests\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import concat, col, lit\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "from datetime import datetime\n",
    "# import boto3\n",
    "# from boto3 import client\n",
    "# from boto3.dynamodb.conditions import Key"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# read csv\n",
    "rslt_dfRFT = pd.read_csv(\"source/input/1_df_RFT_PAT_PAX.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# DataFrame to Dataframe\n",
    "from pyspark.sql import SparkSession\n",
    "#Create PySpark SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n",
    "#Create PySpark DataFrame from Pandas\n",
    "sparkDF=spark.createDataFrame(rslt_dfRFT)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/02 22:07:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Split Raw Data\n",
    "#  Start of repeat\n",
    "#  END REPEAT\n",
    "#  END of Data Set Indicator\n",
    "# <   Carrriage Return\n",
    "# DCI < SAL < TAX < ITI < FAR < FOP < END < CER < EXC < EXS <\n",
    "#     < REF <\n",
    "\n",
    "def split_raw_data(sparkDF):\n",
    "    split_df_type = sparkDF.withColumn(\"split\", F.split(\"BOS_FILE_EXTRACT\", \"\"))\\\n",
    "                 .withColumn(\"DCI_SAL\", F.element_at(\"split\", 1))\\\n",
    "                 .withColumn(\"split2\", F.split(\"DCI_SAL\", \"<\"))\\\n",
    "                 .withColumn(\"DCI\", F.element_at(\"split2\", 1))\\\n",
    "                 .withColumn(\"SAL\", F.element_at(\"split2\", 2))\\\n",
    "                 .withColumn(\"TAX\", F.element_at(\"split\", 2))\\\n",
    "                 .withColumn(\"ITI\", F.element_at(\"split\", 3))\\\n",
    "                 .withColumn(\"FAR\", F.element_at(\"split\", 4))\\\n",
    "                 .withColumn(\"FOP\", F.element_at(\"split\", 5))\\\n",
    "                 .withColumn(\"END\", F.element_at(\"split\", 6))\\\n",
    "                 .withColumn(\"CER\", F.element_at(\"split\", 7))\\\n",
    "                 .withColumn(\"EXC\", F.element_at(\"split\", 8))\\\n",
    "                 .withColumn(\"EXS\",  F.element_at(\"split\", 9))\\\n",
    "                 .withColumn(\"RFT\",  F.regexp_extract('BOS_FILE_EXTRACT', '<.+<',0))\n",
    "\n",
    "    split_df_type = split_df_type.select('COLUMN_DEF', \"DCI\", \"SAL\", \"TAX\", \"ITI\", \"FAR\", \"FOP\", \"END\", \"CER\", \"EXC\", \"EXS\", \"RFT\")\n",
    "\n",
    "    return split_df_type\n",
    "\n",
    "split_df_type = split_raw_data(sparkDF)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Common\n",
    "# etl main fc\n",
    "def etl_fc(df, fc, input, output):\n",
    "    # fc\n",
    "    fc = udf(fc, ArrayType(StringType()))\n",
    "\n",
    "    # input\n",
    "    fc_list = fc(*input)\n",
    "\n",
    "    # output\n",
    "    for i in range(len(output)):\n",
    "        df = df.withColumn(output[i], fc_list[i])\n",
    "\n",
    "    return df\n",
    "\n",
    "# data validation fc\n",
    "def dv_fc(rule_name, args_name, args, msg, paras=''):\n",
    "\n",
    "    try:\n",
    "        if args is not None:\n",
    "            #rules\n",
    "            if rule_name == 'check_len':\n",
    "                # ValueOutOfRange\n",
    "                if '.' in args:\n",
    "                    (args, msg) = (args, msg) if (len(str(args).split('.')[0]) <= (paras[0] - paras[1])) & (len(str(args).split('.')[1]) < paras[1]) else ('NULL', msg + ' # ' + args_name +'OutOfRange: ' + str(args) + ' out of (' + str(paras[0]) + ',' + str(paras[1])  + ') # ')\n",
    "                elif re.search(r'^[0-9]+$',args):\n",
    "                        (args, msg) = (args, msg) if (len(str(args).split('.')[0]) <= (paras[0] - paras[1])) else ('NULL', msg + ' # ' + args_name +'OutOfRange: ' + str(args) + ' out of (' + str(paras[0]) + ',' + str(paras[1])  + ') # ')\n",
    "                else:\n",
    "                    (args, msg) = (args, msg) if len(str(args).split('.')[0]) <= paras[0] else ('NULL', msg + ' # ' + args_name +'OutOfRange: ' + str(args) + ' out of ' + str(paras[0]) + ') # ')\n",
    "\n",
    "            if rule_name == 'check_match':\n",
    "                # Value1MismatchValue2\n",
    "                msg = msg if args[0] == args[1] else msg + ' # ' + args_name[0] +'MisMatch' + args_name[1] + ': (' + args_name[0] + ' , ' + args_name[1]  + ') : (' + str(args[0]) + ' , '  + str(args[1]) + ') # '\n",
    "\n",
    "            if rule_name == 'check_empty':\n",
    "                #ValueIsEmpty\n",
    "                msg = msg if args != '' else ' # ' + args_name + 'isEmpty'  + ' # '\n",
    "\n",
    "        else:\n",
    "            # ValueIsNull\n",
    "            msg = msg + ' # ' + args_name + 'IsNone' + ' # '\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # ValueExceptin\n",
    "        msg = msg + ' # ' + args_name + 'Exception: ' + str(e) + ' # '\n",
    "\n",
    "    return (args, msg)\n",
    "\n",
    "# coupons format\n",
    "def coupons_format(s):\n",
    "    coupons = 10000\n",
    "    coupons_dict = {\"1\": 1000, \"2\": 200, \"3\": 30, \"4\": 4}\n",
    "\n",
    "    for i in range(len(s)):\n",
    "        if s[i] in coupons_dict:\n",
    "            coupons = coupons + coupons_dict[s[i]]\n",
    "\n",
    "    return str(coupons)[1:]"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Custom\n",
    "# PAT/PAX/REF : [transaction_date, source, booking_channel, version_no, currency_code, ticket_type]\n",
    "\n",
    "def fc_custom(data):\n",
    "\n",
    "    # var\n",
    "    transaction_date = current_timestamp() # <<File Generated Date>>\n",
    "    source = 'BOS' # BOS\n",
    "    booking_channel = 'WEB' # WEB\n",
    "    version_no = 1\n",
    "    currency_code = 'USD' # always “USD”\n",
    "\n",
    "    ''' ticket_type :\n",
    "         line starts with PAT → ticket type = TKTT\n",
    "         line starts with PAX→ ticket type = EXCH-TKTT\n",
    "         line starts with RFT → ticket type = RFND\n",
    "         '''\n",
    "\n",
    "    # insert var\n",
    "    data = data.withColumn('transaction_date', transaction_date)\\\n",
    "               .withColumn('source', F.lit(source)) \\\n",
    "               .withColumn('booking_channel', F.lit(booking_channel))\\\n",
    "               .withColumn('version_no', F.lit(version_no))\\\n",
    "               .withColumn('ticket_type', when(col('column_def') == 'PAT', 'TKTT').\\\n",
    "                                          when(col('column_def') == 'PAX', 'EXCH-TKTT').\\\n",
    "                                          when(col('column_def') == 'RFT', 'RFND').\\\n",
    "                                          otherwise(''))\\\n",
    "               .withColumn('currency_code', F.lit(currency_code))\\\n",
    "               .withColumn('exception', F.lit(''))\n",
    "\n",
    "    return data\n",
    "\n",
    "bos_df_csv = fc_custom(split_df_type)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import json\n",
    "# sprint 3\n",
    "# DCI\n",
    "# PAT/PAX/REF\n",
    "input  = ['DCI', 'column_def']\n",
    "output = ['DCI_json']\n",
    "\n",
    "def fc_DCI(DCI, column_def):\n",
    "    # init\n",
    "    DCI_json = None\n",
    "\n",
    "    # DCI\n",
    "    if DCI is not None:\n",
    "        if column_def in ('PAT', 'PAT', 'RFT'):\n",
    "            # split\n",
    "            DCI_split = DCI.split(\"\")\n",
    "\n",
    "            # vars\n",
    "            VLNC = DCI_split[1] if len(DCI_split) >1 else None\n",
    "            BACN = DCI_split[4] if len(DCI_split) >4 else None\n",
    "            BDNR = DCI_split[5] if len(DCI_split) >5 else None\n",
    "            DAIS = DCI_split[7] if len(DCI_split) >7 else None\n",
    "\n",
    "            # json\n",
    "            DCI_json = json.dumps({\n",
    "                'VLNC' : VLNC,\n",
    "                'BACN' : BACN,\n",
    "                'BDNR' : BDNR,\n",
    "                'DAIS' : DAIS\n",
    "            })\n",
    "\n",
    "    return [DCI_json]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_DCI, input, output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(DCI_json='{\"VLNC\": \"22521623\", \"BACN\": \"125\", \"BDNR\": \"2161454822\", \"DAIS\": \"17JUN23\"}'),\n Row(DCI_json=None),\n Row(DCI_json='{\"VLNC\": \"22521623\", \"BACN\": \"074\", \"BDNR\": \"2100377105\", \"DAIS\": \"16JUN23\"}')]"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv.select('DCI_json').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# sprint3\n",
    "# SAL\n",
    "# PAT/PAX\n",
    "\n",
    "input  = ['column_def', 'SAL']\n",
    "output = ['SAL_json']\n",
    "\n",
    "def fc_SAL(column_def, SAL):\n",
    "    # init\n",
    "    SAL_json = None\n",
    "\n",
    "    # SAL\n",
    "    if SAL is not None:\n",
    "        if column_def in ('PAT', 'PAX'):\n",
    "            # split\n",
    "            SAL_split = SAL.split(\"\")\n",
    "\n",
    "            # vars\n",
    "            CPUI = SAL_split[6]\n",
    "            TDAM = SAL_split[7]\n",
    "            FARE = SAL_split[8]\n",
    "            CUOF = SAL_split[9]\n",
    "            EQFR = SAL_split[10]\n",
    "            TTAX = SAL_split[11]\n",
    "            COAM = SAL_split[12]\n",
    "            CORT = SAL_split[13]\n",
    "            PNRR = SAL_split[14]\n",
    "            PXNM = SAL_split[15]\n",
    "            TOUR = SAL_split[16]\n",
    "\n",
    "            # json\n",
    "            SAL_json = json.dumps({\n",
    "                'CPUI' : CPUI,\n",
    "                'TDAM' : TDAM,\n",
    "                'FARE' : FARE,\n",
    "                'CUOF' : CUOF,\n",
    "                'EQFR' : EQFR,\n",
    "                'TTAX' : TTAX,\n",
    "                'COAM' : COAM,\n",
    "                'CORT' : CORT,\n",
    "                'PNRR' : PNRR,\n",
    "                'PXNM' : PXNM,\n",
    "                'TOUR' : TOUR\n",
    "\n",
    "            })\n",
    "\n",
    "    return [SAL_json]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_SAL, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(SAL_json=None, SAL='\\x80\\x80\\x80\\x80\\x80953.65\\x800.00\\x800.00\\x80358.00\\x80595.65\\x800.00\\x800.00\\x800.00\\x800.00\\x80\\x80\\x80\\x81125\\x802161454822\\x801234\\x80'),\n Row(SAL_json='{\"CPUI\": \"FFVV\", \"TDAM\": \"203.20\", \"FARE\": \"166.51\", \"CUOF\": \"USD\", \"EQFR\": \"0.00\", \"TTAX\": \"36.69\", \"COAM\": \"1.00\", \"CORT\": \"0.60\", \"PNRR\": \"HNKNVK/AA\", \"PXNM\": \"REDACTED SAL NAME\", \"TOUR\": \"\"}', SAL='\\x80\\x80\\x80\\x80\\x80\\x80FFVV\\x80203.20\\x80166.51\\x80USD\\x800.00\\x8036.69\\x801.00\\x800.60\\x80HNKNVK/AA\\x80REDACTED SAL NAME\\x80\\x80\\x80\\x800011\\x80/\\x80\\x80Y\\x80\\x80\\x800\\x80\\x80\\x8000\\x80'),\n Row(SAL_json='{\"CPUI\": \"FFVV\", \"TDAM\": \"302.20\", \"FARE\": \"213.00\", \"CUOF\": \"USD\", \"EQFR\": \"0.00\", \"TTAX\": \"89.20\", \"COAM\": \"0.00\", \"CORT\": \"0.00\", \"PNRR\": \"UOAGUL\", \"PXNM\": \"REDACTED SAL NAME\", \"TOUR\": \"ITAFKL\"}', SAL='\\x80\\x80\\x80\\x80\\x80\\x80FFVV\\x80302.20\\x80213.00\\x80USD\\x800.00\\x8089.20\\x800.00\\x800.00\\x80UOAGUL\\x80REDACTED SAL NAME\\x80ITAFKL\\x80\\x800005WS\\x800744\\x80/\\x80\\x807\\x80\\x80\\x800\\x80X\\x80\\x8000\\x80')]"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv.select('SAL_json','SAL').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# sprint3\n",
    "# TAX\n",
    "# PAT/PAX\n",
    "\n",
    "input  = ['column_def', 'TAX']\n",
    "output = ['TAX_json']\n",
    "\n",
    "def fc_TAX(column_def, TAX):\n",
    "    # init\n",
    "    TAX_json = None\n",
    "\n",
    "    # TAX\n",
    "    if TAX is not None:\n",
    "        if column_def in ('PAT','PAX'):\n",
    "            # split\n",
    "            TAX_split = TAX.split('<')[0].replace('','').split('<')\n",
    "\n",
    "            # vars\n",
    "            # TAX_L1 : TMFA, TMFT\n",
    "            TAX_L1 = list()\n",
    "            for i in range(len(TAX_split)):\n",
    "                # split\n",
    "                element = TAX_split[i].split('')\n",
    "\n",
    "                # element\n",
    "                TMFA = element[0]\n",
    "                TMFT = element[1]\n",
    "\n",
    "                # dict\n",
    "                dict = {\n",
    "                    'TMFA' : TMFA,\n",
    "                    'TMFT' : TMFT\n",
    "                }\n",
    "\n",
    "                # append list\n",
    "                TAX_L1.append(dict)\n",
    "\n",
    "            # json\n",
    "            TAX_json = json.dumps({\n",
    "                'TAX_L1' : TAX_L1\n",
    "            })\n",
    "\n",
    "\n",
    "    return [TAX_json]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_TAX, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(TAX_json=None),\n Row(TAX_json='{\"TAX_L1\": [{\"TMFA\": \"12.49\", \"TMFT\": \"US\"}, {\"TMFA\": \"9.60\", \"TMFT\": \"ZP\"}, {\"TMFA\": \"5.60\", \"TMFT\": \"AY\"}, {\"TMFA\": \"9.00\", \"TMFT\": \"XF\"}]}'),\n Row(TAX_json='{\"TAX_L1\": [{\"TMFA\": \"2.20\", \"TMFT\": \"YR\"}, {\"TMFA\": \"16.00\", \"TMFT\": \"CJ\"}, {\"TMFA\": \"22.50\", \"TMFT\": \"RN\"}, {\"TMFA\": \"28.60\", \"TMFT\": \"VV\"}, {\"TMFA\": \"15.70\", \"TMFT\": \"JD\"}, {\"TMFA\": \"0.70\", \"TMFT\": \"OG\"}, {\"TMFA\": \"3.50\", \"TMFT\": \"QV\"}]}')]"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv.select('TAX_json').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# sprint3\n",
    "# ITI\n",
    "# PAT/PAX :\n",
    "\n",
    "input  = ['column_def', 'ITI']\n",
    "output = ['ITI_json']\n",
    "\n",
    "def fc_ITI(column_def, ITI):\n",
    "\n",
    "    # init\n",
    "    ITI_json = None\n",
    "\n",
    "    # ITI\n",
    "    if ITI is not None:\n",
    "        if column_def in ('PAT','PAX'):\n",
    "            # split\n",
    "            ITI_split = ITI.replace('','').replace('<','').split('<')\n",
    "\n",
    "            # vars\n",
    "            ITI_L = list()\n",
    "            for i in range(len(ITI_split)):\n",
    "\n",
    "                # legs_dict\n",
    "                dict = {\n",
    "                  'ITI_Group' : ITI_split[i]\n",
    "                }\n",
    "\n",
    "                # append list\n",
    "                ITI_L.append(dict)\n",
    "\n",
    "            # json\n",
    "            ITI_json = json.dumps({\n",
    "                'ITI_L' : ITI_L\n",
    "            })\n",
    "\n",
    "        return [ITI_json]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_ITI, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(currency_code='USD'), Row(currency_code='USD'), Row(currency_code='USD')]"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv.select('currency_code').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# sprint3\n",
    "# FAR\n",
    "# PAT/PAX\n",
    "\n",
    "input  = ['column_def', 'FAR']\n",
    "output = ['FAR_json']\n",
    "\n",
    "def fc_FAR(column_def, FAR):\n",
    "\n",
    "    # init\n",
    "    FAR_json = None\n",
    "\n",
    "    # FAR\n",
    "    if FAR is not None:\n",
    "        if column_def in ('PAT','PAX'):\n",
    "            # split\n",
    "            FAR_split =FAR.replace('','').replace('<','').split('<')\n",
    "\n",
    "            # vars\n",
    "            # FAR_L\n",
    "            FAR_L = []\n",
    "            for i in range(len(FAR_split)):\n",
    "                # split\n",
    "                element = FAR_split[i].split('')\n",
    "\n",
    "                # element\n",
    "                FRCA = element[0]\n",
    "\n",
    "                # dict\n",
    "                dict = {\n",
    "                    'FRCA' : FRCA\n",
    "                }\n",
    "\n",
    "                # append list\n",
    "                FAR_L.append(dict)\n",
    "\n",
    "            # json\n",
    "            FAR_json = json.dumps({\n",
    "                'FAR_L' : FAR_L\n",
    "            })\n",
    "\n",
    "    return [FAR_json]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_FAR, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(FAR_json=None),\n Row(FAR_json='{\"FAR_L\": [{\"FRCA\": \"ORF AA X/WAS AA GRS166.51USD166.51END ZPORFDCA XFORF4.5DCA4.5\"}]}'),\n Row(FAR_json='{\"FAR_L\": [{\"FRCA\": \"AMS KL MAD119.12KL AMS97.52NUC216.64END ROE0.907418XT22.50RN28.60VV15.70JD0.70OG3.50QV\"}]}')]"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv.select('FAR_json').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# sprint3\n",
    "# FOP\n",
    "# PAT/PAX\n",
    "\n",
    "input  = ['column_def', 'FOP']\n",
    "output = ['FOP_json']\n",
    "\n",
    "def fc_FOP(column_def, FOP):\n",
    "\n",
    "    # init\n",
    "    FOP_json = None\n",
    "\n",
    "    # FOP\n",
    "    if FOP is not None:\n",
    "        if column_def in ('PAT','PAX'):\n",
    "            # split\n",
    "            FOP_split = FOP.replace('','').replace('<','').split('<')\n",
    "\n",
    "            # vars\n",
    "            FOP_L = []\n",
    "            for i in range(len(FOP_split)):\n",
    "                # split\n",
    "                FOP_element = FOP_split[i].split(\"\")\n",
    "\n",
    "                # element\n",
    "                FPTP = FOP_element[0]\n",
    "                FPAC = FOP_element[1]\n",
    "                APLC = FOP_element[4]\n",
    "                FPAM = FOP_element[5]\n",
    "\n",
    "                # dict\n",
    "                dict = {\n",
    "                    'FPTP' : FPTP,\n",
    "                    'FPAC' : FPAC,\n",
    "                    'APLC' : APLC,\n",
    "                    'FPAM' : FPAM\n",
    "                }\n",
    "\n",
    "                # append list\n",
    "                FOP_L.append(dict)\n",
    "\n",
    "            # json\n",
    "            FOP_json = json.dumps({\n",
    "                'FOP_L' : FOP_L\n",
    "            })\n",
    "\n",
    "    return [FOP_json]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_FOP, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(FOP_json=None),\n Row(FOP_json='{\"FOP_L\": [{\"FPTP\": \"CA\", \"FPAC\": \"CASH\", \"APLC\": \"\", \"FPAM\": \"203.20\"}, {\"FPTP\": \"CA\", \"FPAC\": \"CASH\", \"APLC\": \"\", \"FPAM\": \"25.00\"}]}'),\n Row(FOP_json='{\"FOP_L\": [{\"FPTP\": \"CA\", \"FPAC\": \"CASH\", \"APLC\": \"\", \"FPAM\": \"302.20\"}]}')]"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv.select('FOP_json').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# sprint3\n",
    "# RFT\n",
    "\n",
    "input  = ['column_def', 'RFT']\n",
    "output = ['RFT_json']\n",
    "\n",
    "def fc_RFT(column_def, RFT):\n",
    "\n",
    "    # init\n",
    "    RFT_json = None\n",
    "\n",
    "     # RFT\n",
    "    if column_def == 'RFT':\n",
    "        if RFT is not None:\n",
    "            # split\n",
    "            RFT_split = RFT.split('<')\n",
    "            RFT_split_1 = re.search('.+<',RFT).group().replace('','').replace('<','').split('<') # loop RACN + RDNR + RCPN\n",
    "            RFT_split_2 = RFT_split[1] # ODOI\n",
    "            RFT1_element = RFT_split_2.split(\"\")\n",
    "\n",
    "            # vars\n",
    "            ODOI = RFT1_element.split(\"\")[0]\n",
    "            FPTP = RFT1_element[10]\n",
    "            FPAC = RFT1_element[11]\n",
    "\n",
    "            # RFT_L\n",
    "            RFT_L1 = []\n",
    "            # element\n",
    "            for i in range(len(RFT_split_1)):\n",
    "                element = RFT_split_1[i].split(\"\")\n",
    "\n",
    "                # element\n",
    "                RACN = element[0]\n",
    "                RDNR = element[1]\n",
    "                RCPN = element[2]\n",
    "\n",
    "                # dict\n",
    "                dict = {\n",
    "                    'RACN' : RACN,\n",
    "                    'RDNR' : RDNR,\n",
    "                    'RCPN' : RCPN\n",
    "                }\n",
    "\n",
    "                # append list\n",
    "                RFT_L1.append(dict)\n",
    "\n",
    "\n",
    "            # json\n",
    "            RFT_json = json.dumps({\n",
    "                'ODOI' : ODOI,\n",
    "                'FPTP' : FPTP,\n",
    "                'FPAC' : FPAC,\n",
    "                'RFT_L' : RFT_L1\n",
    "            })\n",
    "\n",
    "    return [RFT_json]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_RFT, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# sprint3\n",
    "# EXC\n",
    "\n",
    "input  = ['column_def', 'EXC']\n",
    "output = ['EXC_json']\n",
    "\n",
    "def fc_EXC(column_def, EXC):\n",
    "\n",
    "    # init\n",
    "    EXC_json = None\n",
    "\n",
    "    # EXC\n",
    "    if EXC is not None:\n",
    "        if column_def == 'PAX':\n",
    "            # split\n",
    "            EXC_split = EXC.split('<')\n",
    "            EXC2_split = EXC_split[1].replace('','').split('<')# loop of RACN + RDNR\n",
    "            EXC2_element = EXC2_split[0].split(\"\")\n",
    "\n",
    "            # vars\n",
    "            RACN = EXC2_element[0]\n",
    "            RDNR = EXC2_element[1]\n",
    "\n",
    "            # json\n",
    "            EXC_json = json.dumps({\n",
    "                'RACN' : RACN,\n",
    "                'RDNR' : RDNR\n",
    "            })\n",
    "\n",
    "    return [EXC_json]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_EXC, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# BRE\n",
    "input  = ['column_def', 'exception', 'DCI_json', 'SAL_json', 'TAX_json' , 'FAR_json', 'ITI_json', 'currency_code']\n",
    "output = ['exception', 'agency_code', 'ticket_number', 'issue_date', 'pnr', 'tour_code', 'passenger_name', 'coupon_used', 'original_fare', 'fare_amount', 'exchange_rate', 'commission_amount', 'original_currency', 'tax_amount', 'total_amount', 'commission', 'tax', 'legs']\n",
    "\n",
    "def fc_BRE(column_def, exception, DCI_json, SAL_json, TAX_json, FAR_json, ITI_json, currency_code):\n",
    "    # init\n",
    "    agency_code, ticket_number, issue_date, pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission, tax, legs = None, None, None, None, None, None, None, None, None,None, None, None,None, None, None, None, None\n",
    "\n",
    "    # vars\n",
    "    # PAT / PAX / RFT\n",
    "    if column_def in ('PAT', 'PAX', 'RFT'):\n",
    "        # DCI\n",
    "        if DCI_json is not None:\n",
    "            # load json\n",
    "            DCI_json = json.loads(DCI_json)\n",
    "            # agency_code : 2nd field from 1st group (VLNC-DCI)\n",
    "            agency_code = DCI_json['VLNC']\n",
    "            # ticket_number : 5th field + 6th field from 1st group (BACN-DCI+ BDNR-DCI)\n",
    "            ticket_number = DCI_json['BACN'] + DCI_json['BDNR']\n",
    "            # issue_date : 8th field from 1st group (DAIS-DCI). Field is reported as YYMMDD\n",
    "            issue_date = datetime.strptime(DCI_json['DAIS'],'%d%b%y').strftime(\"%Y-%m-%d\")\n",
    "    # PAT / PAX\n",
    "    if column_def in ('PAT', 'PAX'):\n",
    "        # SAL\n",
    "        if SAL_json is not None:\n",
    "            # load json\n",
    "            SAL_json = json.loads(SAL_json)\n",
    "            # pnr : 15th field from 2nd group (PNRR-SAL)\n",
    "            pnr = SAL_json['PNRR']\n",
    "            # tour_code : # 17th field from 2nd group (TOUR-SAL)\n",
    "            tour_code = SAL_json['TOUR']\n",
    "            # passenger_name : 16th field from 2nd group (PXNM-SAL)\n",
    "            passenger_name = SAL_json['PXNM']\n",
    "            # coupon_used : 7th field from 2nd group (CPUI-SAL)\n",
    "            coupon_used = SAL_json['CPUI']\n",
    "            # original_fare : 9th field from 2nd group(-SAL)\n",
    "            original_fare = SAL_json['FARE']\n",
    "            # original_currency : 10th field from 2nd group (CUOF-SAL)\n",
    "            original_currency = SAL_json['CUOF']\n",
    "            # tax_amount : 12th field from 2nd group (TTAX-SAL)\n",
    "            tax_amount = SAL_json['TTAX']\n",
    "            # total_amount : 8th field from 2nd group (TDAM-SAL)\n",
    "            total_amount = SAL_json['TDAM']\n",
    "            # fare_amount : 11th field from 2nd group (EQFR-SAL)… Note: if is 0.00, use the same as ORIGINAL_FARE\n",
    "            fare_amount = SAL_json['EQFR'] if float(SAL_json['EQFR']) != 0 else original_fare\n",
    "            # exchange_rate : FARE_AMOUNT / ORIGINAL_FARE\n",
    "            exchange_rate = round(float(fare_amount) / float(original_fare),3) if float(original_fare) != 0 else None\n",
    "            # commission_amount : same as FARE_AMOUNT\n",
    "            commission_amount = fare_amount\n",
    "\n",
    "            # commission\n",
    "            ''' COMMISSION:\n",
    "                #JSON. Example: [{\"type\":\"BASE\",\"amount\":4.26,\"currency\":\"CAD\",\"commissionRate\":3.0}]\n",
    "                       amount: 13th field from 2nd group (COAM-SAL)\n",
    "                       commissionRate: 14th field from 2nd group (CORT-SAL)'''\n",
    "            amount = SAL_json['COAM']\n",
    "            commissionRate = SAL_json['CORT']\n",
    "            type1 = 'BASE'\n",
    "            currency = currency_code\n",
    "\n",
    "            commission = '[{' + f'\"type\":\"{type1}\",\"amount\":{amount},\"currency\":\"{currency}\",\"commissionRate\":{commissionRate}' + '}]'\n",
    "\n",
    "        # TAX\n",
    "        if TAX_json is not None:\n",
    "            # load json\n",
    "            TAX_json = json.loads(TAX_json)\n",
    "            ''' TAX:\n",
    "            Field will be <null> if is RFND\n",
    "            Note: this group may have a loop\n",
    "            JSON. Example: [{\"type\":\"CA\",\"amount\":7.12,\"currency\":\"CAD\"},{\"type\":\"YR\",\"amount\":16.00,\"currency\":\"CAD\"}]\n",
    "            type: 2nd field of the loop from 3rd group (TMFT-TAX)\n",
    "            amount: 1st field of the loop from 3rd group (TMFA-TAX)\n",
    "            currency: 10th field from 2nd group (CUOF-SAL)'''\n",
    "            # tax\n",
    "            tax = ''\n",
    "            TAX_L1 = TAX_json['TAX_L1']\n",
    "            for i in range(len(TAX_L1)):\n",
    "                # element\n",
    "                type1 = TAX_L1[i]['TMFT']\n",
    "                amount = TAX_L1[i]['TMFA']\n",
    "                currency = original_currency\n",
    "\n",
    "                # tax\n",
    "                s = ',' if i != 0 else '['\n",
    "                tax = tax + s + '{' + f'\"type\":\"{type1}\",\"amount\":{amount},\"currency\":\"{currency}\"' + '}'\n",
    "\n",
    "            tax = tax + ']'\n",
    "\n",
    "        # FAR\n",
    "        if FAR_json is not None:\n",
    "            # load json\n",
    "            FAR_json = json.loads(FAR_json)\n",
    "            # fare\n",
    "            FAR_L = FAR_json['FAR_L']\n",
    "            FRCA = FAR_L[0]['FRCA']\n",
    "            # split\n",
    "            FAR_split = re.findall(r'[A-PR-Z][\\d\\.]+', FRCA.split(\"END\")[0]) # filter startswith 'Q'\n",
    "            # fare_legs, fare_total\n",
    "            if len(FAR_split) > 0:\n",
    "                FAR_split = [x[1:] for x in FAR_split ] # filter start alpha\n",
    "            if (len(FAR_split) > 1):\n",
    "                # if two more than two ticket legs, direction from right -> left\n",
    "                FAR_split.reverse()\n",
    "                # toal_far\n",
    "                fare_total = FAR_split[0]\n",
    "                # leg far\n",
    "                fare_legs = FAR_split[1:]\n",
    "            elif (len(FAR_split) == 1):\n",
    "                fare_total = FAR_split[0]\n",
    "                fare_legs = 0\n",
    "            else:\n",
    "                fare_total = 0\n",
    "                fare_legs = 0\n",
    "\n",
    "        # ITI\n",
    "        if ITI_json is not None:\n",
    "            legs = ''\n",
    "            # load json\n",
    "            ITI_json = json.loads(ITI_json)\n",
    "            # legs\n",
    "            '''LEGS:\n",
    "            NOTE: If the ticket type is RFND, LEGS field needs to be empty\n",
    "            Note: this info is provided in the ITI group. Each ticket may have 4 legs max. After the 5th leg, the ticket is considered as conjunction. In the file, if there is a loop, the ticket has a conjunction ticket.Example: 1st leg, 2nd leg, 3rd leg, 4th leg + loop + 5th leg…If the leg is empty, it means that the ticket stopped in the previous leg. Don’t load empty values in the Json.\n",
    "            JSON. example: [{\"departure\":\"FLR\",\"destination\":\"YYZ\",\"seatClass\":\"C\",\"conjunction\":\"1111234567890\",\"carrier\":\"AC\",\"tripCode\":\"876\",\"departureOn\":\"2022-12-30\",\"designator\":\"\",\"stopOver\":\"X\",\"flyerCode\":\"\",\"fare\":259.25,\"currency\": \"CAD\",\"originalFare\":259.25,\"originalCurrency\":\"CAD\"}]\n",
    "            departure: from 4th group (ORAC-ITI) → Leg 1: 4th field | Leg 2: 13th field | Leg 3: 22nd field | Leg 4: 31st field\n",
    "            destination: from 4th group (DSTC-ITI) → Leg 1: 5th field | Leg 2: 14th field | Leg 3: 23rd field | Leg 4: 32nd field\n",
    "            seatClass: 4th group (CLSC-ITI) → Leg 1: 8th field | Leg 2: 17th field | Leg 3: 26th field | Leg 4: 35th field\n",
    "            conjunction: 1st field from 4th group (CJNR-ITI). If is empty, use the same as TICKET_NUMBER\n",
    "\n",
    "            if the ticket includes more than 4 legs: in ITI section, the 39th field (the field after 4th repeat’s designator) will give a new BDNR (10 digits), use the BACN from DCI + new BDNR as conjunction for the following legs\n",
    "            carrier: from 4th group (CARR-ITI) → Leg 1: 6th field | Leg 2: 15th field | Leg 3: 24th field | Leg 4: 33rd field\n",
    "            tripCode: 4th group (FTNR-ITI) → Leg 1: 7th field | Leg 2: 16th field | Leg 3: 25th field | Leg 4: 34th field\n",
    "            departured on: 4th group (FTDA-ITI) → Leg 1: 9th field | Leg 2: 18th field | Leg 3: 27th field | Leg 4: 36th field. NOTE: you need to store this format in the databse: YYYY-MM-DD but the file has JAN01 for example. Use the same procedure/logic from CAT file loader in order to convert into date\n",
    "\n",
    "            Check the logic from CAT (Java code) with Haibinhg and Santhosh because there are some tricks in the code but the logic is:\n",
    "            File will come as JUL01 (they don’t report the year) → convert into 2023-07-01\n",
    "            If the departure date is before the issue date, the year will be ISSUE_DATE +1 year. Example: issue date is 2023-07-01 and departure date is JUN01, then the departure date will be 2024-06-01\n",
    "            If the departure date is after or equals to the issue date, the year will be the same as Issue Date. Example: issue date is 2023-07-01 and departure date is DEC01, then the departure date will be 2023-12-01\n",
    "            If the departure date is after the issue date (but after december 31st), the year will be the same as Issue Date + 1 year. Example: issue date is 2023-07-01 and departure date is JAN01, then the departure date will be 2024-01-01\n",
    "            designator: 4th group (FBTD-ITI) → Leg 1: 11th field | Leg 2: 20th field | Leg 3: 29th field | Leg 4: 38th field\n",
    "            stopOver: from 4th group (STPO-ITI) → Leg 1: 3rd field | Leg 2: 12th field | Leg 3: 21st field | Leg 4: 30th field\n",
    "            flyerCode: <empty>\n",
    "            fare: you need to check the fare construction group and then apply the same logic as CAT loader (use the same rules applied on these stories: FTS-1518, FTS-1188 item 2, FTS-1188 and FTS-1502)\n",
    "            currency: same as CURRENCY_CODE\n",
    "            originalFare: you need to check the fare construction group and then apply the same logic as CAT loader (use the same rules applied on these stories: FTS-1518 and FTS-1188 item 2)\n",
    "            originalCurrency: same as ORIGINAL_CURRENCY'''\n",
    "            ITI_L = ITI_json['ITI_L']\n",
    "            print(column_def)\n",
    "            print('ITI_L')\n",
    "            print(ITI_L)\n",
    "            for i in range(len(ITI_L)):\n",
    "                element = ITI_L[i]['ITI_Group'].split('')\n",
    "\n",
    "                # segment\n",
    "                j = 30 # index for element\n",
    "                k = 0 # index for fare_legs segment\n",
    "                if (ticket_number is not None):\n",
    "                    conjunction = ticket_number if len(element[0]) == 0 else (ticket_number[0:3] + element[0])\n",
    "                    currency = 'USD'\n",
    "                    originalCurrency = original_currency\n",
    "                    while (j > 0):\n",
    "                        if len(element[j]) != 0:\n",
    "                            # element\n",
    "                            departure = element[j]\n",
    "                            destination = element[j+1]\n",
    "                            seatClass = element[j+4]\n",
    "                            carrier = element[j+2]\n",
    "                            tripCode = element[j+3]\n",
    "                            designator = element[j+7]\n",
    "                            stopOver = element[j-1]\n",
    "                            flyerCode = ''\n",
    "\n",
    "                            # fare\n",
    "                            # far if 'X' != 0, take one from fare_leg\n",
    "                            if (stopOver == 'X'):\n",
    "                                fare = str('0.00')\n",
    "                            else:\n",
    "                                if (fare_legs == 0):\n",
    "                                    fare = 'NULL'\n",
    "                                elif (k < len(fare_legs)):\n",
    "                                    fare = fare_legs[k]\n",
    "                                    k = k + 1\n",
    "                                else:\n",
    "                                    fare = 'NULL'\n",
    "\n",
    "                            originalFare = fare\n",
    "\n",
    "                            # departureOn\n",
    "                            # dep_on_date(issue_year-mm-dd)if dep_on_date(mm-dd) > issue_data(mm-dd) else   dep_on_date((issue_year+1)-mm-dd))\n",
    "                            dep_on_date = element[j+5]\n",
    "                            if len(dep_on_date) != 0:\n",
    "                                if re.match(r'^\\d{4}-\\d{2}-\\d{2}$',str(issue_date)):\n",
    "                                    issue_year = issue_date[0:4]\n",
    "                                    dep_day = datetime.strptime(dep_on_date + '2024','%d%b%Y').strftime(\"%m-%d\") # 2024 is leap year to avoid   '02-28', just for transformation, not use it afterward\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(issue_year)+ 1)\n",
    "                                    departureOn = str(pd.datetime.strptime(dep_on_date + dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    departureOn = ''\n",
    "                            else:\n",
    "                                departureOn = ''\n",
    "\n",
    "                            # legs\n",
    "                            s = '[' if ((i == len(ITI_L) - 1) and (j == 3)) else ','\n",
    "                            legs = s + '{' + f'\"departure\":\"{departure}\",\"destination\":\"{destination}\",\"seatClass\":\"{seatClass}\",\"conjunction\":\"{conjunction}\",\"carrier\":\"{carrier}\",\"tripCode\":\"{tripCode}\",\"departureOn\":\"{departureOn}\",\"designator\":    \"{designator}\",\"stopOver\":\"{stopOver}\",\"flyerCode\":\"{flyerCode}\",\"fare\":{fare},\"currency\":\"{currency}\",\"originalFare\":{originalFare},\"originalCurrency\":\"{originalCurrency}\"' + '}' + legs\n",
    "\n",
    "                        j = j - 9\n",
    "\n",
    "            legs = legs + ']'\n",
    "\n",
    "\n",
    "    return [exception, agency_code, ticket_number, issue_date, pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission, tax, legs]\n",
    "\n",
    "bos_df_csv2 = etl_fc(bos_df_csv, fc_BRE, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ITI_Le 36:>                                                         (0 + 1) / 1]\n",
      "[{'ITI_Group': '\\x80\\x80X\\x80ORF\\x80DCA\\x80AA\\x805508\\x80S\\x8008JUL\\x80323P\\x80SUAIZNN1\\x80\\x80DCA\\x80GRR\\x80AA\\x805091\\x80S\\x8008JUL\\x80530P\\x80SUAIZNN1\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80'}]\n",
      "ITI_L\n",
      "[{'ITI_Group': '\\x80\\x80O\\x80AMS\\x80MAD\\x80KL\\x801701\\x80Q\\x8024JUN\\x800930\\x80QH5UA5LG/XX\\x80O\\x80MAD\\x80AMS\\x80KL\\x801702\\x80E\\x8027JUN\\x801305\\x80EH5UA5LG\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80'}]\n",
      "/var/folders/d9/871p0v1d2cn4c6y7bj_xghhh0000gn/T/ipykernel_2690/1591397334.py:195: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "ITI_L\n",
      "[{'ITI_Group': '\\x80\\x80X\\x80ORF\\x80DCA\\x80AA\\x805508\\x80S\\x8008JUL\\x80323P\\x80SUAIZNN1\\x80\\x80DCA\\x80GRR\\x80AA\\x805091\\x80S\\x8008JUL\\x80530P\\x80SUAIZNN1\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80'}]\n",
      "ITI_L\n",
      "[{'ITI_Group': '\\x80\\x80O\\x80AMS\\x80MAD\\x80KL\\x801701\\x80Q\\x8024JUN\\x800930\\x80QH5UA5LG/XX\\x80O\\x80MAD\\x80AMS\\x80KL\\x801702\\x80E\\x8027JUN\\x801305\\x80EH5UA5LG\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80'}]\n",
      "/var/folders/d9/871p0v1d2cn4c6y7bj_xghhh0000gn/T/ipykernel_2690/1591397334.py:195: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(column_def='RFT', legs=None),\n Row(column_def='PAX', legs=']'),\n Row(column_def='PAT', legs='[{\"departure\":\"AMS\",\"destination\":\"MAD\",\"seatClass\":\"Q\",\"conjunction\":\"0742100377105\",\"carrier\":\"KL\",\"tripCode\":\"1701\",\"departureOn\":\"2023-06-24\",\"designator\":    \"QH5UA5LG/XX\",\"stopOver\":\"O\",\"flyerCode\":\"\",\"fare\":119.12,\"currency\":\"USD\",\"originalFare\":119.12,\"originalCurrency\":\"USD\"},{\"departure\":\"MAD\",\"destination\":\"AMS\",\"seatClass\":\"E\",\"conjunction\":\"0742100377105\",\"carrier\":\"KL\",\"tripCode\":\"1702\",\"departureOn\":\"2023-06-27\",\"designator\":    \"EH5UA5LG\",\"stopOver\":\"O\",\"flyerCode\":\"\",\"fare\":97.52,\"currency\":\"USD\",\"originalFare\":97.52,\"originalCurrency\":\"USD\"}]')]"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv2.select('column_def','legs').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# DCI\n",
    "# PAT/PAX/REF : ['agency_code', 'ticket_number', 'issue_date']\n",
    "input  = ['DCI', 'attributes']\n",
    "output = ['agency_code', 'ticket_number', 'issue_date', 'attributes']\n",
    "\n",
    "def fc_DCI(DCI, attributes):\n",
    "    # init\n",
    "    agency_code, ticket_number, issue_date = None, None, None\n",
    "\n",
    "    # DCI\n",
    "    if DCI is not None:\n",
    "        # split\n",
    "        DCI_split = DCI.split(\"\")\n",
    "\n",
    "        # var\n",
    "        agency_code, attributes = DCI_split[1] if len(DCI_split) >1 else None, attributes# 2nd field from 1st group (VLNC-DCI)\n",
    "        ticket_number, attributes = DCI_split[4] + DCI_split[5] if len(DCI_split) >5 else None, attributes # 5th field + 6th field from 1st group (BACN-DCI+ BDNR-DCI)\n",
    "        issue_date, attributes = datetime.strptime(DCI_split[7],'%d%b%y').strftime(\"%Y-%m-%d\") if len(DCI_split) >7 else None, attributes  # 8th field from 1st group (DAIS-DCI). Field is reported as YYMMDD\n",
    "        # agency_code, attributes = dv_fc('check_empty', 'agent_code', DCI_split[1], attributes) if len(DCI_split) >1 else None, attributes# 2nd field from 1st group (VLNC-DCI)\n",
    "        # ticket_number, attributes = dv_fc('check_empty', 'ticket_number', DCI_split[4] + DCI_split[5], attributes) if len(DCI_split) >5 else None, attributes # 5th field + 6th field from 1st group (BACN-DCI+ BDNR-DCI)\n",
    "        # issue_date = dv_fc('check_empty', 'issue_date', datetime.strptime(DCI_split[7],'%d%b%y').strftime(\"%Y-%m-%d\"),attributes) if len(DCI_split) >7 else None, attributes  # 8th field from 1st group (DAIS-DCI). Field is reported as YYMMDD\n",
    "\n",
    "\n",
    "    return [agency_code, ticket_number, issue_date, attributes]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_DCI, input, output)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# SAL\n",
    "# PAT/PAX : ['pnr', 'tour_code', 'passenger_name', 'coupon_used', 'original_fare', 'fare_amount', 'exchange_rate', 'commission_amount', 'original_currency', 'tax_amount', 'total_amount', 'commission','RFT']\n",
    "\n",
    "input  = ['column_def', 'SAL', 'RFT']\n",
    "output = ['pnr', 'tour_code', 'passenger_name', 'coupon_used', 'original_fare', 'fare_amount', 'exchange_rate', 'commission_amount', 'original_currency', 'tax_amount', 'total_amount', 'commission']\n",
    "\n",
    "def fc_SAL(column_def, SAL, RFT):\n",
    "    # init\n",
    "    pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission = None, None, None, None, None, None, None, None, None, None, None, None\n",
    "\n",
    "    # SAL\n",
    "    if SAL is not None:\n",
    "        if column_def == 'PAT' or column_def == 'PAX':\n",
    "            # split\n",
    "            SAL_split = SAL.split(\"\")\n",
    "\n",
    "            # var\n",
    "            pnr = SAL_split[14]  # 15th field from 2nd group (PNRR-SAL). Note: it will be empty for RFND.\n",
    "            tour_code = SAL_split[16] # 17th field from 2nd group (TOUR-SAL). Note: it will be empty for RFND.\n",
    "            passenger_name = SAL_split[15]  # 16th field from 2nd group (PXNM-SAL) for non-RFND.\n",
    "            coupon_used = coupons_format(SAL_split[15])  # 7th field from 2nd group (CPUI-SAL) for non-RFND\n",
    "            original_fare = SAL_split[8]  # 9th field from 2nd group\n",
    "            original_currency = SAL_split[9] # 10th field from 2nd group (CUOF-SAL)\n",
    "            tax_amount = SAL_split[11]  # 12th field from 2nd group (TTAX-SAL)\n",
    "            total_amount = SAL_split[7]  # 8th field from 2nd group (TDAM-SAL)\n",
    "            fare_amount = SAL_split[10] if SAL_split[10] != '0.00' else original_fare # 11th field from 2nd group (EQFR-SAL)… Note: if is 0.00, use the same as ORIGINAL_FARE\n",
    "            exchange_rate = round(float(fare_amount) / float(original_fare),3) if original_fare != '0.00' else None # FARE_AMOUNT / ORIGINAL_FARE\n",
    "            commission_amount = fare_amount # same as FARE_AMOUNT\n",
    "\n",
    "            ''' COMMISSION:\n",
    "            #JSON. Example: [{\"type\":\"BASE\",\"amount\":4.26,\"currency\":\"CAD\",\"commissionRate\":3.0}]\n",
    "                       amount: 13th field from 2nd group (COAM-SAL)\n",
    "                       commissionRate: 14th field from 2nd group (CORT-SAL)'''\n",
    "            amount = SAL_split[12]\n",
    "            commissionRate = SAL_split[13]\n",
    "            type1 = 'BASE'\n",
    "            currency = 'USD'\n",
    "\n",
    "            commission = '[{' + f'\"type\":\"{type1}\",\"amount\":{amount},\"currency\":\"{currency}\",\"commissionRate\":{commissionRate}' + '}]'\n",
    "\n",
    "    # RFT\n",
    "    if RFT is not None:\n",
    "        if column_def == 'RFT':\n",
    "            # split\n",
    "            RFT_split = RFT.split('<')\n",
    "            RFT1_split = RFT_split[0].replace('<', '') # RCAM RCRT\n",
    "            RFT1_element = RFT1_split.split('')\n",
    "\n",
    "            '''commission:\n",
    "            JSON. Example: [{\"type\":\"BASE\",\"amount\": -4.26,\"currency\":\"USD\",\"commissionRate\":3.0}]\n",
    "            type: BASE\n",
    "            amount: 11th field from REF * (-1) because commission is being refunded\n",
    "            commissionrate: 12th field from REF\n",
    "            currency: USD'''\n",
    "\n",
    "            # var\n",
    "            type1 = 'BASE'\n",
    "            amount = str(float(RFT1_element[10]) * -1) if float(RFT1_element[10]) != 0.00 else '0.00'\n",
    "            commissionRate = RFT1_element[11]\n",
    "            currency = 'USD'\n",
    "\n",
    "            commission = '[{' + f'\"type\":\"{type1}\",\"amount\":{amount},\"currency\":\"{currency}\",\"commissionRate\":{commissionRate}' + '}]'\n",
    "\n",
    "\n",
    "    return [pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_SAL, input, output)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# TAX\n",
    "# PAT/PAX : ['tax']\n",
    "\n",
    "input  = ['column_def', 'TAX', 'original_currency']\n",
    "output = ['tax']\n",
    "\n",
    "def fc_TAX(column_def, TAX, original_currency):\n",
    "    # init\n",
    "    tax = None\n",
    "\n",
    "    # TAX\n",
    "    if TAX is not None:\n",
    "        if column_def == 'PAT' or column_def == 'PAX':\n",
    "            # split\n",
    "            TAX_split = TAX.split('<')[0].replace('','').split('<')\n",
    "\n",
    "            # var\n",
    "            ''' TAX:\n",
    "            Field will be <null> if is RFND\n",
    "            Note: this group may have a loop\n",
    "            JSON. Example: [{\"type\":\"CA\",\"amount\":7.12,\"currency\":\"CAD\"},{\"type\":\"YR\",\"amount\":16.00,\"currency\":\"CAD\"}]\n",
    "            type: 2nd field of the loop from 3rd group (TMFT-TAX)\n",
    "            amount: 1st field of the loop from 3rd group (TMFA-TAX)\n",
    "            currency: 10th field from 2nd group (CUOF-SAL)'''\n",
    "            tax = ''\n",
    "            for i in range(len(TAX_split)):\n",
    "                # split\n",
    "                element = TAX_split[i].split('')\n",
    "\n",
    "                # element\n",
    "                type1 = element[1]\n",
    "                amount = element[0]\n",
    "                currency = original_currency\n",
    "\n",
    "                # tax\n",
    "                s = ',' if i != 0 else '['\n",
    "                tax = tax + s + '{' + f'\"type\":\"{type1}\",\"amount\":{amount},\"currency\":\"{currency}\"' + '}'\n",
    "\n",
    "            tax = tax + ']'\n",
    "\n",
    "    return [tax]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_TAX, input, output)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ITI\n",
    "# PAT/PAX : ['legs']\n",
    "\n",
    "input  = ['column_def', 'ITI', 'ticket_number', 'currency_code', 'original_currency', 'issue_date', 'FAR', 'attributes']\n",
    "output = ['legs', 'attributes']\n",
    "\n",
    "def fc_ITI(column_def, ITI, ticket_number, currency_code, original_currency, issue_date, FAR, attributes):\n",
    "\n",
    "    # init\n",
    "    legs = None\n",
    "\n",
    "    if column_def == 'PAT' or column_def == 'PAX':\n",
    "        # FAR\n",
    "        if FAR is not None:\n",
    "            FAR_split = re.findall(r'[A-PR-Z]\\d+\\.\\d+', FAR.split(\"END\")[0]) # filter startswith 'Q'\n",
    "            if len(FAR_split) > 0:\n",
    "                FAR_split = [x[1:] for x in FAR_split ] # filter start alpha\n",
    "            if (len(FAR_split) > 1):\n",
    "                # if two more than two ticket legs, direction from right -> left\n",
    "                FAR_split.reverse()\n",
    "                # toal_far\n",
    "                fare_total = FAR_split[0]\n",
    "                # leg far\n",
    "                fare_legs = FAR_split[1:]\n",
    "            elif (len(FAR_split) == 1):\n",
    "                fare_total = FAR_split[0]\n",
    "                fare_legs = 0\n",
    "            else:\n",
    "                fare_total = 0\n",
    "                fare_legs = 0\n",
    "\n",
    "        # ITI\n",
    "        if ITI is not None:\n",
    "            # split\n",
    "            ITI_split = ITI.replace('','').replace('<','').split('<')\n",
    "            if (len(ITI_split)>1):\n",
    "                # if two more than two ticket legs, direction from right -> left\n",
    "                ITI_split.reverse()\n",
    "\n",
    "            # var\n",
    "            '''LEGS:\n",
    "            NOTE: If the ticket type is RFND, LEGS field needs to be empty\n",
    "            Note: this info is provided in the ITI group. Each ticket may have 4 legs max. After the 5th leg, the ticket is considered as conjunction. In the file, if there is a loop, the ticket has a conjunction ticket.Example: 1st leg, 2nd leg, 3rd leg, 4th leg + loop + 5th leg…If the leg is empty, it means that the ticket stopped in the previous leg. Don’t load empty values in the Json.\n",
    "            JSON. example: [{\"departure\":\"FLR\",\"destination\":\"YYZ\",\"seatClass\":\"C\",\"conjunction\":\"1111234567890\",\"carrier\":\"AC\",\"tripCode\":\"876\",\"departureOn\":\"2022-12-30\",\"designator\":\"\",\"stopOver\":\"X\",\"flyerCode\":\"\",\"fare\":259.25,\"currency\": \"CAD\",\"originalFare\":259.25,\"originalCurrency\":\"CAD\"}]\n",
    "            departure: from 4th group (ORAC-ITI) → Leg 1: 4th field | Leg 2: 13th field | Leg 3: 22nd field | Leg 4: 31st field\n",
    "            destination: from 4th group (DSTC-ITI) → Leg 1: 5th field | Leg 2: 14th field | Leg 3: 23rd field | Leg 4: 32nd field\n",
    "            seatClass: 4th group (CLSC-ITI) → Leg 1: 8th field | Leg 2: 17th field | Leg 3: 26th field | Leg 4: 35th field\n",
    "            conjunction: 1st field from 4th group (CJNR-ITI). If is empty, use the same as TICKET_NUMBER\n",
    "\n",
    "            if the ticket includes more than 4 legs: in ITI section, the 39th field (the field after 4th repeat’s designator) will give a new BDNR (10 digits), use the BACN from DCI + new BDNR as conjunction for the following legs\n",
    "            carrier: from 4th group (CARR-ITI) → Leg 1: 6th field | Leg 2: 15th field | Leg 3: 24th field | Leg 4: 33rd field\n",
    "            tripCode: 4th group (FTNR-ITI) → Leg 1: 7th field | Leg 2: 16th field | Leg 3: 25th field | Leg 4: 34th field\n",
    "            departured on: 4th group (FTDA-ITI) → Leg 1: 9th field | Leg 2: 18th field | Leg 3: 27th field | Leg 4: 36th field. NOTE: you need to store this format in the databse: YYYY-MM-DD but the file has JAN01 for example. Use the same procedure/logic from CAT file loader in order to convert into date\n",
    "\n",
    "            Check the logic from CAT (Java code) with Haibinhg and Santhosh because there are some tricks in the code but the logic is:\n",
    "            File will come as JUL01 (they don’t report the year) → convert into 2023-07-01\n",
    "            If the departure date is before the issue date, the year will be ISSUE_DATE +1 year. Example: issue date is 2023-07-01 and departure date is JUN01, then the departure date will be 2024-06-01\n",
    "            If the departure date is after or equals to the issue date, the year will be the same as Issue Date. Example: issue date is 2023-07-01 and departure date is DEC01, then the departure date will be 2023-12-01\n",
    "            If the departure date is after the issue date (but after december 31st), the year will be the same as Issue Date + 1 year. Example: issue date is 2023-07-01 and departure date is JAN01, then the departure date will be 2024-01-01\n",
    "            designator: 4th group (FBTD-ITI) → Leg 1: 11th field | Leg 2: 20th field | Leg 3: 29th field | Leg 4: 38th field\n",
    "            stopOver: from 4th group (STPO-ITI) → Leg 1: 3rd field | Leg 2: 12th field | Leg 3: 21st field | Leg 4: 30th field\n",
    "            flyerCode: <empty>\n",
    "            fare: you need to check the fare construction group and then apply the same logic as CAT loader (use the same rules applied on these stories: FTS-1518, FTS-1188 item 2, FTS-1188 and FTS-1502)\n",
    "            currency: same as CURRENCY_CODE\n",
    "            originalFare: you need to check the fare construction group and then apply the same logic as CAT loader (use the same rules applied on these stories: FTS-1518 and FTS-1188 item 2)\n",
    "            originalCurrency: same as ORIGINAL_CURRENCY'''\n",
    "\n",
    "            # if re.match(r'^\\d{4}-\\d{2}-\\d{2}$',str(issue_date)):\n",
    "            legs = ''\n",
    "            for i in range(len(ITI_split)):\n",
    "                # split\n",
    "                element = ITI_split[i].split('')\n",
    "\n",
    "                # segment\n",
    "                j = 30 # index for element\n",
    "                k = 0 # index for fare_legs\n",
    "                conjunction = ticket_number if len(element[0]) == 0 else (ticket_number[0:3] + element[0])\n",
    "                currency = currency_code\n",
    "                originalCurrency = original_currency\n",
    "                while (j > 0):\n",
    "                    if len(element[j]) != 0:\n",
    "                        # element\n",
    "                        departure = element[j]\n",
    "                        destination = element[j+1]\n",
    "                        seatClass = element[j+4]\n",
    "                        carrier = element[j+2]\n",
    "                        tripCode = element[j+3]\n",
    "                        designator = element[j+7]\n",
    "                        stopOver = element[j-1]\n",
    "                        flyerCode = ''\n",
    "\n",
    "                        # fare\n",
    "                        # far if 'X' != 0, take one from fare_leg\n",
    "                        if (stopOver == 'X'):\n",
    "                            fare = str('0.00')\n",
    "                        else:\n",
    "                            if (fare_legs == 0):\n",
    "                                fare = 'NULL'\n",
    "                            elif (k < len(fare_legs)):\n",
    "                                fare = fare_legs[k]\n",
    "                                k = k + 1\n",
    "                            else:\n",
    "                                fare = 'NULL'\n",
    "\n",
    "                        originalFare = fare\n",
    "\n",
    "                        # departureOn\n",
    "                        # dep_on_date(issue_year-mm-dd)if dep_on_date(mm-dd) > issue_data(mm-dd) else   dep_on_date((issue_year+1)-mm-dd))\n",
    "                        dep_on_date = element[j+5]\n",
    "                        if len(dep_on_date) != 0:\n",
    "                            issue_year = issue_date[0:4]\n",
    "                            dep_day = datetime.strptime(dep_on_date + '2024','%d%b%Y').strftime(\"%m-%d\") # 2024 is leap year to avoid   '02-28', just for transformation, not use it afterward\n",
    "                            dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(issue_year)+ 1)\n",
    "                            departureOn = str(pd.datetime.strptime(dep_on_date + dep_year,'%d%b%Y'))[0:10]\n",
    "                        else:\n",
    "                            departureOn = ''\n",
    "\n",
    "                        # legs\n",
    "                        s = '[' if ((i == len(ITI_split) - 1) and (j == 3)) else ','\n",
    "                        legs = s + '{' + f'\"departure\":\"{departure}\",\"destination\":\"{destination}\",\"seatClass\":\"{seatClass}\",\"conjunct  ion\":\"{conjunction}\",\"carrier\":\"{carrier}\",\"tripCode\":\"{tripCode}\",\"departureOn\":\"{departureOn}\",\"designator\":    \"{designator}\",\"stopOver\":\"{stopOver}\",\"flyerCode\":\"{flyerCode}\",\"fare\":{fare},\"currency\":\"{currency}\",\"origin  alFare\":{originalFare},\"originalCurrency\":\"{originalCurrency}\"' + '}' + legs\n",
    "\n",
    "                    j = j - 9\n",
    "\n",
    "            legs = legs + ']'\n",
    "\n",
    "            # data validation\n",
    "            # check fare total\n",
    "            leg_fare = '%.2f'%sum([float(x[7:]) for x in re.findall(r'\\\"fare\\\"\\:\\d+\\.\\d+', legs)])\n",
    "            (args, attributes) = dv_fc(rule_name = 'check_match', args_name = ('leg_fare','total_fare'), args = (float(leg_fare),float  (fare_total)), msg = attributes, paras = None)\n",
    "\n",
    "            #check legs match fare\n",
    "            h = len(fare_legs) if fare_legs != 0 else 0\n",
    "            (args, attributes) = dv_fc(rule_name = 'check_match', args_name = ('leg','fare'), args = (k, h), msg = attributes, paras    = None)\n",
    "\n",
    "    return [legs, attributes]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_ITI, input, output)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# FAR\n",
    "# PAT/PAX : [fare_construction]\n",
    "\n",
    "input  = ['column_def', 'FAR']\n",
    "output = ['fare_construction']\n",
    "\n",
    "def fc_FAR(column_def, FAR):\n",
    "    # init\n",
    "    fare_construction = None\n",
    "    if FAR is not None:\n",
    "        if column_def == 'PAT' or column_def == 'PAX':\n",
    "            # split\n",
    "            FAR_split =FAR.replace('','').replace('<','').split('<') # filter the last one which is ''\n",
    "\n",
    "            # var\n",
    "            '''FARE_CONSTRUCTION:\n",
    "            Note: the FAR group might have a loop, that’s why we need to use sequence 1, sequence 2, etc.\n",
    "            JSON. Example: [{\"sequence\":1,\"content\":\"AX373911153791006*0626/ 122948\"},{\"sequence\":2,\"content\":\"YHZ PD YMQ54.56CAD54.56END\"}]\n",
    "            content: 1st field from 5th group (FRCA-FAR)'''\n",
    "            fare_construction = ''\n",
    "            for i in range(len(FAR_split)):\n",
    "                element = FAR_split[i].split('')\n",
    "                content = element[0]\n",
    "                s = ',' if i != 0 else '['\n",
    "                fare_construction = fare_construction + s + '{' + f'\"sequence\":{i+1},\"content\":\"{content}\"' +'}'\n",
    "\n",
    "            fare_construction = fare_construction + ']'\n",
    "\n",
    "    return [fare_construction]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_FAR, input, output)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# FOP\n",
    "# PAT/PAX : [payment]\n",
    "\n",
    "input  = ['column_def', 'FOP', 'currency_code', 'EXC', 'RFT']\n",
    "output = ['payment']\n",
    "\n",
    "def fc_FOP(column_def, FOP, currency_code, EXC, RFT):\n",
    "\n",
    "    # init\n",
    "    payment = None\n",
    "\n",
    "    # PAT PAX\n",
    "    if column_def == 'PAT' or column_def == 'PAX':\n",
    "        # EXC\n",
    "        if EXC is not None:\n",
    "            if column_def == 'PAX':\n",
    "                # split\n",
    "                EXC_split = EXC.split('<')\n",
    "                EXC2_split = EXC_split[1].replace('','').split('<')# loop of RACN + RDNR + CDGT\n",
    "                EXC2_element = EXC2_split[0].split(\"\")\n",
    "\n",
    "        # FOP\n",
    "        if FOP is not None:\n",
    "            # split\n",
    "            FOP_split = FOP.replace('','').replace('<','').split('<')\n",
    "\n",
    "            # var\n",
    "            '''PAYMENT:\n",
    "            JSON. Example: [{\"mode\":\"CC\",\"type\":\"CCXX\",\"amount\":0.00,\"accountNumber\":\"\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"CAD\"}]\n",
    "            mode: 1st field of the loop from 7th group (FPTP-FOP). Use only the first 2 chars\n",
    "            type: 1st field of the loop from 7th group (FPTP-FOP)\n",
    "            amount: 6th field of the loop from 7th group (FPAM-FOP)\n",
    "            accountNumber: 2nd field of the loop from 7th group (FPAC-FOP)\n",
    "            approvalCode: 5th field of the loop from 7th group (APLC-FOP)\n",
    "            invoiceNumber: <empty>\n",
    "            currency: same as CURRENCY_CODE\n",
    "\n",
    "            for EXCH, the PAYMENT will be like the example below:\n",
    "            Besides the regular FOP above, we need to add the EX info. Example: [{\"mode\":\"EX\",\"type\":\"EX\",\"amount\":0.00,\"accountNumber\":\"451123456789001\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"CAD\"},{\"mode\":\"CC\",\"type\":\"CCXX\",\"amount\":250.00,\"accountNumber\":\"\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"CAD\"}]\n",
    "            accountNumber: 1st field + 2nd field + 3rd field + 19th field from 10th group (NACN-EXC+ NDNR-EXC + NCDT-EXC + RCPU-EXC). Note: RCPU is char and needs to be converted as number (use the same logic as “coupons field” from refund_legs.\n",
    "            amount: 0.00'''\n",
    "\n",
    "            '''PAX payment (json)\n",
    "            IF FPTP (Form of Payment Type) field is NOT empty\n",
    "            regular json object {} follows the same rules indicated in PAT\n",
    "            JSON. Example: [{\"mode\":\"CC\",\"type\":\"CCXX\",\"amount\":0.00,\"accountNumber\":\"\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"CAD\"}]\n",
    "\n",
    "            IF FPTP (Form of Payment Type) field is empty\n",
    "            a json object as below\n",
    "            Example: {\"mode\":\"EX\",\"type\":\"EX\",\"amount\":0.00,\"accountNumber\":\"451123456789001\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"USD\"}\n",
    "            mode:  EX\n",
    "            type: EX\n",
    "            amount: take the FPAM (Form of Payment AmounT) field from FOP section\n",
    "            accountNumber: EXC GROUP : 8th field (3 digit) + 9th field (10 digit) + 10th field (1 digit) + 22nd field  requirements confirmed\n",
    "            approvalCode: leave empty\n",
    "            invoiceNumber: leave empty\n",
    "            currency: same as CURRENCY_CODE\n",
    "            ** this condition is to be investigated and added to requirementafter 1st test\n",
    "            in case the original ticket has more than 4 legs, two { EX json } is required, because originating ticket has 2 conjunction number\n",
    "            1st {EX} :  the account number contains the first 4 legs' conjunction\n",
    "            2nd {EX} ; the account number contains the following legs' conjunction'''\n",
    "\n",
    "            payment = ''\n",
    "            currency = currency_code\n",
    "            for i in range(len(FOP_split)):\n",
    "                # split\n",
    "                FOP_element = FOP_split[i].split(\"\")\n",
    "\n",
    "                # payment\n",
    "                # element\n",
    "                mode , type1, accountNumber = '', '', ''\n",
    "                if len(FOP_element[0]) != 0:\n",
    "                    mode = FOP_element[0][:2]\n",
    "                    type1 = FOP_element[0]\n",
    "                    accountNumber = FOP_element[1]\n",
    "                else:\n",
    "                    mode = 'EX'\n",
    "                    type1 = 'EX'\n",
    "                    accountNumber = EXC2_element[0] + EXC2_element[1] + EXC2_element[2] + EXC2_element[13] if EXC2_element is not None else ''\n",
    "\n",
    "                amount = FOP_element[5] if len(FOP_element) >= 5 else ''\n",
    "                approvalCode = FOP_element[4] if len(FOP_element) >= 4 else ''\n",
    "                invoiceNumber = ''\n",
    "\n",
    "                s = ',' if i != 0 else '['\n",
    "                payment = payment + s + '{' + f'\"mode\":\"{mode}\",\"type\":\"{type1}\",\"amount\":{amount},\"accountNumber\":\"{accountNumber}\",\"approvalCode\":\"{approvalCode}\",\"invoiceNumber\":\"{invoiceNumber}\",\"currency\":\"{currency}\"' +'}'\n",
    "\n",
    "            payment = payment + ']'\n",
    "\n",
    "    # RFT\n",
    "    if RFT is not None:\n",
    "        if column_def == 'RFT':\n",
    "            RFT_split = RFT.split('<')\n",
    "            RFT2_split = RFT_split[1] # FPTP, FPAC, AMDU\n",
    "            RFT2_element = RFT2_split.split('')\n",
    "\n",
    "            '''REF payment:\n",
    "            JSON. Example: [{\"mode\":\"CC\",\"type\":\"CCVI4000\",\"amount\":0.00,\"accountNumber\":\"VI************5960\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"USD\"}]\n",
    "            mode: 30th field from REF: use the first 2 characters only\n",
    "            type: 30th field from REF\n",
    "            amount: 26th field from REF\n",
    "            accountnumber: 31th field from REF\n",
    "            approvalcode: leave empty\n",
    "            invoicenumber: leave empty\n",
    "            currency: USD'''\n",
    "            mode = RFT2_element[8][:2]\n",
    "            type1 = RFT2_element[8]\n",
    "            amount = RFT2_element[3]\n",
    "            accountNumber = RFT2_element[9]\n",
    "            approvalCode = ''\n",
    "            invoiceNumber = ''\n",
    "            currency = 'USD'\n",
    "\n",
    "            payment = '[{' + f'\"mode\":\"{mode}\",\"type\":\"{type1}\",\"amount\":{amount},\"accountNumber\":\"{accountNumber}\",\"approvalCode\":\"{approvalCode}\",\"invoiceNumber\":\"{invoiceNumber}\",\"currency\":\"{currency}\"' +'}]'\n",
    "\n",
    "    return [payment]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_FOP, input, output)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# RFT\n",
    "# RFT : [refund_legs]\n",
    "\n",
    "input  = ['column_def', 'RFT', 'ticket_number', 'EXC']\n",
    "output = ['refund_legs', 'org_ticket_no']\n",
    "\n",
    "def fc_RFT(column_def, RFT, ticket_number, EXC):\n",
    "\n",
    "    # init\n",
    "    refund_legs, org_ticket_no = None, None\n",
    "\n",
    "    # RFT\n",
    "    if RFT is not None:\n",
    "        if column_def == 'RFT':\n",
    "            # split\n",
    "            RFT_split = RFT.split('<')\n",
    "            RFT_split_1 = re.search('.+<',RFT).group().replace('','').replace('<','').split('<') # loop RACN + RDNR + RCPN\n",
    "            RFT_split_2 = RFT_split[1] # ODOI\n",
    "\n",
    "            # var\n",
    "            # refund_legs\n",
    "            '''REFUND_LEGS:\n",
    "            note: to be populated if ticket_type is RFND only\n",
    "            JSON. example: [{\"sequence\":1,\"ticketNumber\":\"0011259634355\",\"coupons\":\"1000\",\"issueDate\":\"2022-05-03\"}]\n",
    "            ticketNumber: 17th field + 18th fied from 2nd group (RACN-REF+ RDNR-REF). Note: it may have a loop here, so you need to use the sequence 1, sequence 2, etc in the JSON\n",
    "            issueDate: 20th fied from 2nd group (ODOI-REF).\n",
    "            coupons: 19th fied from 2nd group (RCPN-REF). Note: we receive this field as chars. You need to convert into numbers, use the same logic as CAT Loader (for example, the field comes as RR, you need to convert into “1200”. Or might come as VRRV, for example, you need to convert into “0230”. You need to apply the number/sequence only for the letter R; to the other letters (or blank) you need to put “0”)'''\n",
    "\n",
    "            # element\n",
    "            issueDate = RFT_split_2.split(\"\")[0]\n",
    "            for i in range(len(RFT_split_1)):\n",
    "                element = RFT_split_1[i].split(\"\")\n",
    "\n",
    "                # element\n",
    "                ticketNumber = element[0] + element[1]\n",
    "                coupons = coupons_format(element[2])\n",
    "                first_refund_legs_ticketNumber = ticketNumber if i == 0 else 'NULL'\n",
    "\n",
    "                # refund_legs\n",
    "                refund_legs = ''\n",
    "                s = ',' if i != 0 else '['\n",
    "                refund_legs = refund_legs + s + '{' + f'\"sequence\":{str(i+1)},\"ticketNumber\":\"{ticketNumber}\",\"coupons\":\"{coupons}\",\"issueDate\":\"{issueDate}\"' +'}'\n",
    "\n",
    "            refund_legs = refund_legs + ']'\n",
    "\n",
    "    # EXC\n",
    "    if EXC is not None:\n",
    "        if column_def == 'PAX':\n",
    "            # split\n",
    "            EXC_split = EXC.split('<')\n",
    "            EXC2_split = EXC_split[1].replace('','').split('<')# loop of RACN + RDNR\n",
    "            EXC2_element = EXC2_split[0].split(\"\")\n",
    "\n",
    "        # var\n",
    "        # org_ticket_no\n",
    "        '''ORG_TICKET_NO:\n",
    "            TKTT → same as TICKET_NUMBER\n",
    "            EXCH → 8th field from EXC (3 digit) + 9th field from EXC (10 digit) – this is the field that indicates the originating ticket subjected to exchange\n",
    "            RFND → same as 1st ticketNumber from REFUND_LEGS'''\n",
    "\n",
    "        if column_def == 'PAT':\n",
    "            org_ticket_no = ticket_number\n",
    "        elif column_def == 'PAX':\n",
    "            org_ticket_no = EXC2_element[0] + EXC2_element[1]\n",
    "        elif column_def == 'RFT':\n",
    "            org_ticket_no = first_refund_legs_ticketNumber\n",
    "        else:\n",
    "            org_ticket_no = 'NULL'\n",
    "\n",
    "\n",
    "    return [refund_legs, org_ticket_no]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc_RFT, input, output)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# data validation before insert DB\n",
    "# PAT/PAX/RFT : ['attributes', 'original_fare', 'exchange_rate', 'fare_amount', 'tax_amount', 'total_amount', 'agency_code']\n",
    "\n",
    "input  = ['column_def', 'attributes', 'original_fare', 'exchange_rate', 'fare_amount', 'tax_amount', 'total_amount', 'agency_code', 'source', 'coupon_used']\n",
    "output = ['attributes', 'original_fare', 'exchange_rate', 'fare_amount', 'tax_amount', 'total_amount','agency_code', 'source', 'coupon_used']\n",
    "\n",
    "def fc(column_def, attributes, original_fare,exchange_rate,fare_amount,tax_amount,total_amount, agency_code, source, coupon_used):\n",
    "\n",
    "    # len validatin\n",
    "    if column_def != 'RFT':\n",
    "        # original_fare\n",
    "        (original_fare, attributes) = dv_fc(rule_name = 'check_len', args_name = 'original_fare', args = exchange_rate, msg = attributes, paras=(12, 5))\n",
    "\n",
    "        # exchange_rate\n",
    "        (exchange_rate, attributes) = dv_fc(rule_name = 'check_len', args_name = 'exchange_rate', args = exchange_rate, msg = attributes, paras=(12, 5))\n",
    "\n",
    "        # original_fare\n",
    "        (fare_amount, attributes) = dv_fc(rule_name = 'check_len', args_name = 'original_fare', args = fare_amount, msg = attributes, paras=(12, 5))\n",
    "\n",
    "        # original_fare\n",
    "        (tax_amount, attributes) = dv_fc(rule_name = 'check_len', args_name = 'original_fare', args = tax_amount, msg = attributes, paras=(12, 5))\n",
    "\n",
    "        # original_fare\n",
    "        (total_amount, attributes) = dv_fc(rule_name = 'check_len', args_name = 'original_fare', args = total_amount, msg = attributes, paras=(12, 5))\n",
    "\n",
    "        # agency_code\n",
    "        (agency_code, attributes) = dv_fc(rule_name = 'check_len', args_name = 'agency_code', args = agency_code, msg = attributes, paras=(10, 0))\n",
    "\n",
    "        # source\n",
    "        (source, attributes) = dv_fc(rule_name = 'check_len', args_name = 'source', args = source, msg = attributes, paras=(10, 0))\n",
    "\n",
    "        # coupon_used\n",
    "        (coupon_used, attributes) = dv_fc(rule_name = 'check_len', args_name = 'coupon_used', args = source, msg = attributes, paras=(10, 0))\n",
    "\n",
    "\n",
    "    return [attributes, original_fare,exchange_rate,fare_amount,tax_amount,total_amount, agency_code, source, coupon_used]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc, input, output)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "sc = SparkContext.getOrCreate();\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "\n",
    "my_conn_options = {\n",
    "    \"dbtable\": \"flextravel.fx_trans_file\",\n",
    "    \"database\": \"fts_cp_uat\",\n",
    "    \"url\": \"jdbc:postgresql://flextravel-uat-serverless-pg.chzjoncadzav.ca-central-1.rds.amazonaws.com:5432/fts_cp_uat\",\n",
    "    \"customJdbcDriverS3Path\":\"s3://flex-data-uat-canda-central/DEV/postgresql-42.6.0.jar\",\n",
    "    \"customJdbcDriverClassName\":\"org.postgresql.Driver\",\n",
    "    \"user\":\"flexuatuser\",\n",
    "    \"password\":\"flexnewyearpwd@2022\"\n",
    "}\n",
    "\n",
    "my_conn_options1 = {\n",
    "    \"dbtable\": \"flextravel.general_info\",\n",
    "    \"database\": \"fts_cp_uat\",\n",
    "    \"url\": \"jdbc:postgresql://flextravel-uat-serverless-pg.chzjoncadzav.ca-central-1.rds.amazonaws.com:5432/fts_cp_uat\",\n",
    "    \"customJdbcDriverS3Path\":\"s3://flex-data-uat-canda-central/DEV/postgresql-42.6.0.jar\",\n",
    "    \"customJdbcDriverClassName\":\"org.postgresql.Driver\",\n",
    "    \"user\":\"flexuatuser\",\n",
    "    \"password\":\"flexnewyearpwd@2022\"\n",
    "}\n",
    "\n",
    "my_conn_options2 = {\n",
    "    \"dbtable\": \"public.fx_trans_bre_interim_bos_sprint2_test\",\n",
    "    \"database\": \"fts_cp_uat\",\n",
    "    \"url\": \"jdbc:postgresql://flextravel-uat-serverless-pg.chzjoncadzav.ca-central-1.rds.amazonaws.com:5432/fts_cp_uat\",\n",
    "    \"customJdbcDriverS3Path\":\"s3://flex-data-uat-canda-central/DEV/postgresql-42.6.0.jar\",\n",
    "    \"customJdbcDriverClassName\":\"org.postgresql.Driver\",\n",
    "    \"user\":\"flexuatuser\",\n",
    "    \"password\":\"flexnewyearpwd@2022\"\n",
    "}\n",
    "\n",
    "df = glueContext.create_dynamic_frame.from_options(\n",
    "    connection_type=\"postgresql\",\n",
    "    connection_options=my_conn_options,\n",
    "    transformation_ctx=\"df\",\n",
    ")\n",
    "\n",
    "df_GI = glueContext.create_dynamic_frame.from_options(\n",
    "    connection_type=\"postgresql\",\n",
    "    connection_options=my_conn_options1,\n",
    "    transformation_ctx=\"df\",\n",
    ")\n",
    "# GI_df = df_GI.toDF().select(\"id\",\"tids_code\")  \n",
    "\n",
    "# # bos_df_csv=  bos_df_csv.withColumn( \"Orginal_currency\",F.when(length(col(\"Org_currency\"))>5,'').otherwise(bos_df_csv.Org_currency))\n",
    "\n",
    "# bos_df_final = bos_df_csv.select('agency_code', 'ticket_number', 'issue_date', 'pnr', 'tour_code', 'passenger_name', 'coupon_used', 'original_fare', 'fare_amount', 'exchange_rate', 'commission_amount', 'original_currency', 'tax_amount', 'total_amount', 'commission', 'org_ticket_no', 'tax', 'legs', 'fare_construction', 'payment','refund_legs','attributes')\n",
    "\n",
    "# Bos_df_GI= bos_df_final.join(GI_df,\n",
    "#                bos_df_csv.agency_code == GI_df.tids_code, \n",
    "#                \"left\")  \n",
    "\n",
    "\n",
    "# Bos_df_GI=Bos_df_GI.withColumnRenamed(\"id\",\"agent_id\")\n",
    "\n",
    "#Bos_df_GI.show(2, truncate=False)\n",
    "\n",
    "# df1 = df.toDF().select(\"id\", \"supplier_id\",\"sup_srv_map_id\",\"file_name\").where(df[\"file_name\"] =='06.07_DCALLRECORDSAM')\n",
    "# #df2=df1.withColumnRenamed(\"sup_srv_map_id\",\"col0\").withColumnRenamed(\"file_name\",\"col1\")\n",
    "# # df1 = df.filter(f=lambda x: x[\"sup_srv_map_id\"] in [65])\n",
    "\n",
    "# df1 = df.toDF()[\"id\", \"supplier_id\",\"sup_srv_map_id\",\"file_name\"]\n",
    "# df1 = df1[df1[\"file_name\"] =='06.07_DCALLRECORDSAM']\n",
    "\n",
    "\n",
    "#df1.show()\n",
    "\n",
    "# Bos_df_file= Bos_df_GI.join(df1,\n",
    "#                bos_df_csv.tax_on_commission == df1.file_name, \n",
    "#                \"left\")    \n",
    "\n",
    "# Bos_df_file.show()\n",
    "\n",
    "# FTS - 2598 [\"Tax_Amt\"].cast(IntegerType()) -> DoubleType, [\"Total_amt\"].cast(IntegerType()) -> DoubleType\n",
    "Bos_df_file = bos_df_csv\n",
    "Bos_df_file= Bos_df_file.withColumn(\"original_fare\", Bos_df_file[\"original_fare\"].cast(DoubleType())).withColumn(\"fare_amount\", Bos_df_file[\"fare_amount\"].cast(DoubleType())).withColumn(\"tax_amount\", Bos_df_file[\"tax_amount\"].cast(DoubleType()))\\\n",
    "            .withColumn(\"total_amount\", Bos_df_file[\"total_amount\"].cast(DoubleType())) .withColumn(\"exchange_rate\", Bos_df_file[\"exchange_rate\"].cast(TimestampType()))\n",
    "\n",
    "Bos_df_file= Bos_df_file.withColumn(\"commission_amount\", Bos_df_file[\"commission_amount\"].cast(DoubleType())).withColumn(\"issue_date\", Bos_df_file[\"issue_date\"].cast(TimestampType()))\n",
    "\n",
    "Bos_df_write = Bos_df_file.select('transaction_date', 'source', 'booking_channel', 'version_no', 'currency_code', 'ticket_type','agency_code', 'ticket_number', 'issue_date', 'pnr', 'tour_code', 'passenger_name', 'coupon_used', 'original_fare', 'fare_amount', 'exchange_rate', 'commission_amount', 'original_currency', 'tax_amount', 'total_amount', 'commission', 'org_ticket_no', 'tax', 'legs', 'fare_construction', 'payment','refund_legs','attributes', 'tax_on_commission')\n",
    "\n"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "Bos_df_write.head(1)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "text": "[Row(transaction_date=datetime.datetime(2023, 8, 1, 21, 54, 59, 831000), source='BOS', booking_channel='WEB', version_no=1, currency_code='USD', ticket_type='TKTT', agency_code='22521623', ticket_number='0742100377105', issue_date=datetime.datetime(2023, 6, 16, 0, 0), pnr='UOAGUL', tour_code='ITAFKL', passenger_name='REDACTED SAL NAME', coupon_used='BOS', original_fare=1.0, fare_amount=213.0, exchange_rate=None, commission_amount=213.0, original_currency='USD', tax_amount=89.2, total_amount=302.2, commission='[{\"type\":\"BASE\",\"amount\":0.00,\"currency\":\"USD\",\"commissionRate\":0.00}]', org_ticket_no='0742100377105', tax='[{\"type\":\"YR\",\"amount\":2.20,\"currency\":\"USD\"},{\"type\":\"CJ\",\"amount\":16.00,\"currency\":\"USD\"},{\"type\":\"RN\",\"amount\":22.50,\"currency\":\"USD\"},{\"type\":\"VV\",\"amount\":28.60,\"currency\":\"USD\"},{\"type\":\"JD\",\"amount\":15.70,\"currency\":\"USD\"},{\"type\":\"OG\",\"amount\":0.70,\"currency\":\"USD\"},{\"type\":\"QV\",\"amount\":3.50,\"currency\":\"USD\"}]', legs='[{\"departure\":\"AMS\",\"destination\":\"MAD\",\"seatClass\":\"Q\",\"conjunct  ion\":\"0742100377105\",\"carrier\":\"KL\",\"tripCode\":\"1701\",\"departureOn\":\"2023-06-24\",\"designator\":    \"QH5UA5LG/XX\",\"stopOver\":\"O\",\"flyerCode\":\"\",\"fare\":119.12,\"currency\":\"USD\",\"origin  alFare\":119.12,\"originalCurrency\":\"USD\"},{\"departure\":\"MAD\",\"destination\":\"AMS\",\"seatClass\":\"E\",\"conjunct  ion\":\"0742100377105\",\"carrier\":\"KL\",\"tripCode\":\"1702\",\"departureOn\":\"2023-06-27\",\"designator\":    \"EH5UA5LG\",\"stopOver\":\"O\",\"flyerCode\":\"\",\"fare\":97.52,\"currency\":\"USD\",\"origin  alFare\":97.52,\"originalCurrency\":\"USD\"}]', fare_construction='[{\"sequence\":1,\"content\":\"AMS KL MAD119.12KL AMS97.52NUC216.64END ROE0.907418XT22.50RN28.60VV15.70JD0.70OG3.50QV\"}]', payment='[{\"mode\":\"CA\",\"type\":\"CA\",\"amount\":302.20,\"accountNumber\":\"CASH\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"USD\"}]', refund_legs=None, attributes='', tax_on_commission='data/date=2023-06-17/DCALLRECORDSAM.pgp.asc_3e5155823ea22a963da362086c693cf3_cleansed')]\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "Bos_df_write_dyn=DynamicFrame.fromDF(Bos_df_write,glueContext,'Bos_df_write_dyn')\n",
    "\n",
    "df3=glueContext.write_dynamic_frame_from_options(\n",
    "    frame=Bos_df_write_dyn,\n",
    "    connection_type=\"postgresql\",\n",
    "    connection_options=my_conn_options2,\n",
    "    transformation_ctx=\"dynamic_frame\"\n",
    ")\n",
    "#df3.show()"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}