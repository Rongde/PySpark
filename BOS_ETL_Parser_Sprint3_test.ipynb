{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "Python_Glue_Session",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "pygments_lexer": "python3",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import csv\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.sql.functions import udf\n",
    "import re\n",
    "import time\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import length, col, explode, upper, to_date, date_sub, lag, coalesce, lit, array_sort, when, arrays_zip, size, date_format, explode_outer, from_json, concat, expr, array\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from operator import itemgetter\n",
    "import datetime, re, requests\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import concat, col, lit\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "from datetime import datetime\n",
    "# import boto3\n",
    "# from boto3 import client\n",
    "# from boto3.dynamodb.conditions import Key\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from awsglue.transforms import *\n",
    "# from awsglue.utils import getResolvedOptions\n",
    "# from pyspark.context import SparkContext\n",
    "# from awsglue.context import GlueContext\n",
    "# from awsglue.job import Job\n",
    "#\n",
    "# ## @params: [JOB_NAME]\n",
    "# args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "#\n",
    "# sc = SparkContext()\n",
    "# glueContext = GlueContext(sc)\n",
    "# spark = glueContext.spark_session\n",
    "# job = Job(glueContext)\n",
    "# job.init(args['JOB_NAME'], args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# # read data from S3 to DataFrame\n",
    "# # input: S3\n",
    "# # output df['ROW_ID', 'BOS_FILE_EXTRACT', 'file_path', 'COLUMN_DEF']\n",
    "# def read_s3_to_df(day_path):\n",
    "#\n",
    "#     # parameter\n",
    "#     i = 0 # flag for initialize dataframe\n",
    "#\n",
    "#     # boto3 client\n",
    "#     s3 = boto3.client('s3')\n",
    "#     conn = client('s3')  # again assumes boto.cfg setup, assume AWS S3\n",
    "#\n",
    "#     # read data file by file\n",
    "#     for key in conn.list_objects(Bucket='bos-etl')['Contents']:\n",
    "#         path_key = key['Key']\n",
    "#         if path_key.endswith('cleansed'):\n",
    "#             if day_path in path_key:\n",
    "#                 file = s3.get_object(Bucket='bos-etl', Key=path_key)\n",
    "#                 txt = (file['Body'].read().decode('latin1'))\n",
    "#                 #st_re = txt.replace(\"\", \",\")\n",
    "#                 st_re_newline = txt.replace(\"!!! EOS !!!\", \"\\n\")\n",
    "#                 st_re_split = st_re_newline.split(\"\\n\")\n",
    "#                 df = pd.DataFrame(st_re_split)\n",
    "#                 df.index.name = 'ROW_ID'\n",
    "#                 df.rename({0:'BOS_FILE_EXTRACT'},axis='columns',inplace=True)\n",
    "#                 df[\"COLUMN_DEF\"]=df['BOS_FILE_EXTRACT'].replace(regex=r\"\\.*\",value=\"\")\n",
    "#                 # rslt_dfRFT_temp = df[df['COLUMN_DEF'] =='PAT'].head(10)\n",
    "#                 rslt_dfRFT_temp = df\n",
    "#                 if ~rslt_dfRFT_temp.empty:\n",
    "#                     # print(path_key)\n",
    "#                     rslt_dfRFT_temp.insert(0,'tax_on_commission', path_key)\n",
    "#                     if (i ==0):\n",
    "#                         rslt_dfRFT = rslt_dfRFT_temp\n",
    "#                         i = 1\n",
    "#                     else:\n",
    "#                         rslt_dfRFT = pd.concat([rslt_dfRFT,rslt_dfRFT_temp])\n",
    "#     return rslt_dfRFT\n",
    "#\n",
    "#\n",
    "# # read data as DataFrame\n",
    "# #select day\n",
    "# day_path = 'date=2023-06-17'\n",
    "# # select current system day\n",
    "# # day_path = time.strftime('%Y-%m-%d')\n",
    "# rslt_dfRFT = read_s3_to_df(day_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# read csv\n",
    "rslt_dfRFT = pd.read_csv(\"source/input/1_df_RFT_PAT_PAX.csv\")\n",
    "\n",
    "# DataFrame to Dataframe\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create PySpark SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[1]\")\\\n",
    "    .appName(\"SparkByExamples.com\")\\\n",
    "    .getOrCreate()\n",
    "#Create PySpark DataFrame from Pandas\n",
    "sparkDF = spark.createDataFrame(rslt_dfRFT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Common\n",
    "# coupons format\n",
    "def coupons_format(s):\n",
    "    coupons = 10000\n",
    "    coupons_dict = {\"1\": 1000, \"2\": 200, \"3\": 30, \"4\": 4}\n",
    "\n",
    "    for i in range(len(s)):\n",
    "        if s[i] in coupons_dict:\n",
    "            coupons = coupons + coupons_dict[s[i]]\n",
    "\n",
    "    return str(coupons)[1:]\n",
    "\n",
    "# check None\n",
    "def check_None(value, name, exception):\n",
    "    try:\n",
    "        if value is None:\n",
    "            msg = {\n",
    "                name : \"ValueIsNone\"\n",
    "            }\n",
    "\n",
    "            # append\n",
    "            exception.append(msg)\n",
    "\n",
    "    except Exception as e:\n",
    "        exception.append(str(e))\n",
    "\n",
    "    return exception\n",
    "\n",
    "# check Empty\n",
    "def check_Empty(value, name, exception):\n",
    "    try:\n",
    "        if len(value) == 0:\n",
    "            msg = {\n",
    "                name : \"ValueIsEmpty\"\n",
    "            }\n",
    "\n",
    "            # append\n",
    "            exception.append(msg)\n",
    "\n",
    "    except Exception as e:\n",
    "        exception.append(str(e))\n",
    "\n",
    "    return exception\n",
    "\n",
    "# check len\n",
    "def check_len(value, name, exception, min, max):\n",
    "    try:\n",
    "        if (len(value) < min) & (len(value) > max):\n",
    "            msg = {\n",
    "                name : f\"ValueOutOfRange: {value} out of ({min},{max})\"\n",
    "            }\n",
    "\n",
    "            # append\n",
    "            exception.append(msg)\n",
    "\n",
    "            # value\n",
    "            value = 'NULL'\n",
    "    except Exception as e:\n",
    "        exception.append(str(e))\n",
    "        value = 'NULL'\n",
    "\n",
    "    return value, exception\n",
    "\n",
    "# check float\n",
    "def check_float(value, name, exception, integ, demic):\n",
    "    try:\n",
    "        value_str = str(float(value))\n",
    "        if (len(value_str.split('.')[0]) > (integ - demic)) & (len(value_str.split('.')[1]) > demic):\n",
    "            msg = {\n",
    "                name : f\"FloatOutOfRange: {value} out of ({integ},{demic})\"\n",
    "            }\n",
    "\n",
    "            # append\n",
    "            exception.append(msg)\n",
    "\n",
    "            # value\n",
    "            value = -0.99\n",
    "    except Exception as e:\n",
    "        exception.append(str(e))\n",
    "        value = -0.99\n",
    "\n",
    "    return value, exception\n",
    "\n",
    "# check Match\n",
    "def check_Match(value1, name1, value2, name2, exception):\n",
    "    try:\n",
    "        if str(value1) != str(value2):\n",
    "            msg = {\n",
    "                f\"({name1},{name2})\" : f\"ValueIsNotMatch: ({value1},{value2})\"\n",
    "            }\n",
    "\n",
    "            # append\n",
    "            exception.append(msg)\n",
    "\n",
    "    except Exception as e:\n",
    "        exception.append(str(e))\n",
    "\n",
    "    return exception"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# BRE Def\n",
    "# commission json def\n",
    "def commission_json(SAL_json, currency_code):\n",
    "    ''' COMMISSION:\n",
    "        #JSON. Example: [{\"type\":\"BASE\",\"amount\":4.26,\"currency\":\"CAD\",\"commissionRate\":3.0}]\n",
    "        mount: 13th field from 2nd group (COAM-SAL)\n",
    "        commissionRate: 14th field from 2nd group (CORT-SAL)'''\n",
    "\n",
    "    # json\n",
    "    commission = json.dumps({\n",
    "        \"type\": 'BASE',\n",
    "        \"amount\": SAL_json['COAM'],\n",
    "        \"currency\": currency_code,\n",
    "        \"commissionRate\": SAL_json['CORT']\n",
    "    })\n",
    "\n",
    "    return commission\n",
    "\n",
    "# tax json def\n",
    "def tax_json(TAX_L1, original_currency):\n",
    "    ''' TAX:\n",
    "        Field will be <null> if is RFND\n",
    "        Note: this group may have a loop\n",
    "        JSON. Example: [{\"type\":\"CA\",\"amount\":7.12,\"currency\":\"CAD\"},{\"type\":\"YR\",\"amount\":16.00,\"currency\":\"CAD\"}]\n",
    "        type: 2nd field of the loop from 3rd group (TMFT-TAX)\n",
    "        amount: 1st field of the loop from 3rd group (TMFA-TAX)\n",
    "        currency: 10th field from 2nd group (CUOF-SAL)'''\n",
    "    # json list\n",
    "    tax_list = []\n",
    "    for i in range(len(TAX_L1)):\n",
    "        # json\n",
    "        tax_dict = {\n",
    "            \"type\": TAX_L1[i]['TMFT'],\n",
    "            \"amount\": TAX_L1[i]['TMFA'],\n",
    "            \"currency\": original_currency\n",
    "        }\n",
    "        # append list\n",
    "        tax_list.append(tax_dict)\n",
    "\n",
    "    return json.dumps(tax_list)\n",
    "\n",
    "# leg json df\n",
    "def legs_json(fare_construction, ITI_L, currency_code, original_currency, ticket_number, issue_date, exception):\n",
    "    '''LEGS:\n",
    "        NOTE: If the ticket type is RFND, LEGS field needs to be empty\n",
    "        Note: this info is provided in the ITI group. Each ticket may have 4 legs max. After the 5th leg,the ticket is considered as conjunction. In the file, if there is a loop, the ticket has aconjunction ticket.Example: 1st leg, 2nd leg, 3rd leg, 4th leg + loop + 5th leg…If the leg is empty, it means that the ticket stopped in the previous leg. Don’t load empty values in the Json.\n",
    "        JSON. example: [{\"departure\":\"FLR\",\"destination\":\"YYZ\",\"seatClass\":\"C\",\"conjunction\":\"1111234567890\",\"carrier\":\"AC\",\"tripCode\":\"876\",\"departureOn\":\"2022-12-30\",\"designator\":\"\",\"stopOver\":\"X\",\"flyerCode\":\"\",\"fare\":259.25,\"currency\": \"CAD\",\"originalFare\":259.25,\"originalCurrency\":\"CAD\"}]\n",
    "        departure: from 4th group (ORAC-ITI) → Leg 1: 4th field | Leg 2: 13th field | Leg 3: 22nd field | Leg 4: 31st field\n",
    "        destination: from 4th group (DSTC-ITI) → Leg 1: 5th field | Leg 2: 14th field | Leg 3: 23rd field | Leg 4: 32nd field\n",
    "        seatClass: 4th group (CLSC-ITI) → Leg 1: 8th field | Leg 2: 17th field | Leg 3: 26th field | Leg 4: 35th field\n",
    "        conjunction: 1st field from 4th group (CJNR-ITI). If is empty, use the same as TICKET_NUMBER\n",
    "                    if the ticket includes more than 4 legs: in ITI section, the 39th field (the field after 4th repeat’s designator) will give a new BDNR (10 digits), use the BACN from DCI + new BDNR as conjunction for the following legs\n",
    "        carrier: from 4th group (CARR-ITI) → Leg 1: 6th field | Leg 2: 15th field | Leg 3: 24th field | Leg 4: 33rd field\n",
    "        tripCode: 4th group (FTNR-ITI) → Leg 1: 7th field | Leg 2: 16th field | Leg 3: 25th field | Leg 4: 34th field\n",
    "        departured on: 4th group (FTDA-ITI) → Leg 1: 9th field | Leg 2: 18th field | Leg 3: 27th field | Leg 4: 36th field. NOTE: you need to store this format in the databse: YYYY-MM-DD but the file has JAN01 for example. Use the same procedure/logic from CAT file loader in order to convert into date. Check the logic from CAT (Java code) with Haibinhg and Santhosh because there are some tricks in the code but the logic is:\n",
    "        File will come as JUL01 (they don’t report the year) → convert into 2023-07-01\n",
    "        If the departure date is before the issue date, the year will be ISSUE_DATE +1 year. Example: issue date is 2023-07-01 and departure date is JUN01, then the departure date will be 2024-06-01\n",
    "         If the departure date is after or equals to the issue date, the year will be the same as Issue Date. Example: issue date is 2023-07-01 and departure date is DEC01, then the departure date will be 2023-12-01\n",
    "        If the departure date is after the issue date (but after december 31st), the year will be the same as Issue Date + 1 year. Example: issue date is 2023-07-01 and departure date is JAN01, then the departure date will be 2024-01-01\n",
    "        designator: 4th group (FBTD-ITI) → Leg 1: 11th field | Leg 2: 20th field | Leg 3: 29th field | Leg 4: 38th field\n",
    "        stopOver: from 4th group (STPO-ITI) → Leg 1: 3rd field | Leg 2: 12th field | Leg 3: 21st field | Leg 4: 30th field\n",
    "        flyerCode: <empty>\n",
    "        fare: you need to check the fare construction group and then apply the same logic as CAT loader (use the same rules applied on these stories: FTS-1518, FTS-1188 item 2, FTS-1188 and FTS-1502)\n",
    "        currency: same as CURRENCY_CODE\n",
    "        originalFare: you need to check the fare construction group and then apply the same logic as CAT loader (use the same rules applied on these stories: FTS-1518 and FTS-1188 item 2)\n",
    "        originalCurrency: same as ORIGINAL_CURRENCY'''\n",
    "\n",
    "    # FAR\n",
    "    # fare\n",
    "    FRCA = json.loads(fare_construction)[0]['content']\n",
    "    # split\n",
    "    FAR_split = re.findall(r'[A-PR-Z][\\d\\.]+', FRCA.split(\"END\")[0])  # filter startswith 'Q'\n",
    "    # fare_legs, fare_total\n",
    "    if len(FAR_split) > 0:\n",
    "        FAR_split = [x[1:] for x in FAR_split]  # filter start alpha\n",
    "        if (len(FAR_split) > 1):\n",
    "            # if two more than two ticket legs, direction from right -> left\n",
    "            FAR_split.reverse()\n",
    "            # toal_far\n",
    "            fare_total = FAR_split[0]\n",
    "            # leg far\n",
    "            fare_legs = FAR_split[1:]\n",
    "        elif (len(FAR_split) == 1):\n",
    "            fare_total = FAR_split[0]\n",
    "            fare_legs = -0.99\n",
    "        else:\n",
    "            fare_total = -0.999\n",
    "            fare_legs = -0.99\n",
    "\n",
    "    # ITI\n",
    "    legs = []\n",
    "    if len(ITI_L) > 0:\n",
    "        ITI_L.reverse()\n",
    "    for i in range(len(ITI_L)):\n",
    "        conjunction = ticket_number if len(ITI_L[i]['CJNR']) == 0 else (ticket_number[0:3] + ITI_L[i]['CJNR'])\n",
    "        currency = currency_code\n",
    "        originalCurrency = original_currency\n",
    "\n",
    "        # loop\n",
    "        elements = ITI_L[i]['ITI_L_L']\n",
    "        elements.reverse()\n",
    "        k = 0  # index for fare_legs segment\n",
    "        for element in elements:\n",
    "            if (element['ORAC'] != ''):\n",
    "                # departureOn\n",
    "                # dep_on_date(issue_year-mm-dd)if dep_on_date(mm-dd) > issue_data(mm-dd) else   dep_on_date((issue_year+1)-mm-dd))\n",
    "                dep_on_date = element['FTDA']  # 4th group (FTDA-ITI)\n",
    "                if len(dep_on_date) != 0:\n",
    "                    if re.match(r'^\\d{4}-\\d{2}-\\d{2}$', str(issue_date)):\n",
    "                        issue_year = issue_date[0:4]\n",
    "                        dep_day = datetime.strptime(dep_on_date + '2024', '%d%b%Y').strftime(\"%m-%d\")  # 2024 is leap year to avoid   '02-28', just for transformation, not use it afterward\n",
    "                        dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(issue_year) + 1)\n",
    "                        departureOn = str(pd.datetime.strptime(dep_on_date + dep_year, '%d%b%Y'))[0:10]\n",
    "                    else:\n",
    "                        departureOn = ''\n",
    "                else:\n",
    "                    departureOn = ''\n",
    "\n",
    "                # fare\n",
    "                # far if 'X' != 0, take one from fare_leg\n",
    "                if (element['STPO'] == 'X'):\n",
    "                    fare = str('0.00')\n",
    "                else:\n",
    "                    if (fare_legs == 0):\n",
    "                        fare = 'NULL'\n",
    "                    elif (k < len(fare_legs)):\n",
    "                        fare = fare_legs[k]\n",
    "                        k = k + 1\n",
    "                    else:\n",
    "                        fare = 'NULL'\n",
    "\n",
    "                originalFare = fare\n",
    "\n",
    "                legs_dict = {\n",
    "                    \"departure\": element[\"ORAC\"],  # from 4th group (ORAC-ITI)\n",
    "                    \"destination\": element[\"DSTC\"],  # from 4th group (DSTC-ITI)\n",
    "                    \"seatClass\": element[\"CLSC\"],  # 4th group (CLSC-ITI)\n",
    "                    \"conjunction\": conjunction,\n",
    "                    \"carrier\": element[\"CARR\"],  # from 4th group (CARR-ITI)\n",
    "                    \"tripCode\": element[\"FTNR\"],  # 4th group (FTNR-ITI)\n",
    "                    \"departureOn\": departureOn,\n",
    "                    \"designator\": element[\"FBTD\"],  # 4th group (FBTD-ITI)\n",
    "                    \"stopOver\": element[\"STPO\"],  # from 4th group (STPO-ITI)\n",
    "                    \"flyerCode\": \"\",  # <empty>\n",
    "                    \"fare\": fare,\n",
    "                    \"currency\": currency,\n",
    "                    \"originalFare\": originalFare,\n",
    "                    \"originalCurrency\": originalCurrency\n",
    "                }\n",
    "                # append list\n",
    "                legs.append(legs_dict)\n",
    "        # reverse\n",
    "        legs.reverse()\n",
    "\n",
    "    # data validation\n",
    "    # check fare total\n",
    "    leg_fare = '%.2f'%sum([float(x[9:]) for x in re.findall(r'\\\"fare\\\"\\:\\s\\\"\\d+\\.\\d+', json.dumps(legs))])\n",
    "    print('leg_fare')\n",
    "    print(json.dumps(legs))\n",
    "    print(re.findall(r'\\\"fare\\\"\\:\\d+\\.\\d+', json.dumps(legs)))\n",
    "    print(leg_fare)\n",
    "    exception = check_Match(leg_fare, 'leg_fare', fare_total, 'fare_total', exception)\n",
    "    #check legs match fare\n",
    "    h = len(fare_legs) if fare_legs != 0 else 0\n",
    "    exception = check_Match(h, 'leg', k, 'fare', exception)\n",
    "\n",
    "    return legs, exception\n",
    "\n",
    "# fare_construction json def\n",
    "def fare_construction_json(FAR_json):\n",
    "    '''FARE_CONSTRUCTION:\n",
    "            Note: the FAR group might have a loop, that’s why we need to use sequence 1, sequence 2, etc.\n",
    "            JSON. Example: [{\"sequence\":1,\"content\":\"AX373911153791006*0626/ 122948\"},{\"sequence\":2,\"content\":\"YHZ PD YMQ54.56CAD54.56END\"}]\n",
    "            content: 1st field from 5th group (FRCA-FAR)'''\n",
    "    FAR_L = FAR_json['FAR_L']\n",
    "    # fare_construction\n",
    "    fare_construction = []\n",
    "    for i in range(len(FAR_L)):\n",
    "        # dict\n",
    "        fare_construction_dict = {\n",
    "            \"sequence\" : i + 1,\n",
    "            \"content\" : FAR_L[i]['FRCA']\n",
    "        }\n",
    "\n",
    "        # append list\n",
    "        fare_construction.append(fare_construction_dict)\n",
    "\n",
    "    return json.dumps(fare_construction)\n",
    "\n",
    "# payment json def\n",
    "def payment_json(column_def, currency_code, FOP_json = None, EXC_json = None, RFT_json = None):\n",
    "    # PAT PAX\n",
    "    if column_def in ('PAT', 'PAX'):\n",
    "        FOP_L = FOP_json[\"FOP_L\"]\n",
    "        payment = []\n",
    "        # PAT\n",
    "        '''PAT PAYMENT:\n",
    "            JSON. Example: [{\"mode\":\"CC\",\"type\":\"CCXX\",\"amount\":0.00,\"accountNumber\":\"\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"CAD\"}]\n",
    "            mode: 1st field of the loop from 7th group (FPTP-FOP). Use only the first 2 chars\n",
    "            type: 1st field of the loop from 7th group (FPTP-FOP)\n",
    "            amount: 6th field of the loop from 7th group (FPAM-FOP)\n",
    "            accountNumber: 2nd field of the loop from 7th group (FPAC-FOP)\n",
    "            approvalCode: 5th field of the loop from 7th group (APLC-FOP)\n",
    "            invoiceNumber: <empty>\n",
    "            currency: same as CURRENCY_CODE'''\n",
    "        if column_def == 'PAT':\n",
    "            for i in range(len(FOP_L)):\n",
    "                # dict\n",
    "                payment_dict = {\n",
    "                    \"mode\" : FOP_L[i][\"FPTP\"][:2],\n",
    "                    \"type\" : FOP_L[i][\"FPTP\"],\n",
    "                    \"amount\" : FOP_L[i]['FPAM'],\n",
    "                    \"accountNumber\" : FOP_L[i][\"FPAC\"],\n",
    "                    \"approvalCode\" : FOP_L[i][\"APLC\"],\n",
    "                    \"invoiceNumber\" : \"\",\n",
    "                    \"currency\" : currency_code\n",
    "                }\n",
    "\n",
    "                payment.append(payment_dict)\n",
    "\n",
    "        # PAX\n",
    "        '''PAX payment (json)\n",
    "            IF FPTP (Form of Payment Type) field is NOT empty\n",
    "            regular json object {} follows the same rules indicated in PAT\n",
    "            JSON. Example: [{\"mode\":\"CC\",\"type\":\"CCXX\",\"amount\":0.00,\"accountNumber\":\"\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"CAD\"}]\n",
    "\n",
    "            IF FPTP (Form of Payment Type) field is empty\n",
    "            a json object as below\n",
    "            Example: {\"mode\":\"EX\",\"type\":\"EX\",\"amount\":0.00,\"accountNumber\":\"451123456789001\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"USD\"}\n",
    "            mode:  EX\n",
    "            type: EX\n",
    "            amount: take the FPAM (Form of Payment AmounT) field from FOP section\n",
    "            accountNumber: EXC GROUP : 8th field (3 digit)(RACN - EXC) + 9th field (10 digit)(RDNR - EXC) + 10th field (1 digit)(CDGT - EXC) + 22nd field (RCPN - EXC) requirements confirmed\n",
    "            approvalCode: leave empty\n",
    "            invoiceNumber: leave empty\n",
    "            currency: same as CURRENCY_CODE'''\n",
    "        if column_def == 'PAX':\n",
    "            for i in range(len(FOP_L)):\n",
    "                # dict\n",
    "                payment_dict = {\n",
    "                    \"mode\" : FOP_L[i][\"FPTP\"][:2] if FOP_L[i][\"FPTP\"][:2] != '' else 'EX',\n",
    "                    \"type\" : FOP_L[i][\"FPTP\"] if FOP_L[i][\"FPTP\"][:2] != '' else 'EX',\n",
    "                    \"amount\" : FOP_L[i]['FPAM'],\n",
    "                    \"accountNumber\" : FOP_L[i][\"FPAC\"],\n",
    "                    \"approvalCode\" : EXC_json['RACN'] + EXC_json['RDNR'] + EXC_json['CDGT'] + EXC_json['RCPN'],\n",
    "                    \"invoiceNumber\" : \"\",\n",
    "                    \"currency\" : currency_code\n",
    "                }\n",
    "\n",
    "                payment.append(payment_dict)\n",
    "\n",
    "    # RFT\n",
    "    '''REF payment:\n",
    "        JSON. Example: [{\"mode\":\"CC\",\"type\":\"CCVI4000\",\"amount\":0.00,\"accountNumber\":\"VI************5960\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"USD\"}]\n",
    "        mode: 30th field from REF: use the first 2 characters only (FPTP - REF)\n",
    "        type: 30th field from REF (FPTP - REF)\n",
    "        amount: 26th field from REF (AMDU - REF)\n",
    "        accountnumber: 31th field from （FPAC - REF)\n",
    "        approvalcode: leave empty\n",
    "        invoicenumber: leave empty\n",
    "        currency: USD'''\n",
    "    if column_def == 'RFT':\n",
    "        payment = []\n",
    "        # dict\n",
    "        payment_dict = {\n",
    "            \"mode\" : RFT_json['FPTP'][0:2],\n",
    "            \"type\" : RFT_json['FPTP'],\n",
    "            \"amount\" : RFT_json['AMDU'],\n",
    "            \"accountNumber\" : RFT_json['FPAC'],\n",
    "            \"approvalCode\" : \"\",\n",
    "            \"invoiceNumber\" : \"\",\n",
    "            \"currency\" : currency_code\n",
    "            }\n",
    "\n",
    "        payment.append(payment_dict)\n",
    "\n",
    "    return json.dumps(payment)\n",
    "\n",
    "# refund_legs json def\n",
    "def refund_legs_json(RFT_json):\n",
    "    '''REFUND_LEGS:\n",
    "        note: to be populated if ticket_type is RFND only\n",
    "        JSON. example: [{\"sequence\":1,\"ticketNumber\":\"0011259634355\",\"coupons\":\"1000\",\"issueDate\":\"2022-05-03\"}]\n",
    "        ticketNumber: 17th field + 18th fied from 2nd group (RACN-REF+ RDNR-REF). Note: it may have a loop here, so you need to use the sequence 1, sequence 2, etc in the JSON\n",
    "        issueDate: 20th fied from 2nd group (ODOI-REF).\n",
    "        coupons: 19th fied from 2nd group (RCPN-REF). Note: we receive this field as chars. You need to convert into numbers, use the same logic as CAT Loader (for example, the field comes as RR, you need to convert into “1200”. Or might come as VRRV, for example, you need to convert into “0230”. You need to apply the number/sequence only for the letter R; to the other letters (or blank) you need to put “0”)'''\n",
    "    RFT_L = RFT_json['RFT_L']\n",
    "    issueDate = RFT_json['ODOI']\n",
    "    refund_legs = []\n",
    "    for i in range(len(RFT_L)):\n",
    "        # dict\n",
    "        refund_legs_dict = {\n",
    "            \"sequence\" : i + 1,\n",
    "            \"ticketNumber\" : RFT_L[i]['RACN'] + RFT_L[i]['RDNR'],\n",
    "            \"coupons\" : coupons_format(RFT_L[i]['RCPN']),\n",
    "            \"issueDate\" : issueDate\n",
    "        }\n",
    "\n",
    "        # append list\n",
    "        refund_legs.append(refund_legs_dict)\n",
    "\n",
    "    return json.dumps(refund_legs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# BOS\n",
    "class BOS:\n",
    "    def __init__(self, line, currency_code, bos_type):\n",
    "        self.line = line\n",
    "        self.currency_code = currency_code\n",
    "        self.bos_type = bos_type\n",
    "\n",
    "    # split\n",
    "    def split_DCI(self):\n",
    "        # init\n",
    "        DCI_json = None\n",
    "        # split\n",
    "        split1 = self.line.split(\"\")\n",
    "\n",
    "        # DCI\n",
    "        DCI = split1[0].split(\"<\")[0]\n",
    "        if DCI is not None:\n",
    "            # split\n",
    "            DCI_split = DCI.split(\"\")\n",
    "\n",
    "            # json\n",
    "            DCI_json = {\n",
    "                'VLNC': DCI_split[1],\n",
    "                'BACN': DCI_split[4],\n",
    "                'BDNR': DCI_split[5],\n",
    "                'DAIS': DCI_split[7]\n",
    "            }\n",
    "\n",
    "        return DCI_json\n",
    "\n",
    "    # map\n",
    "    def map_DCI(self, exception, DCI_json):\n",
    "        # init\n",
    "        agency_code, ticket_number, issue_date = None, None, None\n",
    "        #check None\n",
    "        exception = check_None(DCI_json, 'DCI', exception)\n",
    "\n",
    "        print('DCI_json')\n",
    "        print(DCI_json)\n",
    "        print(DCI_json[\"VLNC\"])\n",
    "\n",
    "        if len(exception) == 0:\n",
    "            # DCI\n",
    "            # agency_code : 2nd field from 1st group (VLNC-DCI)\n",
    "            agency_code = DCI_json['VLNC']\n",
    "            # ticket_number : 5th field + 6th field from 1st group (BACN-DCI+ BDNR-DCI)\n",
    "            ticket_number = DCI_json['BACN'] + DCI_json['BDNR']\n",
    "            # issue_date : 8th field from 1st group (DAIS-DCI). Field is reported as YYMMDD\n",
    "            issue_date = datetime.strptime(DCI_json['DAIS'], '%d%b%y').strftime(\"%Y-%m-%d\")\n",
    "            print('DCI_Map')\n",
    "            print(ticket_number)\n",
    "\n",
    "        return exception, agency_code, ticket_number, issue_date\n",
    "\n",
    "    # parser\n",
    "    def parser(self):\n",
    "        pass\n",
    "\n",
    "# PAT\n",
    "class PATX(BOS):\n",
    "\n",
    "    # split\n",
    "    def split_PATX(self):\n",
    "        DCI_json, SAL_json, TAX_json, ITI_json, FAR_json, FOP_json, EXC_json = None, None, None, None, None, None, None\n",
    "\n",
    "        # split\n",
    "        split1 = self.line.split(\"\")\n",
    "\n",
    "        # DCI\n",
    "        DCI_json = self.split_DCI()\n",
    "\n",
    "        # SAL\n",
    "        SAL = split1[0].split(\"<\")[1]\n",
    "        if SAL is not None:\n",
    "            # split\n",
    "            SAL_split = SAL.split(\"\")\n",
    "\n",
    "            # json\n",
    "            SAL_json = {\n",
    "                'CPUI': SAL_split[6],\n",
    "                'TDAM': SAL_split[7],\n",
    "                'FARE': SAL_split[8],\n",
    "                'CUOF': SAL_split[9],\n",
    "                'EQFR': SAL_split[10],\n",
    "                'TTAX': SAL_split[11],\n",
    "                'COAM': SAL_split[12],\n",
    "                'CORT': SAL_split[13],\n",
    "                'PNRR': SAL_split[14],\n",
    "                'PXNM': SAL_split[15],\n",
    "                'TOUR': SAL_split[16]\n",
    "            }\n",
    "\n",
    "        # TAX\n",
    "        TAX = split1[1]\n",
    "        if TAX is not None:\n",
    "            # split\n",
    "            TAX_split = TAX.split('<')[0].replace('', '').split('<')\n",
    "\n",
    "            # vars\n",
    "            # TAX_L1 : TMFA, TMFT\n",
    "            TAX_L1 = list()\n",
    "            for i in range(len(TAX_split)):\n",
    "                # split\n",
    "                element = TAX_split[i].split('')\n",
    "\n",
    "                # dict\n",
    "                dict = {\n",
    "                    'TMFA': element[0],\n",
    "                    'TMFT': element[1]\n",
    "                }\n",
    "\n",
    "                # append list\n",
    "                TAX_L1.append(dict)\n",
    "\n",
    "            # json\n",
    "            TAX_json = {\n",
    "                'TAX_L1': TAX_L1\n",
    "            }\n",
    "\n",
    "        # ITI\n",
    "        ITI = split1[2]\n",
    "        if ITI is not None:\n",
    "            # split\n",
    "            ITI_split = ITI.replace('', '').replace('<', '').split('<')\n",
    "\n",
    "            # vars\n",
    "            ITI_L = list()\n",
    "            for i in range(len(ITI_split)):\n",
    "                # split\n",
    "                element = ITI_split[i].split('')\n",
    "\n",
    "                # vars\n",
    "                CJNR = element[0]\n",
    "                CDGT = element[1]\n",
    "\n",
    "                # segment list\n",
    "                ITI_L_L = list()\n",
    "                # dict\n",
    "                # 4 segment\n",
    "                for j in range(4):\n",
    "                    segment_dict = {\n",
    "                        'STPO': element[(j * 9) + 2],\n",
    "                        'ORAC': element[(j * 9) + 3],\n",
    "                        'DSTC': element[(j * 9) + 4],\n",
    "                        'CARR': element[(j * 9) + 5],\n",
    "                        'FTNR': element[(j * 9) + 6],\n",
    "                        'CLSC': element[(j * 9) + 7],\n",
    "                        'FTDA': element[(j * 9) + 8],\n",
    "                        'FTDT': element[(j * 9) + 9],\n",
    "                        'FBTD': element[(j * 9) + 10]\n",
    "                    }\n",
    "\n",
    "                    # append segment list\n",
    "                    ITI_L_L.append(segment_dict)\n",
    "\n",
    "                # ITI_dict\n",
    "                ITI_dict = {\n",
    "                    'CJNR': CJNR,\n",
    "                    'CDGT': CDGT,\n",
    "                    'ITI_L_L': ITI_L_L\n",
    "                }\n",
    "\n",
    "                # append list\n",
    "                ITI_L.append(ITI_dict)\n",
    "\n",
    "            # json\n",
    "            ITI_json = {\n",
    "                'ITI_L': ITI_L\n",
    "            }\n",
    "\n",
    "        # FAR\n",
    "        FAR = split1[3]\n",
    "        if FAR is not None:\n",
    "            # split\n",
    "            FAR_split = FAR.replace('', '').replace('<', '').split('<')\n",
    "\n",
    "            # vars\n",
    "            # FAR_L\n",
    "            FAR_L = []\n",
    "            for i in range(len(FAR_split)):\n",
    "                # split\n",
    "                element = FAR_split[i].split('')\n",
    "\n",
    "                # dict\n",
    "                FAR_dict = {\n",
    "                    'FRCA': element[0]\n",
    "                }\n",
    "\n",
    "                # append list\n",
    "                FAR_L.append(FAR_dict)\n",
    "\n",
    "            # json\n",
    "            FAR_json = {\n",
    "                'FAR_L': FAR_L\n",
    "            }\n",
    "\n",
    "        # FOP\n",
    "        FOP = split1[4]\n",
    "        if FOP is not None:\n",
    "            # split\n",
    "            FOP_split = FOP.replace('', '').replace('<', '').split('<')\n",
    "\n",
    "            # vars\n",
    "            FOP_L = []\n",
    "            for i in range(len(FOP_split)):\n",
    "                # split\n",
    "                FOP_element = FOP_split[i].split(\"\")\n",
    "\n",
    "                # dict\n",
    "                FOP_dict = {\n",
    "                    'FPTP': FOP_element[0],\n",
    "                    'FPAC': FOP_element[1],\n",
    "                    'APLC': FOP_element[4],\n",
    "                    'FPAM': FOP_element[5]\n",
    "                }\n",
    "\n",
    "                # append list\n",
    "                FOP_L.append(FOP_dict)\n",
    "\n",
    "            # json\n",
    "            FOP_json = {\n",
    "                'FOP_L': FOP_L\n",
    "            }\n",
    "\n",
    "        # EXC\n",
    "        if self.bos_type == 'PAX':\n",
    "            EXC = split1[7]\n",
    "            if EXC is not None:\n",
    "                # split\n",
    "                EXC_split = EXC.split('<')\n",
    "                EXC2_split = EXC_split[1].replace('', '').split('<')\n",
    "                EXC2_element = EXC2_split[0].split(\"\")\n",
    "\n",
    "                # json\n",
    "                EXC_json = {\n",
    "                    'RACN': EXC2_element[0],\n",
    "                    'RDNR': EXC2_element[1],\n",
    "                    'CDGT' : EXC2_element[2],\n",
    "                    'RCPN' : EXC2_element[13]\n",
    "                }\n",
    "\n",
    "\n",
    "        return DCI_json, SAL_json, TAX_json, ITI_json, FAR_json, FOP_json, EXC_json\n",
    "\n",
    "    # map\n",
    "    def map_PATX(self, exception, DCI_json, SAL_json, TAX_json, ITI_json, FAR_json, FOP_json, EXC_json):\n",
    "        # init\n",
    "        exception, agency_code, ticket_number, issue_date, pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission, tax, fare_construction, legs, payment, org_ticket_no = [], None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None\n",
    "        # DCI\n",
    "        exception, agency_code, ticket_number, issue_date = self.map_DCI(exception, DCI_json)\n",
    "        #check None\n",
    "        exception = check_None(DCI_json, 'DCI', exception)\n",
    "        exception = check_None(SAL_json, 'SAL', exception)\n",
    "        exception = check_None(TAX_json, 'TAX', exception)\n",
    "        exception = check_None(ITI_json, 'ITI', exception)\n",
    "        exception = check_None(FAR_json, 'FAR', exception)\n",
    "        exception = check_None(FOP_json, 'FOP', exception)\n",
    "        if len(exception) == 0:\n",
    "            # vars\n",
    "            pnr = SAL_json['PNRR']  # 15th field from 2nd group (PNRR-SAL)\n",
    "            tour_code = SAL_json['TOUR']  # 17th field from 2nd group (TOUR-SAL)\n",
    "            passenger_name = SAL_json['PXNM'] # 16th field from 2nd group (PXNM-SAL)\n",
    "            coupon_used = SAL_json['CPUI'] # 7th field from 2nd group (CPUI-SAL)\n",
    "            original_fare = SAL_json['FARE'] # 9th field from 2nd group(FARE-SAL)\n",
    "            original_currency = SAL_json['CUOF']  # 10th field from 2nd group (CUOF-SAL)\n",
    "            tax_amount = SAL_json['TTAX']  # 12th field from 2nd group (TTAX-SAL)\n",
    "            total_amount = SAL_json['TDAM']  # 8th field from 2nd group (TDAM-SAL)\n",
    "            fare_amount = SAL_json['EQFR'] if float(SAL_json['EQFR']) != 0 else original_fare  # fare_amount : 11tfrom 2nd group (EQFR-SAL)… Note: if is 0.00, use the same as ORIGINAL_FARE\n",
    "            exchange_rate = round(float(fare_amount) / float(original_fare), 3) if float(original_fare) != 0 else None #FARE_AMOUNT / ORIGINAL_FARE\n",
    "            commission_amount = fare_amount  # commission_amount : same as FARE_AMOUNT\n",
    "            commission = commission_json(SAL_json, self.currency_code)  #JSON. E[{\"type\":\"BASE\",\"amount\":4.26,\"currency\":\"CAD\",\"commissionRate\n",
    "            tax = tax_json(TAX_json['TAX_L1'], original_currency)  # JSON. E[{\"type\":\"CA\",\"amount\":7.12,\"currency\":\"CAD\"},{\"type\":\"YR\",\"amount\":16.00,\"currency\":\n",
    "            fare_construction = fare_construction_json(FAR_json) # JSON. E[{\"sequence\":1,\"content\":\"AX373911153791006*0626/ 122948\"},{\"sequence\":2,\"content\":YMQ54.56CAD54.5\n",
    "            legs, exception = legs_json(fare_construction, ITI_json['ITI_L'], self.currency_code, original_currency,ticket_number,  issue_date, exception)  # JSON. example: [{\"departure\":\"FLR\",\"destination\":\"YYZ\",\"seatC\",\"conjunction\":\"1111234567890\",\"carrier\":\"AC\",\"tripCode\":\"876\",\"departureOn\":\"2022-12-30\",\"designatoropOver\":\"X\",\"flyerCode\":\"\",\"fare\":259.25,\"currency\": \"CAD\",\"originalFare\":259.25,\n",
    "\n",
    "\n",
    "            # \"originalCurrency\"\n",
    "            if (self.bos_type == 'PAT'):\n",
    "                # pament\n",
    "                payment = payment_json(self.bos_type, self.currency_code, FOP_json = FOP_json) # JSON. Example: [{\"mode\":\"CC\",\"type\":\"CCXX\",\"amount\":0.00,\"accountNumber\":\"\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"CAD\"}]\n",
    "                org_ticket_no = ticket_number # same as TICKET_NUMBER\n",
    "\n",
    "            if (self.bos_type == 'PAX'):\n",
    "                exception = check_None(EXC_json, 'EXC', exception)\n",
    "                if len(exception) == 0:\n",
    "                    # pament\n",
    "                    payment = payment_json(self.bos_type, self.currency_code, FOP_json = FOP_json, EXC_json = EXC_json) # JSON. Example: [{\"mode\":\"EX\",\"type\":\"EX\",\"amount\":0.00,\"accountNumber\":\"\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"CAD\"}]\n",
    "                    # org_ticket_no\n",
    "                    org_ticket_no = EXC_json['RACN'] + EXC_json['RDNR'] # 8th field from EXC (3 digit)(RACN - EXC) + 9th field from EXC (10 digit)(RDNR - EXC) – this is the field that indicates the originating ticket subjected to exchange\n",
    "\n",
    "            # Data Validation\n",
    "            # original_fare\n",
    "            original_fare, exception = check_float(original_fare, 'original_fare', exception, 12, 5)\n",
    "            # exchange_rate\n",
    "            exchange_rate, exception = check_float(exchange_rate, 'exchange_rate', exception, 12, 5)\n",
    "            # fare_amount\n",
    "            fare_amount, exception = check_float(fare_amount, 'fare_amount', exception, 12, 5)\n",
    "            # tax_amount\n",
    "            tax_amount, exception = check_float(tax_amount, 'tax_amount', exception, 12, 5)\n",
    "            # total_amount\n",
    "            total_amount, exception = check_float(total_amount, 'total_amount', exception, 12, 5)\n",
    "            # coupon_used\n",
    "            (coupon_used, exception) = check_len(coupon_used, 'coupon_used', exception, 0, 10)\n",
    "\n",
    "        return exception, agency_code, ticket_number, issue_date, pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission, tax, fare_construction, legs, payment, org_ticket_no\n",
    "\n",
    "    # parser\n",
    "    def parser(self):\n",
    "        # init\n",
    "        exception, agency_code, ticket_number, issue_date, pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission, tax, fare_construction, legs, payment, org_ticket_no, ticket_type = [], None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None\n",
    "\n",
    "        if self.bos_type == 'PAT':\n",
    "            ticket_type = 'TKTT'\n",
    "        elif self.bos_type == 'PAX':\n",
    "            ticket_type = 'EXCH-TKTT'\n",
    "\n",
    "        # Parser\n",
    "        DCI_json, SAL_json, TAX_json, ITI_json, FAR_json, FOP_json, EXC_json = self.split_PATX()\n",
    "\n",
    "        # Map\n",
    "        exception, agency_code, ticket_number, issue_date, pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission, tax, fare_construction, legs, payment, org_ticket_no =self.map_PATX(exception, DCI_json, SAL_json, TAX_json, ITI_json, FAR_json, FOP_json, EXC_json)\n",
    "\n",
    "        return exception, agency_code, ticket_number, issue_date, pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission, tax, fare_construction, legs, payment, org_ticket_no, ticket_type\n",
    "\n",
    "# RFT\n",
    "class RFT(BOS):\n",
    "    def split_RFT(self):\n",
    "        DCI_json, RFT_json = None, None\n",
    "\n",
    "        # DCI\n",
    "        DCI_json = self.split_DCI()\n",
    "\n",
    "        # RFT\n",
    "        RFT1 = re.search(r'<.+', self.line).group()\n",
    "        print('RFT')\n",
    "        print(RFT)\n",
    "        if RFT1 is not None:\n",
    "            # split\n",
    "            RFT_split = RFT1.split('<')\n",
    "            RFT_split_1 = RFT_split[0].split('')[1].split('<')\n",
    "            RFT_split_2_element = RFT_split[1].split(\"\")\n",
    "\n",
    "            # RFT_L\n",
    "            RFT_L1 = []\n",
    "            # element\n",
    "            for i in range(len(RFT_split_1)):\n",
    "                element = RFT_split_1[i].split(\"\")\n",
    "\n",
    "                # dict\n",
    "                RFT_dict = {\n",
    "                    'RACN': element[0],\n",
    "                    'RDNR': element[1],\n",
    "                    'RCPN': element[2]\n",
    "                }\n",
    "\n",
    "                # append list\n",
    "                RFT_L1.append(RFT_dict)\n",
    "\n",
    "            # json\n",
    "            RFT_json = {\n",
    "                'ODOI' : RFT_split_2_element[0],\n",
    "                'AMDU' : RFT_split_2_element[3],\n",
    "                'FPTP': RFT_split_2_element[8],\n",
    "                'FPAC': RFT_split_2_element[9],\n",
    "                'RFT_L': RFT_L1\n",
    "            }\n",
    "\n",
    "        return DCI_json, RFT_json\n",
    "\n",
    "    def map_RFT(self, exception, DCI_json, RFT_json):\n",
    "        # init\n",
    "        exception, agency_code, ticket_number, issue_date, payment, refund_legs, org_ticket_no, ticket_type = [], None, None, None, None, None, None, None\n",
    "        # DCI\n",
    "        exception, agency_code, ticket_number, issue_date = self.map_DCI(exception, DCI_json)\n",
    "        #check None\n",
    "        exception = check_None(DCI_json, 'DCI', exception)\n",
    "        exception = check_None(RFT_json, 'EXC', exception)\n",
    "        if len(exception) == 0:\n",
    "            # vars\n",
    "            # payment\n",
    "            payment = payment_json(self.bos_type, self.currency_code, RFT_json = RFT_json) # JSON. Example: [{\"mode\":\"CC\",\"type\":\"CCVI4000\",\"amount\":0.00,\"accountNumber\":\"VI************5960\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"USD\"}]\n",
    "\n",
    "            # refund_legs\n",
    "            refund_legs = refund_legs_json(RFT_json) # JSON. example: [{\"sequence\":1,\"ticketNumber\":\"0011259634355\",\"coupons\":\"1000\",\"issueDate\":\"2022-05-03\"}]\n",
    "\n",
    "            # org_ticket_no\n",
    "            org_ticket_no = RFT_json['RFT_L'][0]['RACN'] + RFT_json['RFT_L'][0]['RDNR'] # same as 1st ticketNumber from REFUND_LEGS\n",
    "\n",
    "        print('map_RFT')\n",
    "        print(ticket_number)\n",
    "\n",
    "        return exception, agency_code, ticket_number, issue_date, payment, refund_legs, org_ticket_no\n",
    "\n",
    "    def parser(self):\n",
    "        # init\n",
    "        exception, agency_code, ticket_number, issue_date, pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission, tax, fare_construction, legs, payment, refund_legs, org_ticket_no = [], None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None\n",
    "\n",
    "        ticket_type = 'RFND'\n",
    "\n",
    "        # Parser\n",
    "        DCI_json, RFT_json = self.split_RFT()\n",
    "\n",
    "        # Map\n",
    "        exception, agency_code, ticket_number, issue_date, payment, refund_legs, org_ticket_no =self.map_RFT(exception, DCI_json, RFT_json)\n",
    "        print('ticket_number')\n",
    "        print(ticket_number)\n",
    "\n",
    "        return exception, agency_code, ticket_number, issue_date, payment, refund_legs, org_ticket_no, ticket_type\n",
    "\n",
    "def BOS_parser(fn : BOS):\n",
    "    return fn.parser()\n",
    "\n",
    "def br_map(line):\n",
    "    # init\n",
    "    exception, agency_code, ticket_number, issue_date, pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission, tax, fare_construction, legs, payment, refund_legs, org_ticket_no, ticket_type = [], None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None\n",
    "\n",
    "    currency_code = \"USD\"\n",
    "\n",
    "    # split bos type\n",
    "    bos_type = line.split(\"\")[0]\n",
    "\n",
    "    # File Parser\n",
    "    if bos_type in (\"PAT\", \"PAX\", \"RFT\"):\n",
    "        if (bos_type in (\"PAT\", \"PAX\")):\n",
    "            bos_file_type = PATX(line, currency_code, bos_type)\n",
    "\n",
    "            # Parser\n",
    "            exception, agency_code, ticket_number, issue_date, pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission, tax, fare_construction, legs, payment, org_ticket_no, ticket_type = BOS_parser(bos_file_type)\n",
    "        elif (bos_type == 'RFT'):\n",
    "            bos_file_type = RFT(line, currency_code, bos_type)\n",
    "            exception, agency_code, ticket_number, issue_date, payment, refund_legs, org_ticket_no, ticket_type = BOS_parser(bos_file_type)\n",
    "\n",
    "    else:\n",
    "        ticket_type = bos_type\n",
    "\n",
    "    return {\n",
    "        \"exception\" : exception,  \\\n",
    "        \"source\" : \"BOS\", \\\n",
    "        \"booking_channel\" : \"WEB\", \\\n",
    "        \"version_no\" : 1, \\\n",
    "        \"ticket_type\" : ticket_type, \\\n",
    "        \"country_code\" : \"USA\",\\\n",
    "        \"passenger_count\" : 1,\n",
    "        \"currency_code\" : currency_code, \\\n",
    "        \"org_ticket_no\" : org_ticket_no, \\\n",
    "        \"agency_code\" : agency_code, \\\n",
    "        \"ticket_number\" : ticket_number, \\\n",
    "        \"issue_date\" : issue_date, \\\n",
    "        \"pnr\" : pnr, \\\n",
    "        \"tour_code\" : tour_code, \\\n",
    "        \"passenger_name\" : passenger_name, \\\n",
    "        \"coupon_used\" : coupon_used, \\\n",
    "        \"original_fare\" : original_fare, \\\n",
    "        \"fare_amount\" : fare_amount, \\\n",
    "        \"exchange_rate\" : exchange_rate, \\\n",
    "        \"commission_amount\" : commission_amount, \\\n",
    "        \"original_currency\" : original_currency, \\\n",
    "        \"tax_amount\" : tax_amount, \\\n",
    "        \"total_amount\" : total_amount, \\\n",
    "        \"commission\" : commission, \\\n",
    "        \"tax\" : tax, \\\n",
    "        \"fare_construction\" : fare_construction, \\\n",
    "        \"legs\" : legs, \\\n",
    "        \"payment\" : payment, \\\n",
    "        \"refund_legs\": refund_legs,\\\n",
    "        \"pos\" : \"1\"\n",
    "    }\n",
    "\n",
    "# schema\n",
    "schema = StructType([ \\\n",
    "    StructField(\"exception\", StringType(), True), \\\n",
    "    StructField(\"source\", StringType(), True), \\\n",
    "    StructField(\"booking_channel\", StringType(), True), \\\n",
    "    StructField(\"version_no\", IntegerType(), True), \\\n",
    "    StructField(\"ticket_type\", StringType(), True), \\\n",
    "    StructField(\"currency_code\", StringType(), True), \\\n",
    "    StructField(\"org_ticket_no\", StringType(), True), \\\n",
    "    StructField(\"agency_code\",StringType(),True), \\\n",
    "    StructField(\"ticket_number\",StringType(),True), \\\n",
    "    StructField(\"issue_date\",StringType(),True), \\\n",
    "    StructField(\"country_code\",StringType(),True), \\\n",
    "    StructField(\"passenger_count\",IntegerType(),True), \\\n",
    "    StructField(\"pnr\", StringType(), True), \\\n",
    "    StructField(\"tour_code\", StringType(), True), \\\n",
    "    StructField(\"passenger_name\", StringType(), True), \\\n",
    "    StructField(\"coupon_used\", StringType(), True), \\\n",
    "    StructField(\"original_fare\", DoubleType(), True), \\\n",
    "    StructField(\"fare_amount\", DoubleType(), True), \\\n",
    "    StructField(\"exchange_rate\", DoubleType(), True), \\\n",
    "    StructField(\"commission_amount\", DoubleType(), True), \\\n",
    "    StructField(\"original_currency\", IntegerType(), True), \\\n",
    "    StructField(\"tax_amount\", DoubleType(), True), \\\n",
    "    StructField(\"total_amount\", DoubleType(), True), \\\n",
    "    StructField(\"commission\", StringType(), True), \\\n",
    "    StructField(\"tax\", StringType(), True), \\\n",
    "    StructField(\"fare_construction\", StringType(), True), \\\n",
    "    StructField(\"legs\", StringType(), True), \\\n",
    "    StructField(\"payment\", StringType(), True), \\\n",
    "    StructField(\"refund_legs\", StringType(), True),\\\n",
    "    StructField(\"pos\", StringType(), True)\n",
    "  ])\n",
    "\n",
    "df = sparkDF.withColumn(\"bre_list\",udf(br_map, schema)(\"BOS_FILE_EXTRACT\"))\n",
    "df = df.withColumns({\n",
    "    \"exception\": df[\"bre_list\"][\"exception\"],\\\n",
    "    \"source\": df[\"bre_list\"][\"source\"],\\\n",
    "    \"booking_channel\": df[\"bre_list\"][\"booking_channel\"],\\\n",
    "    \"version_no\": df[\"bre_list\"][\"version_no\"],\\\n",
    "    \"ticket_type\": df[\"bre_list\"][\"ticket_type\"],\\\n",
    "    \"currency_code\": df[\"bre_list\"][\"currency_code\"],\\\n",
    "    \"org_ticket_no\": df[\"bre_list\"][\"org_ticket_no\"],\\\n",
    "    \"agency_code\": df[\"bre_list\"][\"agency_code\"],\\\n",
    "    \"ticket_number\": df[\"bre_list\"][\"ticket_number\"],\\\n",
    "    \"issue_date\": df[\"bre_list\"][\"issue_date\"],\\\n",
    "    \"pnr\": df[\"bre_list\"][\"pnr\"],\\\n",
    "    \"tour_code\": df[\"bre_list\"][\"tour_code\"],\\\n",
    "    \"passenger_name\": df[\"bre_list\"][\"passenger_name\"],\\\n",
    "    \"coupon_used\": df[\"bre_list\"][\"coupon_used\"],\\\n",
    "    \"original_fare\": df[\"bre_list\"][\"original_fare\"],\\\n",
    "    \"fare_amount\": df[\"bre_list\"][\"fare_amount\"],\\\n",
    "    \"exchange_rate\": df[\"bre_list\"][\"exchange_rate\"],\\\n",
    "    \"commission_amount\": df[\"bre_list\"][\"commission_amount\"],\\\n",
    "    \"original_currency\": df[\"bre_list\"][\"original_currency\"],\\\n",
    "    \"tax_amount\": df[\"bre_list\"][\"tax_amount\"],\\\n",
    "    \"total_amount\": df[\"bre_list\"][\"total_amount\"],\\\n",
    "    \"commission\": df[\"bre_list\"][\"commission\"],\\\n",
    "    \"tax\": df[\"bre_list\"][\"tax\"],\\\n",
    "    \"fare_construction\": df[\"bre_list\"][\"fare_construction\"],\\\n",
    "    \"legs\": df[\"bre_list\"][\"legs\"],\\\n",
    "    \"payment\": df[\"bre_list\"][\"payment\"],\\\n",
    "    \"refund_legs\": df[\"bre_list\"][\"refund_legs\"],\\\n",
    "    \"pos\": df[\"bre_list\"][\"pos\"]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RFTage 14:>                                                         (0 + 1) / 1]\n",
      "<class '__main__.RFT'>\n",
      "DCI_json\n",
      "{'VLNC': '22521623', 'BACN': '125', 'BDNR': '2161454822', 'DAIS': '17JUN23'}\n",
      "22521623\n",
      "DCI_Map\n",
      "1252161454822\n",
      "map_RFT\n",
      "1252161454822\n",
      "ticket_number\n",
      "1252161454822\n",
      "DCI_json\n",
      "{'VLNC': '22521623', 'BACN': '001', 'BDNR': '7976703339', 'DAIS': '17JUN23'}\n",
      "22521623\n",
      "DCI_Map\n",
      "0017976703339\n",
      "/var/folders/d9/871p0v1d2cn4c6y7bj_xghhh0000gn/T/ipykernel_2961/3275215194.py:113: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "leg_fare\n",
      "[{\"departure\": \"ORF\", \"destination\": \"DCA\", \"seatClass\": \"S\", \"conjunction\": \"0017976703339\", \"carrier\": \"AA\", \"tripCode\": \"5508\", \"departureOn\": \"2023-07-08\", \"designator\": \"SUAIZNN1\", \"stopOver\": \"X\", \"flyerCode\": \"\", \"fare\": \"0.00\", \"currency\": \"USD\", \"originalFare\": \"0.00\", \"originalCurrency\": \"USD\"}, {\"departure\": \"DCA\", \"destination\": \"GRR\", \"seatClass\": \"S\", \"conjunction\": \"0017976703339\", \"carrier\": \"AA\", \"tripCode\": \"5091\", \"departureOn\": \"2023-07-08\", \"designator\": \"SUAIZNN1\", \"stopOver\": \"\", \"flyerCode\": \"\", \"fare\": \"166.51\", \"currency\": \"USD\", \"originalFare\": \"166.51\", \"originalCurrency\": \"USD\"}]\n",
      "[]\n",
      "166.51\n",
      "DCI_json\n",
      "{'VLNC': '22521623', 'BACN': '074', 'BDNR': '2100377105', 'DAIS': '16JUN23'}\n",
      "22521623\n",
      "DCI_Map\n",
      "0742100377105\n",
      "leg_fare\n",
      "[{\"departure\": \"AMS\", \"destination\": \"MAD\", \"seatClass\": \"Q\", \"conjunction\": \"0742100377105\", \"carrier\": \"KL\", \"tripCode\": \"1701\", \"departureOn\": \"2023-06-24\", \"designator\": \"QH5UA5LG/XX\", \"stopOver\": \"O\", \"flyerCode\": \"\", \"fare\": \"119.12\", \"currency\": \"USD\", \"originalFare\": \"119.12\", \"originalCurrency\": \"USD\"}, {\"departure\": \"MAD\", \"destination\": \"AMS\", \"seatClass\": \"E\", \"conjunction\": \"0742100377105\", \"carrier\": \"KL\", \"tripCode\": \"1702\", \"departureOn\": \"2023-06-27\", \"designator\": \"EH5UA5LG\", \"stopOver\": \"O\", \"flyerCode\": \"\", \"fare\": \"97.52\", \"currency\": \"USD\", \"originalFare\": \"97.52\", \"originalCurrency\": \"USD\"}]\n",
      "[]\n",
      "216.64\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(bre_list=Row(exception='[]', source='BOS', booking_channel='WEB', version_no=1, ticket_type='RFND', currency_code='USD', org_ticket_no='1252161454822', agency_code='22521623', ticket_number='1252161454822', issue_date='2023-06-17', country_code='USA', passenger_count=1, pnr=None, tour_code=None, passenger_name=None, coupon_used=None, original_fare=None, fare_amount=None, exchange_rate=None, commission_amount=None, original_currency=None, tax_amount=None, total_amount=None, commission=None, tax=None, fare_construction=None, legs=None, payment='[{\"mode\": \"CA\", \"type\": \"CA\", \"amount\": \"-953.65\", \"accountNumber\": \"CASH\", \"approvalCode\": \"\", \"invoiceNumber\": \"\", \"currency\": \"USD\"}]', refund_legs='[{\"sequence\": 1, \"ticketNumber\": \"1252161454822\", \"coupons\": \"1234\", \"issueDate\": \"\"}]', pos='1')),\n Row(bre_list=Row(exception='[]', source='BOS', booking_channel='WEB', version_no=1, ticket_type='EXCH-TKTT', currency_code='USD', org_ticket_no='0017965804275', agency_code='22521623', ticket_number='0017976703339', issue_date='2023-06-17', country_code='USA', passenger_count=1, pnr='HNKNVK/AA', tour_code='', passenger_name='REDACTED SAL NAME', coupon_used='FFVV', original_fare=None, fare_amount=None, exchange_rate=1.0, commission_amount=None, original_currency=None, tax_amount=None, total_amount=None, commission='{\"type\": \"BASE\", \"amount\": \"1.00\", \"currency\": \"USD\", \"commissionRate\": \"0.60\"}', tax='[{\"type\": \"US\", \"amount\": \"12.49\", \"currency\": \"USD\"}, {\"type\": \"ZP\", \"amount\": \"9.60\", \"currency\": \"USD\"}, {\"type\": \"AY\", \"amount\": \"5.60\", \"currency\": \"USD\"}, {\"type\": \"XF\", \"amount\": \"9.00\", \"currency\": \"USD\"}]', fare_construction='[{\"sequence\": 1, \"content\": \"ORF AA X/WAS AA GRS166.51USD166.51END ZPORFDCA XFORF4.5DCA4.5\"}]', legs='[{fare=0.00, departureOn=2023-07-08, stopOver=X, destination=DCA, designator=SUAIZNN1, carrier=AA, conjunction=0017976703339, seatClass=S, originalFare=0.00, tripCode=5508, flyerCode=, currency=USD, departure=ORF, originalCurrency=USD}, {fare=166.51, departureOn=2023-07-08, stopOver=, destination=GRR, designator=SUAIZNN1, carrier=AA, conjunction=0017976703339, seatClass=S, originalFare=166.51, tripCode=5091, flyerCode=, currency=USD, departure=DCA, originalCurrency=USD}]', payment='[{\"mode\": \"CA\", \"type\": \"CA\", \"amount\": \"203.20\", \"accountNumber\": \"CASH\", \"approvalCode\": \"0017965804275212\", \"invoiceNumber\": \"\", \"currency\": \"USD\"}, {\"mode\": \"CA\", \"type\": \"CA\", \"amount\": \"25.00\", \"accountNumber\": \"CASH\", \"approvalCode\": \"0017965804275212\", \"invoiceNumber\": \"\", \"currency\": \"USD\"}]', refund_legs=None, pos='1')),\n Row(bre_list=Row(exception='[]', source='BOS', booking_channel='WEB', version_no=1, ticket_type='TKTT', currency_code='USD', org_ticket_no='0742100377105', agency_code='22521623', ticket_number='0742100377105', issue_date='2023-06-16', country_code='USA', passenger_count=1, pnr='UOAGUL', tour_code='ITAFKL', passenger_name='REDACTED SAL NAME', coupon_used='FFVV', original_fare=None, fare_amount=None, exchange_rate=1.0, commission_amount=None, original_currency=None, tax_amount=None, total_amount=None, commission='{\"type\": \"BASE\", \"amount\": \"0.00\", \"currency\": \"USD\", \"commissionRate\": \"0.00\"}', tax='[{\"type\": \"YR\", \"amount\": \"2.20\", \"currency\": \"USD\"}, {\"type\": \"CJ\", \"amount\": \"16.00\", \"currency\": \"USD\"}, {\"type\": \"RN\", \"amount\": \"22.50\", \"currency\": \"USD\"}, {\"type\": \"VV\", \"amount\": \"28.60\", \"currency\": \"USD\"}, {\"type\": \"JD\", \"amount\": \"15.70\", \"currency\": \"USD\"}, {\"type\": \"OG\", \"amount\": \"0.70\", \"currency\": \"USD\"}, {\"type\": \"QV\", \"amount\": \"3.50\", \"currency\": \"USD\"}]', fare_construction='[{\"sequence\": 1, \"content\": \"AMS KL MAD119.12KL AMS97.52NUC216.64END ROE0.907418XT22.50RN28.60VV15.70JD0.70OG3.50QV\"}]', legs='[{fare=119.12, departureOn=2023-06-24, stopOver=O, destination=MAD, designator=QH5UA5LG/XX, carrier=KL, conjunction=0742100377105, seatClass=Q, originalFare=119.12, tripCode=1701, flyerCode=, currency=USD, departure=AMS, originalCurrency=USD}, {fare=97.52, departureOn=2023-06-27, stopOver=O, destination=AMS, designator=EH5UA5LG, carrier=KL, conjunction=0742100377105, seatClass=E, originalFare=97.52, tripCode=1702, flyerCode=, currency=USD, departure=MAD, originalCurrency=USD}]', payment='[{\"mode\": \"CA\", \"type\": \"CA\", \"amount\": \"302.20\", \"accountNumber\": \"CASH\", \"approvalCode\": \"\", \"invoiceNumber\": \"\", \"currency\": \"USD\"}]', refund_legs=None, pos='1'))]"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('bre_list').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "'119.12'"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '[{\"departure\": \"AMS\", \"destination\": \"MAD\", \"seatClass\": \"Q\", \"conjunction\": \"0742100377105\", \"carrier\": \"KL\", \"tripCode\": \"1701\", \"departureOn\": \"2023-06-24\", \"designator\": \"QH5UA5LG/XX\", \"stopOver\": \"O\", \"flyerCode\": \"\", \"fare\": \"119.12\", \"currency\": \"USD\", \"originalFare\": \"119.12\", \"originalCurrency\": \"USD\"}, {\"departure\": \"MAD\", \"destination\": \"AMS\", \"seatClass\": \"E\", \"conjunction\": \"0742100377105\", \"carrier\": \"KL\", \"tripCode\": \"1702\", \"departureOn\": \"2023-06-27\", \"designator\": \"EH5UA5LG\", \"stopOver\": \"O\", \"flyerCode\": \"\", \"fare\": \"97.52\", \"currency\": \"USD\", \"originalFare\": \"97.52\", \"originalCurrency\": \"USD\"}]'\n",
    "\n",
    "re.findall(r'\\\"fare\\\"\\:\\s\\\"\\d+\\.\\d+', s)[0][9:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "'<\\x80\\x80\\x80\\x80\\x80953.65\\x800.00\\x800.00\\x80358.00\\x80595.65\\x800.00\\x800.00\\x800.00\\x800.00\\x80\\x80\\x80\\x81125\\x802161454822\\x801234\\x80<\\x82\\x80REDACTED REF NAME\\x80F\\x80-953.65\\x800.00\\x800.00\\x80\\x80-953.65\\x80CA\\x80CASH\\x80<'"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'RFT2252162320230618230618050933261252161454822417JUN23IARBA/D/ALLRECORDS/18JUN23103<953.650.000.00358.00595.650.000.000.000.0012521614548221234<REDACTED REF NAMEF-953.650.000.00-953.65CACASH<'\n",
    "re.search(r'<.+', s).group()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "k1 = sparkDF.withColumn('test', F.lit([{'123':789},{'456':890}]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "k2 = df.withColumns({'a':df['bre_list']['num'],'b':df['bre_list']['letters']})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  a|  b|\n",
      "+---+---+\n",
      "|123|456|\n",
      "|123|456|\n",
      "|123|456|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k2.select('a','b').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"test[123]\" due to data type mismatch: Parameter 2 requires the \"INTEGRAL\" type, however \"123\" has the type \"STRING\".;\n'Project [ROW_ID#12L, file_path#13, BOS_FILE_EXTRACT#14, COLUMN_DEF#15, test#26, test#26[123] AS a#94, test#26[456] AS b#95]\n+- Project [ROW_ID#12L, file_path#13, BOS_FILE_EXTRACT#14, COLUMN_DEF#15, array(123, 456) AS test#26]\n   +- LogicalRDD [ROW_ID#12L, file_path#13, BOS_FILE_EXTRACT#14, COLUMN_DEF#15], false\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[47], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m k3 \u001B[38;5;241m=\u001B[39m \u001B[43mk1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithColumns\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43ma\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mk1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m123\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mk1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m456\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/sql/dataframe.py:4737\u001B[0m, in \u001B[0;36mDataFrame.withColumns\u001B[0;34m(self, *colsMap)\u001B[0m\n\u001B[1;32m   4733\u001B[0m col_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(colsMap\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[1;32m   4734\u001B[0m cols \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(colsMap\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[1;32m   4736\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\n\u001B[0;32m-> 4737\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithColumns\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_to_seq\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcol_names\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jcols\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   4738\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession,\n\u001B[1;32m   4739\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/pyspark/lib/python3.8/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/anaconda3/envs/pyspark/lib/python3.8/site-packages/pyspark/errors/exceptions/captured.py:175\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    171\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 175\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"test[123]\" due to data type mismatch: Parameter 2 requires the \"INTEGRAL\" type, however \"123\" has the type \"STRING\".;\n'Project [ROW_ID#12L, file_path#13, BOS_FILE_EXTRACT#14, COLUMN_DEF#15, test#26, test#26[123] AS a#94, test#26[456] AS b#95]\n+- Project [ROW_ID#12L, file_path#13, BOS_FILE_EXTRACT#14, COLUMN_DEF#15, array(123, 456) AS test#26]\n   +- LogicalRDD [ROW_ID#12L, file_path#13, BOS_FILE_EXTRACT#14, COLUMN_DEF#15], false\n"
     ]
    }
   ],
   "source": [
    "k3 = k1.withColumns({'a':k1.test['123'],'b':k1.test['456']})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  a|  b|\n",
      "+---+---+\n",
      "|123|456|\n",
      "|123|456|\n",
      "|123|456|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k2.select('a','b').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}