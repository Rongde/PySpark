{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "Python_Glue_Session",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "pygments_lexer": "python3",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import csv\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.sql.functions import udf\n",
    "import re\n",
    "import time\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import length,col, explode, upper, to_date, date_sub, lag, coalesce, lit, array_sort, when, arrays_zip, size, date_format, explode_outer, from_json, concat, expr, array\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from operator import itemgetter\n",
    "import datetime, re, requests\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import concat, col, lit \n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "from schema import Schema"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# # read data from S3 to DataFrame\n",
    "# # input: S3\n",
    "# # output df['ROW_ID', 'BOS_FILE_EXTRACT', 'file_path', 'COLUMN_DEF']\n",
    "# def read_s3_to_df(day_path):\n",
    "#\n",
    "#     # parameter\n",
    "#     i = 0 # flag for initialize dataframe\n",
    "#\n",
    "#     # boto3 client\n",
    "#     s3 = boto3.client('s3')\n",
    "#     conn = client('s3')  # again assumes boto.cfg setup, assume AWS S3\n",
    "#\n",
    "#     # read data file by file\n",
    "#     for key in conn.list_objects(Bucket='bos-etl')['Contents']:\n",
    "#         path_key = key['Key']\n",
    "#         if path_key.endswith('cleansed'):\n",
    "#             if day_path in path_key:\n",
    "#                 file = s3.get_object(Bucket='bos-etl', Key=path_key)\n",
    "#                 txt = (file['Body'].read().decode('latin1'))\n",
    "#                 #st_re = txt.replace(\"\", \",\")\n",
    "#                 st_re_newline = txt.replace(\"!!! EOS !!!\", \"\\n\")\n",
    "#                 st_re_split = st_re_newline.split(\"\\n\")\n",
    "#                 df = pd.DataFrame(st_re_split)\n",
    "#                 df.index.name = 'ROW_ID'\n",
    "#                 df.rename({0:'BOS_FILE_EXTRACT'},axis='columns',inplace=True)\n",
    "#                 df[\"COLUMN_DEF\"]=df['BOS_FILE_EXTRACT'].replace(regex=r\"\\.*\",value=\"\")\n",
    "#                 rslt_dfRFT_temp = df[df['COLUMN_DEF'] =='PAX']\n",
    "#                 # rslt_dfRFT_temp = df\n",
    "#                 if ~rslt_dfRFT_temp.empty:\n",
    "#                     # print(path_key)\n",
    "#                     rslt_dfRFT_temp.insert(0,'file_path', path_key)\n",
    "#                     if (i ==0):\n",
    "#                         rslt_dfRFT = rslt_dfRFT_temp\n",
    "#                         i = 1\n",
    "#                     else:\n",
    "#                         rslt_dfRFT = pd.concat([rslt_dfRFT,rslt_dfRFT_temp])\n",
    "#     return rslt_dfRFT\n",
    "#\n",
    "#\n",
    "# # read data as DataFrame\n",
    "# #select day\n",
    "# day_path = 'date=2023-06-17'\n",
    "# # select current system day\n",
    "# # day_path = time.strftime('%Y-%m-%d')\n",
    "# rslt_dfRFT = read_s3_to_df(day_path)\n",
    "#\n",
    "# # test\n",
    "# #filter content\n",
    "# # check_list=['123','456']\n",
    "#\n",
    "# # for i in range():\n",
    "# #       rslt_dfRFT['BOS_FILE_EXTRACT'].filter(like=check_list[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# #test write to s3 csv\n",
    "# from io import StringIO\n",
    "# bucket = 'bos-etl' # already created on S3\n",
    "# csv_buffer = StringIO()\n",
    "# rslt_dfRFT.to_csv(csv_buffer)\n",
    "# s3_resource = boto3.resource('s3')\n",
    "# s3_resource.Object(bucket, 'write_back/df.csv').put(Body=csv_buffer.getvalue())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# read csv\n",
    "rslt_dfRFT = pd.read_csv(\"source/input/1_df_RFT_PAT_PAX.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from awsglue.transforms import *\n",
    "# from awsglue.utils import getResolvedOptions\n",
    "# from pyspark.context import SparkContext\n",
    "# from awsglue.context import GlueContext\n",
    "# from awsglue.job import Job\n",
    "#\n",
    "# ## @params: [JOB_NAME]\n",
    "# args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "#\n",
    "# sc = SparkContext()\n",
    "# glueContext = GlueContext(sc)\n",
    "# spark = glueContext.spark_session\n",
    "# job = Job(glueContext)\n",
    "# job.init(args['JOB_NAME'], args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Pyspark Dataframe\n",
    "from pyspark.sql import SparkSession\n",
    "#Create PySpark SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n",
    "#Create PySpark DataFrame from Pandas\n",
    "sparkDF=spark.createDataFrame(rslt_dfRFT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Split Raw Data\n",
    "\n",
    "def split_raw_data(sparkDF):\n",
    "    df1 = sparkDF.withColumn(\"split\", F.split(\"BOS_FILE_EXTRACT\", \"<\")).withColumn(\"ITI\", F.element_at(\"split\", 2)).withColumn(\"FAR\", F.element_at(\"split\", 3))\\\n",
    "    .withColumn(\"FOP_AND_FAR2\", F.element_at(\"split\", 4)).withColumn(\"END\", F.element_at(\"split\", 5)).withColumn(\"CER\", F.element_at(\"split\", 6))\\\n",
    "    .withColumn(\"EXC\", F.element_at(\"split\", 7))\\\n",
    "    .withColumn(\"split2\", F.split(\"BOS_FILE_EXTRACT\", \"<\")).withColumn(\"DCI\", F.element_at(\"split2\", 1)).withColumn(\"SAL\", F.element_at(\"split2\", 2))\\\n",
    "    .withColumn(\"EXS\", F.element_at(\"split2\", -1))\\\n",
    "    .withColumn(\"split3\", F.split(\"BOS_FILE_EXTRACT\", \"<\")).withColumn(\"TAX2\", F.element_at(\"split3\", 2))\\\n",
    "    .withColumn(\"split4\", F.split(\"BOS_FILE_EXTRACT\", \"<\")).withColumn(\"TAX1\", F.element_at(\"split4\", 2))\\\n",
    "    .withColumn(\"split5\", F.split(\"BOS_FILE_EXTRACT\", \"\")).withColumn(\"REF_LG\", F.element_at(\"split5\", 2))\n",
    "\n",
    "    split_df = df1.select(\"COLUMN_DEF\",\"DCI\",\"SAL\",\"TAX1\",\"TAX2\",\"ITI\",\"FAR\",\"FOP_AND_FAR2\",\"END\",\"CER\",\"EXC\",\"EXS\",split(df1.TAX1, '<').alias('split_text'),split(df1.FOP_AND_FAR2,'N<').alias(\"Splittext3\"),\"file_path\",\"TAX2\",\"REF_LG\")\n",
    "    split_df_type=split_df.selectExpr(\"column_def\",\"DCI\",\"SAL\",\"concat(split_text[0],',',TAX2) as TAX\",\"ITI\",\"FAR\", \"Case when column_def=='PAT' then FOP_AND_FAR2 else Splittext3[1] end as FOP_T\",\"Case when column_def=='PAT' then CER else END end as END_T\",\"Case when column_def=='PAT' then EXC else CER end as CER_T\",\"Case when column_def=='PAT' then '' else EXC end as EXC_T\",\"Case when column_def=='PAT' then '' else CER end as EXS_T\",\"file_path\",\"TAX2\",\"REF_LG\")\n",
    "\n",
    "    return split_df_type\n",
    "\n",
    "split_df_type = split_raw_data(sparkDF)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Custom\n",
    "# PAT/PAX/REF : transaction_date, source, booking_channel\n",
    "\n",
    "def fc_custom(data):\n",
    "\n",
    "    # var\n",
    "    transaction_date = current_timestamp() # <<File Generated Date>>\n",
    "    source = 'BOS' # BOS\n",
    "    booking_channel = 'WEB' # WEB\n",
    "    version_no = 1\n",
    "\n",
    "    # ticket_type\n",
    "    # line starts with PAT → ticket type = TKTT\n",
    "    #line starts with PAX→ ticket type = EXCH-TKTT\n",
    "    # line starts with RFT → ticket type = RFND\n",
    "\n",
    "    # insert var\n",
    "    data = data.withColumn('transaction_date', transaction_date)\\\n",
    "               .withColumn('source', F.lit(source)) \\\n",
    "               .withColumn('booking_channel', F.lit(booking_channel))\\\n",
    "               .withColumn('version_no', F.lit(version_no))\\\n",
    "               .withColumn('ticket_type', when(col('column_def') == 'PAT', 'TKTT').\\\n",
    "                                          when(col('column_def') == 'PAX', 'EXCH-TKTT').\\\n",
    "                                          when(col('column_def') == 'RFT', 'RFND').\\\n",
    "                                          otherwise(''))\n",
    "    return data\n",
    "\n",
    "bos_df_csv = fc_custom(split_df_type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(transaction_date=datetime.datetime(2023, 7, 28, 23, 0, 16, 686482), source='BOS', booking_channel='WEB', ticket_type='RFND', version_no=1),\n Row(transaction_date=datetime.datetime(2023, 7, 28, 23, 0, 16, 686482), source='BOS', booking_channel='WEB', ticket_type='EXCH-TKTT', version_no=1),\n Row(transaction_date=datetime.datetime(2023, 7, 28, 23, 0, 16, 686482), source='BOS', booking_channel='WEB', ticket_type='TKTT', version_no=1)]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv.select('column_def','transaction_date' , 'source', 'booking_channel', 'ticket_type','version_no').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# DCI\n",
    "# PAT/PAX/REF : agency_code, ticket_number, issue_date\n",
    "\n",
    "def fc_dci(DCI):\n",
    "\n",
    "    # split\n",
    "    DCI_split = DCI.split(\"\")\n",
    "    # print(DCI_split)\n",
    "\n",
    "    # var\n",
    "    agency_code = DCI_split[1] # 2nd field from 1st group (VLNC-DCI)\n",
    "    ticket_number = DCI_split[4] + DCI_split[5] # 5th field + 6th field from 1st group (BACN-DCI+ BDNR-DCI)\n",
    "    issue_date = datetime.strptime(DCI_split[7],'%d%b%y').strftime(\"%Y-%m-%d\") # 8th field from 1st group (DAIS-DCI). Field is reported as YYMMDD\n",
    "\n",
    "    return [agency_code, ticket_number, issue_date]\n",
    "\n",
    "fc_dci = udf(fc_dci, ArrayType(StringType()))\n",
    "fc_dci_list = fc_dci('SAL')\n",
    "bos_df_csv = bos_df_csv.withColumn('agency_code', fc_dci_list[0])\\\n",
    "                        .withColumn('ticket_number', fc_dci_list[1])\\\n",
    "                        .withColumn('issue_date', fc_dci_list[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------+\n",
      "|agency_code|ticket_number|issue_date|\n",
      "+-----------+-------------+----------+\n",
      "|   22521623|1252161454822|2023-06-17|\n",
      "|   22521623|0017976703339|2023-06-17|\n",
      "|   22521623|0742100377105|2023-06-16|\n",
      "+-----------+-------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['PAX', '22521623', '20230618', '23061805093326', '001', '7976703339', '0', '17JUN23', '', 'IAR', 'BA/D/ALLRECORDS/18JUN23', '103', '']\n",
      "['RFT', '22521623', '20230618', '23061805093326', '125', '2161454822', '4', '17JUN23', '', 'IAR', 'BA/D/ALLRECORDS/18JUN23', '103', '']\n",
      "['PAT', '22521623', '20230618', '23061805093326', '074', '2100377105', '3', '16JUN23', '', 'IAR', 'BA/D/ALLRECORDS/18JUN23', '103', '']\n"
     ]
    }
   ],
   "source": [
    "bos_df_csv.select('column_def','agency_code','ticket_number','issue_date').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "# SAL\n",
    "# PAT/PAX :\n",
    "\n",
    "def fc_sal(SAL, column_def):\n",
    "\n",
    "    # split\n",
    "    print(SAL)\n",
    "    SAL_split = SAL.split(\"\")\n",
    "    print(SAL_split)\n",
    "\n",
    "    # var\n",
    "    pnr = SAL_split[14] if column_def != 'RFT' else None # 15th field from 2nd group (PNRR-SAL). Note: it will be empty for RFND.\n",
    "    tour_code = SAL_split[16] if column_def != 'RFT' else None # 17th field from 2nd group (TOUR-SAL). Note: it will be empty for RFND.\n",
    "    passenger_name = SAL_split[15] if column_def != 'RFT' else None # 16th field from 2nd group (PXNM-SAL) for non-RFND.\n",
    "    coupon_used = SAL_split[15] if column_def != 'RFT' else None # 7th field from 2nd group (CPUI-SAL) for non-RFND\n",
    "    original_fare = SAL_split[8] if column_def != 'RFT' else None # 9th field from 2nd group\n",
    "\n",
    "    fare_amount = None\n",
    "    exchange_rate = None\n",
    "    commission_amount = None\n",
    "    commission = None\n",
    "    if column_def != 'RFT':\n",
    "        fare_amount = SAL_split[10] if SAL_split[10] != '0.00' else original_fare # 11th field from 2nd group (EQFR-SAL)… Note: if is 0.00, use the same as ORIGINAL_FARE\n",
    "\n",
    "        exchange_rate = round(float(fare_amount) / float(original_fare),2) if original_fare != '0.00' else None # FARE_AMOUNT / ORIGINAL_FARE\n",
    "        commission_amount = fare_amount # same as FARE_AMOUNT\n",
    "\n",
    "        # commission\n",
    "        #JSON. Example: [{\"type\":\"BASE\",\"amount\":4.26,\"currency\":\"CAD\",\"commissionRate\":3.0}]\n",
    "        #               amount: 13th field from 2nd group (COAM-SAL)\n",
    "        #               commissionRate: 14th field from 2nd group (CORT-SAL)\n",
    "        amount = SAL_split[12]\n",
    "        commissionRate = SAL_split[13]\n",
    "        commission = '[{' + f'\"type\":\"BASE\",\"amount\":{amount},\"currency\":\"CAD\",\"commissionRate\":{commissionRate}' + '}]'\n",
    "\n",
    "    original_currency = SAL_split[9] if column_def != 'RFT' else None# 10th field from 2nd group (CUOF-SAL)\n",
    "    tax_amount = SAL_split[11] if column_def != 'RFT' else None # 12th field from 2nd group (TTAX-SAL)\n",
    "    total_amount = SAL_split[7] if column_def != 'RFT' else None # 8th field from 2nd group (TDAM-SAL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return [pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission]\n",
    "\n",
    "fc_sal = udf(fc_sal, ArrayType(StringType()))\n",
    "fc_sal_list = fc_sal('SAL', 'column_def')\n",
    "bos_df_csv2 = bos_df_csv.withColumn('pnr', fc_sal_list[0])\\\n",
    "                        .withColumn('tour_code', fc_sal_list[1])\\\n",
    "                        .withColumn('passenger_name', fc_sal_list[2])\\\n",
    "                        .withColumn('coupon_used', fc_sal_list[3])\\\n",
    "                        .withColumn('original_fare', fc_sal_list[4])\\\n",
    "                        .withColumn('fare_amount', fc_sal_list[5])\\\n",
    "                        .withColumn('exchange_rate', fc_sal_list[6])\\\n",
    "                        .withColumn('commission_amount', fc_sal_list[7])\\\n",
    "                        .withColumn('original_currency', fc_sal_list[8])\\\n",
    "                        .withColumn('tax_amount', fc_sal_list[9])\\\n",
    "                        .withColumn('total_amount', fc_sal_list[10])\\\n",
    "                        .withColumn('commission', fc_sal_list[11])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FFVV302.20213.00USD0.0089.200.000.00UOAGULREDACTED SAL NAMEITAFKL0005WS0744/70X00\n",
      "['', '', '', '', '', '', 'FFVV', '302.20', '213.00', 'USD', '0.00', '89.20', '0.00', '0.00', 'UOAGUL', 'REDACTED SAL NAME', 'ITAFKL', '', '0005WS', '0744', '/', '', '7', '', '', '0', 'X', '', '00', '']\n",
      "953.650.000.00358.00595.650.000.000.000.0012521614548221234\n",
      "['', '', '', '', '', '953.65', '0.00', '0.00', '358.00', '595.65', '0.00', '0.00', '0.00', '0.00', '', '', '\\x81125', '2161454822', '1234', '']\n",
      "FFVV203.20166.51USD0.0036.691.000.60HNKNVK/AAREDACTED SAL NAME0011/Y000\n",
      "['', '', '', '', '', '', 'FFVV', '203.20', '166.51', 'USD', '0.00', '36.69', '1.00', '0.60', 'HNKNVK/AA', 'REDACTED SAL NAME', '', '', '', '0011', '/', '', 'Y', '', '', '0', '', '', '00', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(column_def='RFT', pnr=None, tour_code=None, passenger_name=None, original_fare=None, fare_amount=None, exchange_rate=None, commission_amount=None, original_currency=None, tax_amount=None, total_amount=None, commission=None),\n Row(column_def='PAX', pnr='HNKNVK/AA', tour_code='', passenger_name='REDACTED SAL NAME', original_fare='166.51', fare_amount='166.51', exchange_rate='1.0', commission_amount='166.51', original_currency='USD', tax_amount='36.69', total_amount='203.20', commission='[{\"type\":\"BASE\",\"amount\":1.00,\"currency\":\"CAD\",\"commissionRate\":0.60}]'),\n Row(column_def='PAT', pnr='UOAGUL', tour_code='ITAFKL', passenger_name='REDACTED SAL NAME', original_fare='213.00', fare_amount='213.00', exchange_rate='1.0', commission_amount='213.00', original_currency='USD', tax_amount='89.20', total_amount='302.20', commission='[{\"type\":\"BASE\",\"amount\":0.00,\"currency\":\"CAD\",\"commissionRate\":0.00}]')]"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv2.select('column_def','pnr','tour_code', 'passenger_name', 'original_fare', 'fare_amount','exchange_rate','commission_amount','original_currency','tax_amount','total_amount','commission').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# FTS - 2610  Commision: \"CAD\" - > \"USD\"\n",
    "# input: Dataframe\n",
    "# output: ['Transaction_Date','Source','Booking_channel','DCI_split','DCI','Agency_code',]\n",
    "\n",
    "def split_col(split_df_type):\n",
    "    data=split_df_type.withColumn(\"Transaction_Date\",current_timestamp()).withColumn(\"Source\",F.lit('BOS')).withColumn(\"Booking_channel\",F.lit('WEB')).withColumn(\"DCI_split\", F.split(\"DCI\", \"\")).withColumn(\"Agency_code\", F.element_at(\"DCI_split\", 2)).withColumn(\"Ticket_No\", concat(F.element_at(\"DCI_split\", 5),F.element_at(\"DCI_split\", 6))).withColumn(\"Issue_Date\", F.to_date(F.element_at(\"DCI_split\", 8),\"ddMMMyy\"))\\\n",
    "    .withColumn(\"SAL_split\", F.split(\"SAL\", \"\")).withColumn(\"PNR\", F.element_at(\"SAL_split\", 15)).withColumn(\"Tour_code\", F.regexp_replace(F.element_at(\"SAL_split\", 17),'','')).withColumn(\"Passenger\", F.element_at(\"SAL_split\", 16)).withColumn(\"Coupon_used\", F.element_at(\"SAL_split\", 7)).withColumn(\"Original_Fare\", F.element_at(\"SAL_split\", 9)).withColumn(\"Fare\", F.element_at(\"SAL_split\", 11)).withColumn(\"Org_currency\", F.element_at(\"SAL_split\", 10)).withColumn(\"Tax_Amt\", F.element_at(\"SAL_split\", 12)).withColumn(\"Total_amt\", F.element_at(\"SAL_split\", 8))\\\n",
    "    .withColumn(\"ITI_split\", F.split(\"ITI\", \"<\"))\\\n",
    "    .withColumn(\"Leg2\", F.element_at(\"ITI_split\", 13)).withColumn(\"Leg3\", F.element_at(\"ITI_split\", 22)).withColumn(\"Leg4\", F.element_at(\"ITI_split\", 31))\\\n",
    "    .withColumn(\"FOP_split\", F.split(\"FOP_T\", \"\"))\\\n",
    "    .withColumn(\"TAX_split\", F.split(\"tax\", \"<\"))\\\n",
    "    .withColumn(\"Commission\", concat(F.lit('[{\"type\":\"BASE\",\"amount\":'),F.element_at(\"SAL_split\", 13),f.lit(',\"currency\":\"USD\",\"commissionRate\":'),F.element_at(\"SAL_split\", 14),f.lit('}]')))\\\n",
    "    .withColumn(\"Fare_split\", F.split(\"FAR\", \"<\")).withColumn(\"FOP_split\", F.split(\"FOP_T\", \"<\")).withColumn(\"SAL2_split\", F.split(\"TAX2\", \"\")).withColumn(\"Passenger_rfnd\", F.element_at(\"SAL2_split\", 2))\n",
    "\n",
    "    return data\n",
    "\n",
    "bos_df = split_col(split_df_type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# # df2.write.options\n",
    "# split_df_type.coalesce(1).write.format('csv').option('header','true').mode(\"overwrite\").save(\"s3://bos-etl/write_back/\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "### FTS - 2607\n",
    "bos_df_csv=bos_df.selectExpr(\"ITI_split\",\"column_def\",\"Transaction_Date\",\"Agency_code\",\"'06.07_DCALLRECORDSAM' as Filename\",\"Source\",\"Booking_channel\",\"case when column_def=='PAX' then 'EXCH-TKTT' when column_def=='PAT' then 'TKTT' else 'RFND' end as ticket_type\", \"1 as version_no\",\"Ticket_No\",\"Issue_date\",\"PNR\",\"Tour_code\",\"case when column_def=='RFT' then passenger_rfnd else Passenger end as Passenger_name\",\"1 as Passenger_Count\",\"Coupon_used\",\"'USA' AS Country_code\",\"Original_Fare\",\"case when Fare==0 then original_fare else fare end as Fare_amt\",\"Org_currency\",\"round((case when Fare==0 then original_fare else fare end)/Original_Fare,3) as exch_rate\",\"case when Fare==0 then original_fare else fare end as comm_amt\",\"Tax_Amt\",\"Total_amt\",\"'USD' as curr_code\",\"ticket_no as org_ticket_no\",\"Commission\",\"TAX_split\",\"FOP_split\",\"Fare_split\",\"file_path\",\"REF_LG\",\"SAL2_split\",\"EXC_T\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(column_def='RFT', DCI='RFT\\x8022521623\\x8020230618\\x8023061805093326\\x80125\\x802161454822\\x804\\x8017JUN23\\x80\\x80IAR\\x80BA/D/ALLRECORDS/18JUN23\\x80103\\x80', SAL='\\x80\\x80\\x80\\x80\\x80953.65\\x800.00\\x800.00\\x80358.00\\x80595.65\\x800.00\\x800.00\\x800.00\\x800.00\\x80\\x80\\x80\\x81125\\x802161454822\\x801234\\x80', TAX=None, ITI=None, FAR=None, FOP_T=None, END_T=None, CER_T=None, EXC_T=None, EXS_T=None, file_path='data/date=2023-06-17/DCALLRECORDSAM.pgp.asc_3e5155823ea22a963da362086c693cf3_cleansed', TAX2='\\x80REDACTED REF NAME\\x80F\\x80-953.65\\x800.00\\x800.00\\x80\\x80-953.65\\x80CA\\x80CASH\\x80<\\x83', REF_LG='125\\x802161454822\\x801234\\x80<\\x82\\x80REDACTED REF NAME\\x80F\\x80-953.65\\x800.00\\x800.00\\x80\\x80-953.65\\x80CA\\x80CASH\\x80<\\x83', Transaction_Date=datetime.datetime(2023, 7, 28, 16, 37, 42, 198614), Source='BOS', Booking_channel='WEB', DCI_split=['RFT', '22521623', '20230618', '23061805093326', '125', '2161454822', '4', '17JUN23', '', 'IAR', 'BA/D/ALLRECORDS/18JUN23', '103', ''], Agency_code='22521623', Ticket_No='1252161454822', Issue_Date=datetime.date(2023, 6, 17), SAL_split=['', '', '', '', '', '953.65', '0.00', '0.00', '358.00', '595.65', '0.00', '0.00', '0.00', '0.00', '', '', '\\x81125', '2161454822', '1234', ''], PNR='', Tour_code='125', Passenger='', Coupon_used='0.00', Original_Fare='358.00', Fare='0.00', Org_currency='595.65', Tax_Amt='0.00', Total_amt='0.00', ITI_split=None, Leg2=None, Leg3=None, Leg4=None, FOP_split=None, TAX_split=None, Commission='[{\"type\":\"BASE\",\"amount\":0.00,\"currency\":\"USD\",\"commissionRate\":0.00}]', Fare_split=None, SAL2_split=['', 'REDACTED REF NAME', 'F', '-953.65', '0.00', '0.00', '', '-953.65', 'CA', 'CASH', '<\\x83'], Passenger_rfnd='REDACTED REF NAME')]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df.head(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# BOS - 116 RFT\n",
    "def fc_Ref(Fare_amt, column_def, Original_Fare, Tax_Amt, Org_currency,Total_amt):\n",
    "    if column_def == 'RFT':\n",
    "        #RFT fare_amount commission_amount: 9th field from REF * (-1)\n",
    "        Fare_amt = float(Original_Fare) * -1\n",
    "\n",
    "        #RFT tax_amount: 10th field from REF * (-1)\n",
    "        Tax_Amt = float(Org_currency) * -1\n",
    "\n",
    "        #RFT total_amount: 8th field from REF * (-1)\n",
    "        Total_amt = float(Total_amt) * -1\n",
    "\n",
    "    return [Fare_amt, Tax_Amt, Total_amt]\n",
    "\n",
    "fc_Ref = udf(fc_Ref, ArrayType(StringType()))\n",
    "fc_Ref_list = fc_Ref('Fare_amt', 'column_def', 'Original_Fare','Tax_Amt','Org_currency','Total_amt')\n",
    "bos_df_csv = bos_df_csv.withColumn('Fare_amt', fc_Ref_list[0])\\\n",
    "                        .withColumn('Tax_Amt', fc_Ref_list[1])\\\n",
    "                        .withColumn('Total_amt', fc_Ref_list[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+---------+\n",
      "|Fare_amt|Tax_Amt|Total_amt|\n",
      "+--------+-------+---------+\n",
      "|  -358.0|-595.65|     -0.0|\n",
      "|  166.51|  36.69|   203.20|\n",
      "|  213.00|  89.20|   302.20|\n",
      "+--------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bos_df_csv.select('Fare_amt', 'Tax_Amt', 'Total_amt').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# FTS - 2609\n",
    "def fc_Fare(li, column_def):\n",
    "    fare_v = ''\n",
    "    fare = ''\n",
    "    fare_end_v = ''\n",
    "    if column_def != 'RFT':\n",
    "        fare_v = ''\n",
    "        if li is not None:\n",
    "            # FTS - 2609\n",
    "            fare_end_v = ''\n",
    "            fare_v = '['\n",
    "            i = 0\n",
    "            # print (fare_v)\n",
    "            for ii in li:\n",
    "                i = i + 1\n",
    "                ii_split = ii.split(\"\")\n",
    "\n",
    "                if i > 1:\n",
    "                    fare_v = fare_v + ',{\"sequence\":' + str(i) + ',\"content\":\"' + ii_split[0] + '\"}'\n",
    "                    fare = fare + ',' + ii_split[0]\n",
    "                else:\n",
    "                    fare_v = fare_v + '{\"sequence\":' + str(i) + ',\"content\":\"' + ii_split[0] + '\"}'\n",
    "                    fare = ii_split[0]\n",
    "            fare_v = fare_v + ']'\n",
    "        # FTS - 2609 spilt by \"END\" + \" \"\n",
    "        # fare_split = fare.split(\" \")\n",
    "        fare_split = fare.split(\"END\" + \" \")[0].split(\" \")\n",
    "        # print(fare_split)\n",
    "\n",
    "        for element in fare_split:\n",
    "            # FTS - 2609 add ~(element.startswith(\"Q\") & element[1].isdigit())\n",
    "            # if element.endswith(\"END\"):\n",
    "            if len(element) > 1:\n",
    "                if (False if (element.startswith(\"Q\") & element[1].isdigit()) else True):\n",
    "                    # FTS - 2609 list -> str\n",
    "                    fare_end_v = fare_end_v + element\n",
    "\n",
    "    return [fare_v, fare, fare_end_v]\n",
    "\n",
    "fc_Fare = udf(fc_Fare, ArrayType(StringType()))\n",
    "fc_Fare_list = fc_Fare('Fare_split', 'column_def')\n",
    "bos_df_csv = bos_df_csv.withColumn('Fare_Cons', fc_Fare_list[0])\\\n",
    "    .withColumn(\"Fare\", fc_Fare_list[1]).withColumn(\"Fare_end\",fc_Fare_list[2]).withColumn(\"Fare_split\", F.split(\"Fare\", \" \"))\n"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|           Fare_Cons|            Fare_end|          Fare_split|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|                    |                    |                  []|\n",
      "|[{\"sequence\":1,\"c...|ORFAAX/WASAAGRR16...|[ORF, AA, X/WAS, ...|\n",
      "|[{\"sequence\":1,\"c...|AMSKLMAD119.12KLA...|[AMS, KL, MAD119....|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bos_df_csv.select('Fare_Cons', \"Fare_end\", \"Fare_split\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# FTS - 2607\n",
    "# tax\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "def fc(li, column_def):\n",
    "    tax_v = ''\n",
    "    if column_def != 'RFT':\n",
    "        tax_v =''\n",
    "        if li is not None:\n",
    "            #print(li)\n",
    "            tax_v ='['\n",
    "            i=0\n",
    "            for ii in li:\n",
    "                ii_split = ii.split(\",\")\n",
    "                # FTS 2607 Bug 2 & 3 : filter string which not start with digit\n",
    "                ii_split = [x for x in ii_split if x[0].isdigit()]\n",
    "                #print(ii_split)\n",
    "                for i1 in ii_split:\n",
    "                    i=i+1\n",
    "                    i1_split = i1.split(\"\")\n",
    "                    #print(i1_split)\n",
    "                    if i>1:\n",
    "                        # FTS-2607 Bug 1\n",
    "                        tax_v = tax_v+ ',{\"type\":\"'+ i1_split[1] +'\",\"amount\":'+i1_split[0] +',\"currency\":\"' +  \"Org_currency\" + '\"}'\n",
    "                    else:\n",
    "                        # FTS-2607 Bug 1\n",
    "                        tax_v = tax_v+ '{\"type\":\"'+ i1_split[1] +'\",\"amount\":'+i1_split[0] +',\"currency\":\"' +   \"Org_currency\" + '\"}'\n",
    "            tax_v=tax_v+']'\n",
    "    return tax_v\n",
    "\n",
    "fc = udf(fc, StringType())\n",
    "bos_df_csv = bos_df_csv.withColumn('Tax_v', fc('TAX_split', 'column_def'))\n",
    "bos_df_csv=bos_df_csv.selectExpr(\"ITI_split\",\"Fare_end\",\"column_def\",\"Transaction_Date\",\"Agency_code\",\"Filename\",\"Source\",\"Booking_channel\",\"ticket_type\", \"version_no\",\"Ticket_No\",\"Issue_date\",\"PNR\",\"Tour_code\",\"Passenger_name\",\"Passenger_Count\",\"Coupon_used\",\"Country_code\",\"Original_Fare\",\"Fare_amt\",\"Org_currency\",\"exch_rate\",\"comm_amt\",\"Tax_Amt\",\"Total_amt\",\"curr_code\",\"org_ticket_no\",\"Commission\",\"Fare_Cons\",\"case when column_def !='RFT' then replace(Tax_v,'Org_currency',Org_currency) end as Tax\",'FOP_split',\"file_path\",\"REF_LG\",\"SAL2_split\",\"EXC_T\")"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# FTS - 2606\n",
    "# PAT - FOP : payment\n",
    "# PAX - EXC : payment\n",
    "def fc_FOP(FOP_split, column_def):\n",
    "    fop_v =''\n",
    "    if column_def == 'PAT' :\n",
    "        if FOP_split is not None:\n",
    "            fop_v =''\n",
    "            i=0\n",
    "            for ii in FOP_split:\n",
    "                ii_split = ii.split(\",\")\n",
    "                for i1 in ii_split:\n",
    "                    i1_split = i1.split(\"\") #FOP\n",
    "                    mode = i1_split[0][:2] # 1st field of the loop from 7th group (FPTP-FOP). Use only the first 2 chars\n",
    "                    type1 = i1_split[0] # 1st field of the loop from 7th group (FPTP-FOP)\n",
    "                    amount = i1_split[5] # 6th field of the loop from 7th group (FPAM-FOP)\n",
    "                    accountNumber = i1_split[1] # 2nd field of the loop from 7th group (FPAC-FOP)\n",
    "                    approvalCode = i1_split[4] # 5th field of the loop from 7th group (APLC-FOP)\n",
    "                    invoiceNumber = '' # <empty>\n",
    "                    currency = \"USD\" # same as CURRENCY_CODE “USD”\n",
    "\n",
    "                    s = ',' if i != 0 else '['\n",
    "                    fop_v = fop_v + s + '{'  + f'\"mode\":\"{mode}\",\"type\":\"{type1}\",\"amount\":{amount},\"accountNumber\":\"{accountNumber}\",\"approvalCode\":\"{approvalCode}\",\"invoiceNumber\":\"{invoiceNumber}\",\"currency\":\"{currency}\"' + '}'\n",
    "\n",
    "                    i=i+1\n",
    "\n",
    "            fop_v = fop_v+']'\n",
    "\n",
    "    return [fop_v]\n",
    "\n",
    "fc_FOP = udf(fc_FOP, ArrayType(StringType()))\n",
    "fc_FOP_list = fc_FOP('FOP_split', \"column_def\")\n",
    "bos_df_csv2 = bos_df_csv.withColumn('FOP', fc_FOP_list[0])\n",
    "bos_df_csv2=bos_df_csv2.selectExpr(\"ITI_split\",\"Fare_end\",\"column_def\",\"Transaction_Date\",\"Agency_code\",\"Filename\",\"Source\",\"Booking_channel\",\"ticket_type\", \"version_no\",\"Ticket_No\",\"Issue_date\",\"PNR\",\"Tour_code\",\"Passenger_name\",\"Passenger_Count\",\"Coupon_used\",\"Country_code\",\"Original_Fare\",\"Fare_amt\",\"Org_currency\",\"exch_rate\",\"comm_amt\",\"Tax_Amt\",\"Total_amt\",\"curr_code\",\"org_ticket_no\",\"Commission\",\"Fare_Cons\",\"Tax\",\"FOP\",\"file_path\",\"REF_LG\",\"SAL2_split\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(Fop='', column_def='RFT'),\n Row(Fop='', column_def='PAX'),\n Row(Fop='[{\"mode\":\"CA\",\"type\":\"CA\",\"amount\":302.20,\"accountNumber\":\"CASH\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"USD\"}]', column_def='PAT')]"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv2.select('Fop','column_def').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "# FTS - 2608 rewrtie function\n",
    "# FTS - 2608 \"currency\": \"CAD\" -> \"currency\": \"USD\"\n",
    "def fc_LEG(li, fare_row, ticket_no, issue_date, column_def):\n",
    "    leg_v =''\n",
    "    attributes = ''\n",
    "    if column_def != 'RFT':\n",
    "        if re.match(r'^\\d{4}-\\d{2}-\\d{2}$',str(issue_date)):\n",
    "            issue_year = issue_date.year\n",
    "            issue_date = issue_date.strftime('%Y-%m-%d')\n",
    "            leap_year = '2024' # not use this value just avoid error from strptime\n",
    "            if li is not None:\n",
    "                #print(li)\n",
    "                leg_v ='[' # segment 1\n",
    "                leg_v_1 = '[' #segment 2\n",
    "                # i=0\n",
    "                # FTS - 2608\n",
    "                i = 0\n",
    "                j = 1 # index of fare , max len 2\n",
    "                fareval = []\n",
    "                if (len(li) > 1): # if two segment, reverse, direction right to left\n",
    "                    li.reverse()\n",
    "                    i = 3\n",
    "                for ii in li:\n",
    "                    ii_split = ii.split(\",\")\n",
    "                    #print(ii_split)\n",
    "                    for i1 in ii_split:\n",
    "                        fareval = re.findall(r'\\d+.\\d+', str(fare_row))\n",
    "                        if len(fareval)==0:\n",
    "                            total_fareval = '0.00'\n",
    "                            fareval=['0.00','0.00','0.00','0.00']\n",
    "                        else:\n",
    "                            total_fareval = fareval[-1]\n",
    "                            fareval = fareval[:-1]\n",
    "                        #print(fareval)\n",
    "                        i = i - 1 # reverse\n",
    "                        i1_split = i1.split(\"\")\n",
    "                        if len(i1_split[0])!=0:\n",
    "                            conj= ticket_no[0:3] + i1_split[0]\n",
    "                        else:\n",
    "                            conj='CONJ'\n",
    "\n",
    "                        if i>1:\n",
    "                           if len(i1_split[30])!=0:\n",
    "                                if len(i1_split[35])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[35] +  leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(   issue_year)    + 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[35]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[29]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "                                leg_v_1 = ',{\"departure\":\"'+ i1_split[30] +'\",\"destination\":\"'+i1_split[31]         +'\",\"seatClass\":\"' +  i1_split[34] +'\",\"conjunction\":\"'+  conj      +'\",\"carrier\":\"'+i1_split[32]+'\",\"tripCode\":\"'+i1_split[    33]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[   37]+'\",\"stopOver\":\"'+i1_split[   29]+'\",\"flyerCode\":\"\",\"fare\":'+ fare +    ',\"currency\": \"USD\",\"originalFare\":'+ fare     +',\"originalCurrency\":\"'+'org_currency'+'\"}'\n",
    "\n",
    "                           if len(i1_split[21])!=0:\n",
    "                                if len(i1_split[26])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[26] +  leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(   issue_year)    + 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[26]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[20]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "                                leg_v_1 = '' if leg_v_1 == '[' else leg_v_1\n",
    "                                leg_v_1 = ',{\"departure\":\"'+ i1_split[21] +'\",\"destination\":\"'+i1_split[22]         +'\",\"seatClass\":\"' + i1_split[25] +'\",\"conjunction\":\"'+  conj       +'\",\"carrier\":\"'+i1_split[23]+'\",\"tripCode\":\"'+i1_split[    24]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[  28]+'\",\"stopOver\":\"'+i1_split[    20]+'\",\"flyerCode\":\"\",\"fare\":'+ fare    +',\"currency\": \"USD\",\"originalFare\":'+ fare        +',\"originalCurrency\":\"'+'org_currency'+'\"}' + leg_v_1\n",
    "\n",
    "                           if len(i1_split[12])!=0:\n",
    "                                if len(i1_split[17])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[17] +  leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(   issue_year)    + 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[17]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[11]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "                                leg_v_1 = '' if leg_v_1 == '[' else leg_v_1\n",
    "                                leg_v_1 = ',{\"departure\":\"'+ i1_split[12] +'\",\"destination\":\"'+i1_split[13]         +'\",\"seatClass\":\"' + i1_split[16] +'\",\"conjunction\":\"'+  conj       +'\",\"carrier\":\"'+i1_split[14]+'\",\"tripCode\":\"'+i1_split[    15]+'\",\"departureOn\":\"'+ dep_on+'\",\"designator\":\"'+i1_split[  19]+'\",\"stopOver\":\"'+i1_split[    11]+'\",\"flyerCode\":\"\",\"fare\":'+ fare    +',\"currency\": \"USD\",\"originalFare\":'+ fare        +',\"originalCurrency\":\"'+'org_currency'+'\"}' + leg_v_1\n",
    "\n",
    "                           if len(i1_split[3])!=0:\n",
    "                                if len(i1_split[8])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[8] +   leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(   issue_year)    + 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[8]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[2]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "\n",
    "                                leg_v_1 = '' if leg_v_1 == '[' else leg_v_1\n",
    "                                leg_v_1 = ',{\"departure\":\"'+ i1_split[3] +'\",\"destination\":\"'+i1_split[4]       +'\",\"seatClass\":\"' + i1_split[7] +'\",\"conjunction\":\"'+  conj    +'\",\"carrier\":\"'+i1_split[5]+'\",\"tripCode\":\"'+i1_split[6]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[  10]+'\",\"stopOver\":\"'+i1_split[ 2]+'\",\"flyerCode\":\"\",\"fare\":'+ fare +',\"currency\":     \"USD\",\"originalFare\":'+ fare  +',\"originalCurrency\":\"'+'org_currency'+'\"}' +    leg_v_1\n",
    "\n",
    "                        else:\n",
    "                            if len(i1_split[30])!=0:\n",
    "                                if len(i1_split[35])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[35] +  leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(issue_year)+ 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[35]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[29]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "\n",
    "                                leg_v = ',{\"departure\":\"'+ i1_split[30] +'\",\"destination\":\"'+i1_split[31]       +'\",\"seatClass\":\"' + i1_split[34] +'\",\"conjunction\":\"'+  conj       +'\",\"carrier\":\"'+i1_split[32]+'\",\"tripCode\":\"'+i1_split[33]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[  37]+'\",\"stopOver\":\"'+i1_split[  29]+'\",\"flyerCode\":\"\",\"fare\":'+ fare +    ',\"currency\": \"USD\",\"originalFare\":'+ fare         +',\"originalCurrency\":\"'+'org_currency'+'\"}'\n",
    "\n",
    "                            if len(i1_split[21])!=0:\n",
    "                                if len(i1_split[26])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[26] +  leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(issue_year)    + 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[26]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[20]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "                                leg_v = '' if leg_v == '[' else leg_v\n",
    "                                leg_v =  ',{\"departure\":\"'+ i1_split[21] +'\",\"destination\":\"'+i1_split[22]      +'\",\"seatClass\":\"' + i1_split[25] +'\",\"conjunction\":\"'+  conj       +'\",\"carrier\":\"'+i1_split[23]+'\",\"tripCode\":\"'+i1_split[24]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[    28]+'\",\"stopOver\":\"'+i1_split[ 20]+'\",\"flyerCode\":\"\",\"fare\":'+ fare     +',\"currency\": \"USD\",\"originalFare\":'+ fare         +',\"originalCurrency\":\"'+'org_currency'+'\"}' + leg_v\n",
    "\n",
    "                            if len(i1_split[12])!=0:\n",
    "                                if len(i1_split[17])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[17] +  leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(issue_year)+ 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[17]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[11]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "                                leg_v = '' if leg_v == '[' else leg_v\n",
    "                                leg_v =   ',{\"departure\":\"'+ i1_split[12] +'\",\"destination\":\"'+i1_split[13]         +'\",\"seatClass\":\"' + i1_split[16] +'\",\"conjunction\":\"'+  conj       +'\",\"carrier\":\"'+i1_split[14]+'\",\"tripCode\":\"'+i1_split[    15]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[  19]+'\",\"stopOver\":\"'+i1_split[    11]+'\",\"flyerCode\":\"\",\"fare\":'+ fare    +',\"currency\": \"USD\",\"originalFare\":'+ fare        +',\"originalCurrency\":\"'+'org_currency'+'\"}' + leg_v\n",
    "\n",
    "                            if len(i1_split[3])!=0:\n",
    "                                #print(conj)\n",
    "                                if len(i1_split[8])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[8] +   leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(   issue_year)    + 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[8]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[2]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "                                leg_v = '' if leg_v == '[' else leg_v\n",
    "                                leg_v = '[{\"departure\":\"'+ i1_split[3] +'\",\"destination\":\"'+i1_split[4]         +'\",\"seatClass\":\"' + i1_split[7] +'\",\"conjunction\":\"'+conj+'\",\"carrier\":\"'+i1_split[5]+'\",\"tripCode\":\"'+i1_split[6]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[  10]+'\",\"stopOver\":\"'+i1_split[   2]+'\",\"flyerCode\":\"\",\"fare\":'+ fare  +',\"currency\": \"USD\",\"originalFare\":'+ fare      +',\"originalCurrency\":\"'+'org_currency'+'\"}' + leg_v\n",
    "\n",
    "                            # segment 1 + segment2\n",
    "                            leg_v_1 = '' if leg_v_1 == '[' else leg_v_1\n",
    "                            leg_v = leg_v + leg_v_1\n",
    "                        #print(pd.datetime.strptime(i1_split[8]+ str(datetime.now().year),'%d%b%Y'))\n",
    "                leg_v=leg_v+']'\n",
    "\n",
    "                # attributes: len(leg) > len(fare)\n",
    "                attributes = '' if j == len(fareval) + 1 else ' # ' + 'FareLegMismatch: leg: ' + str(j-1) +  ' does not match fare: ' + str(len(fareval)) + ' # '\n",
    "\n",
    "                # atributes: total_fareval <> leg: fareval\n",
    "                leg_fer_sum = '%.2f'%sum([float(x[7:]) for x in re.findall(r'\\\"fare\\\"\\:\\d+\\.\\d+', leg_v)])\n",
    "                attributes = attributes if total_fareval == leg_fer_sum else '#' + 'FareAmountMismatch: Leg sum amount: ' + str(leg_fer_sum) + ' does not match fare amount: ' + str(total_fareval)  + ' # '\n",
    "\n",
    "        else:\n",
    "            # issue_date is not datatime\n",
    "            attributes = attributes + '#' + 'Issue_dateNotDatetime: issue_date: ' +  str(issue_date)  + ' # '\n",
    "\n",
    "    return [leg_v, attributes]\n",
    "\n",
    "fc_LEG = udf(fc_LEG, ArrayType(StringType()))\n",
    "fc_LEG_list = fc_LEG('ITI_split','Fare_end','Ticket_no','Issue_date','column_def')\n",
    "bos_df_csv = bos_df_csv.withColumn('Leg_v1', fc_LEG_list[0]).withColumn('attributes', fc_LEG_list[1])\n",
    "bos_df_csv=bos_df_csv.selectExpr(\"FOP\",\"column_def\",\"Transaction_Date\",\"Agency_code\",\"Filename\",\"Source\",\"Booking_channel\",\"ticket_type\", \"version_no\",\"Ticket_No\",\"Issue_date\",\"PNR\",\"Tour_code\",\"Passenger_name\",\"Passenger_Count\",\"Coupon_used\",\"Country_code\",\"Original_Fare\",\"Fare_amt\",\"Org_currency\",\"exch_rate\",\"comm_amt\",\"Tax_Amt\",\"Total_amt\",\"curr_code\",\"org_ticket_no\",\"Commission\",\"Fare_Cons\",\"Tax\",\"case when column_def !='RFT' then replace(replace(Leg_v1,'CONJ',Ticket_no),'org_currency',Org_currency) end as Legs\",\"attributes\",\"file_path\",\"REF_LG\",\"SAL2_split\")"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 86,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|Legs|\n",
      "+----+\n",
      "|null|\n",
      "+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bos_df_csv.select('Legs').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "bos_df_csv2 = bos_df_csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# Refund_Legs\n",
    "# ONLY for RFT\n",
    "def fc_refund_legs (REF_LG, column_def,SAL2_split, org_ticket_no, Coupon_used):\n",
    "    refund_legs = ''\n",
    "    if column_def == 'RFT':\n",
    "        REF_LG_split = REF_LG.split('')[0].split('<')[:-1]\n",
    "        org_date = SAL2_split[0]\n",
    "        i = 1 # flag if it is the first & sequence\n",
    "        for lg_split in REF_LG_split:\n",
    "            s = ',' if i != 0 else '['\n",
    "            lg_split_split = lg_split.split('')\n",
    "            ticketNumber = lg_split_split[0] + lg_split_split[1]\n",
    "            coupons = lg_split_split[2]\n",
    "            issueDate = org_date\n",
    "            refund_legs = refund_legs + s + '{' + f'\"sequence\":{i},\"ticketNumber\":\"{ticketNumber}\",\"coupons\":\"{coupons}\",\"issueDate\":\"{issueDate}\"' + '}'\n",
    "\n",
    "            # RFT ORG_TICKET_NO\n",
    "            # RFT Coupon_used\n",
    "            if i == 1:\n",
    "                org_ticket_no = ticketNumber\n",
    "                Coupon_used = coupons\n",
    "\n",
    "            i = i + 1\n",
    "\n",
    "        refund_legs = refund_legs + ']'\n",
    "\n",
    "    return [refund_legs, org_ticket_no, Coupon_used]\n",
    "\n",
    "fc_fefund_legs = udf(fc_refund_legs, ArrayType(StringType()))\n",
    "fc_fefund_legs_list = fc_fefund_legs(\"REF_LG\",\"column_def\",\"SAL2_split\",\"org_ticket_no\",\"Coupon_used\")\n",
    "bos_df_csv = bos_df_csv.withColumn('refund_legs', fc_fefund_legs_list[0])\\\n",
    "                         .withColumn('org_ticket_no', fc_fefund_legs_list[1])\\\n",
    "                         .withColumn('Coupon_used', fc_fefund_legs_list[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['', 'REDACTED REF NAME', 'F', '-953.65', '0.00', '0.00', '', '-953.65', 'CA', 'CASH', '<\\x83']\n",
      "['125', '2161454822', '1234', '']\n",
      "['', 'REDACTED REF NAME', 'F', '-953.65', '0.00', '0.00', '', '-953.65', 'CA', 'CASH', '<\\x83']\n",
      "['125', '2161454822', '1234', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(refund_legs=',{\"sequence\":1,\"ticketNumber\":\"1252161454822\",\"coupons\":\"1234\",\"issueDate\":\"\"}]', org_ticket_no='1252161454822', Coupon_used='1234')]"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv2.select('refund_legs','org_ticket_no','Coupon_used').head(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ticketNumber = 'ticketNumber'\n",
    "coupons = 'coupons'\n",
    "issueDate = 'issueDate'\n",
    "refund_legs = '[{' + f'\"sequence\":1,\"ticketNumber\":\"{ticketNumber}\",\"coupons\":\"{coupons}\",\"issueDate\":\"{issueDate}\"' + '}]'\n",
    "print(refund_legs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data Validation\n",
    "# def\n",
    "def check_float(data, msg, header, length, decimal = 0):\n",
    "    try:\n",
    "        data_1 = data\n",
    "        data = data if len(str(data).split('.')[0]) <= (length - decimal) else 'NULL'\n",
    "        msg = msg if str(data) == str(data_1) else msg + ' # ' + header + 'OutOfRange: ' + str(data_1) + 'is out of range of (' +  str(length) + ',' + str(decimal) + ') # '\n",
    "    except Exception as e:\n",
    "        data = 'NULL'\n",
    "        msg = msg + '# ERROR ' + str(e) + ' # '\n",
    "    return data, msg\n",
    "\n",
    "\n",
    "def fc_DV(attributes,original_fare, exchange_rate,fare_amount,tax_amount,total_amount):\n",
    "\n",
    "    # attributes\n",
    "    attributes = '' if attributes is None else attributes\n",
    "\n",
    "    # original_fare\n",
    "    # numeric(12, 5)\n",
    "    original_fare, attributes = check_float(data = original_fare, msg = attributes , header = 'original_fare', length = 12, decimal = 5)\n",
    "\n",
    "    # exchange_rate\n",
    "    # numeric(12, 5)\n",
    "    exchange_rate, attributes = check_float(data = exchange_rate, msg = attributes , header = 'exchange_rate', length = 12, decimal = 5)\n",
    "\n",
    "    # fare_amount\n",
    "    # numeric(12, 5)\n",
    "    fare_amount, attributes = check_float(data = fare_amount, msg = attributes , header = 'fare_amount', length = 12, decimal = 5)\n",
    "\n",
    "    # tax_amount\n",
    "    # numeric(12, 5)\n",
    "    tax_amount, attributes = check_float(data = tax_amount, msg = attributes , header = 'tax_amount', length = 12, decimal = 5)\n",
    "\n",
    "    # total_amount\n",
    "    # numeric(12, 5)\n",
    "    total_amount, attributes = check_float(data = total_amount, msg = attributes , header = 'total_amount', length = 12, decimal = 5)\n",
    "\n",
    "    return [attributes,original_fare,exchange_rate,fare_amount,tax_amount,total_amount]\n",
    "\n",
    "fc_DV = udf(fc_DV, ArrayType(StringType()))\n",
    "fc_DV_list = fc_DV('attributes', 'Original_Fare', 'exch_rate', 'Fare_amt', 'Tax_Amt', 'Total_amt')\n",
    "bos_df_csv = bos_df_csv\\\n",
    "    .withColumn('attributes', fc_DV_list[0])\\\n",
    "    .withColumn('Original_Fare', fc_DV_list[1])\\\n",
    "    .withColumn('exch_rate', fc_DV_list[2])\\\n",
    "    .withColumn('Fare_amt', fc_DV_list[3])\\\n",
    "    .withColumn('Tax_Amt', fc_DV_list[4])\\\n",
    "    .withColumn('Total_amt', fc_DV_list[5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def fc_DV_2(attributes, Agency_code,Source,ticket_type,Coupon_used):\n",
    "\n",
    "    # attributes\n",
    "    attributes = '' if attributes is None else attributes\n",
    "\n",
    "    # Agency_code\n",
    "    # numeric(10, 0)\n",
    "    Agency_code, attributes = check_float(data = Agency_code, msg = attributes , header = 'Agency_code', length = 10, decimal = 0)\n",
    "\n",
    "    # Source\n",
    "    # numeric(10, 0)\n",
    "    Source, attributes = check_float(data = Source, msg = attributes , header = 'Source', length = 10, decimal = 0)\n",
    "\n",
    "    # ticket_type\n",
    "    # numeric(10, 0)\n",
    "    ticket_type, attributes = check_float(data = ticket_type, msg = attributes , header = 'ticket_type', length = 10, decimal = 0)\n",
    "\n",
    "\n",
    "    # Coupon_used\n",
    "    # numeric(10, 0)\n",
    "    Coupon_used, attributes = check_float(data = Coupon_used, msg = attributes , header = 'Coupon_used', length = 10, decimal = 0)\n",
    "\n",
    "\n",
    "    return [attributes,Agency_code,Source,ticket_type,Coupon_used]\n",
    "\n",
    "fc_DV_2 = udf(fc_DV_2, ArrayType(StringType()))\n",
    "fc_DV_2_list = fc_DV_2('attributes', 'Agency_code','Source','ticket_type','Coupon_used')\n",
    "bos_df_csv = bos_df_csv\\\n",
    "    .withColumn('attributes', fc_DV_2_list[0])\\\n",
    "    .withColumn('Agency_code', fc_DV_2_list[1])\\\n",
    "    .withColumn('Source', fc_DV_2_list[2])\\\n",
    "    .withColumn('ticket_type', fc_DV_2_list[3])\\\n",
    "    .withColumn('Coupon_used', fc_DV_2_list[4])"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "sc = SparkContext.getOrCreate();\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "\n",
    "my_conn_options = {\n",
    "    \"dbtable\": \"flextravel.fx_trans_file\",\n",
    "    \"database\": \"fts_cp_uat\",\n",
    "    \"url\": \"jdbc:postgresql://flextravel-uat-serverless-pg.chzjoncadzav.ca-central-1.rds.amazonaws.com:5432/fts_cp_uat\",\n",
    "    \"customJdbcDriverS3Path\":\"s3://flex-data-uat-canda-central/DEV/postgresql-42.6.0.jar\",\n",
    "    \"customJdbcDriverClassName\":\"org.postgresql.Driver\",\n",
    "    \"user\":\"flexuatuser\",\n",
    "    \"password\":\"flexnewyearpwd@2022\"\n",
    "}\n",
    "\n",
    "my_conn_options1 = {\n",
    "    \"dbtable\": \"flextravel.general_info\",\n",
    "    \"database\": \"fts_cp_uat\",\n",
    "    \"url\": \"jdbc:postgresql://flextravel-uat-serverless-pg.chzjoncadzav.ca-central-1.rds.amazonaws.com:5432/fts_cp_uat\",\n",
    "    \"customJdbcDriverS3Path\":\"s3://flex-data-uat-canda-central/DEV/postgresql-42.6.0.jar\",\n",
    "    \"customJdbcDriverClassName\":\"org.postgresql.Driver\",\n",
    "    \"user\":\"flexuatuser\",\n",
    "    \"password\":\"flexnewyearpwd@2022\"\n",
    "}\n",
    "\n",
    "my_conn_options2 = {\n",
    "    \"dbtable\": \"public.fx_trans_bre_interim_bos_sprint2_test\",\n",
    "    \"database\": \"fts_cp_uat\",\n",
    "    \"url\": \"jdbc:postgresql://flextravel-uat-serverless-pg.chzjoncadzav.ca-central-1.rds.amazonaws.com:5432/fts_cp_uat\",\n",
    "    \"customJdbcDriverS3Path\":\"s3://flex-data-uat-canda-central/DEV/postgresql-42.6.0.jar\",\n",
    "    \"customJdbcDriverClassName\":\"org.postgresql.Driver\",\n",
    "    \"user\":\"flexuatuser\",\n",
    "    \"password\":\"flexnewyearpwd@2022\"\n",
    "}\n",
    "\n",
    "df = glueContext.create_dynamic_frame.from_options(\n",
    "    connection_type=\"postgresql\",\n",
    "    connection_options=my_conn_options,\n",
    "    transformation_ctx=\"df\",\n",
    ")\n",
    "\n",
    "df_GI = glueContext.create_dynamic_frame.from_options(\n",
    "    connection_type=\"postgresql\",\n",
    "    connection_options=my_conn_options1,\n",
    "    transformation_ctx=\"df\",\n",
    ")\n",
    "GI_df = df_GI.toDF().select(\"id\",\"tids_code\")  \n",
    "\n",
    "\n",
    "\n",
    "bos_df_csv=  bos_df_csv.withColumn( \"Orginal_currency\",F.when(length(col(\"Org_currency\"))>5,'').otherwise(bos_df_csv.Org_currency))\n",
    "\n",
    "\n",
    "bos_df_final = bos_df_csv.select(\"ticket_type\",\"org_ticket_no\",\"version_no\",\"Filename\",\"Transaction_Date\",\"Agency_code\",\"Source\",\"Booking_channel\",\"Ticket_No\",\"PNR\",\"Issue_date\",\"Tour_code\",\"Passenger_name\",\"Passenger_Count\",\"Coupon_used\",\"Country_code\",\"Legs\",\"Original_Fare\",\"Orginal_currency\",\"exch_rate\",\"Fare_amt\",\"Tax_Amt\",\"Total_amt\",\"curr_code\",\"FOP\",\"Tax\",\"Commission\",\"Fare_Cons\",\"attributes\",\"file_path\", \"refund_legs\")\n",
    "                                                           \n",
    "Bos_df_GI= bos_df_final.join(GI_df,\n",
    "               bos_df_csv.Agency_code == GI_df.tids_code, \n",
    "               \"left\")  \n",
    "\n",
    "\n",
    "Bos_df_GI=Bos_df_GI.withColumnRenamed(\"id\",\"agent_id\")\n",
    "\n",
    "#Bos_df_GI.show(2, truncate=False)\n",
    "\n",
    "# df1 = df.toDF().select(\"id\", \"supplier_id\",\"sup_srv_map_id\",\"file_name\").where(df[\"file_name\"] =='06.07_DCALLRECORDSAM')\n",
    "# #df2=df1.withColumnRenamed(\"sup_srv_map_id\",\"col0\").withColumnRenamed(\"file_name\",\"col1\")\n",
    "# # df1 = df.filter(f=lambda x: x[\"sup_srv_map_id\"] in [65])\n",
    "\n",
    "df1 = df.toDF()[\"id\", \"supplier_id\",\"sup_srv_map_id\",\"file_name\"]\n",
    "df1 = df1[df1[\"file_name\"] =='06.07_DCALLRECORDSAM']\n",
    "\n",
    "\n",
    "#df1.show()\n",
    "\n",
    "Bos_df_file= Bos_df_GI.join(df1,\n",
    "               bos_df_csv.Filename == df1.file_name, \n",
    "               \"left\")    \n",
    "\n",
    "# Bos_df_file.show()\n",
    "\n",
    "# FTS - 2598 [\"Tax_Amt\"].cast(IntegerType()) -> DoubleType, [\"Total_amt\"].cast(IntegerType()) -> DoubleType\n",
    "Bos_df_file= Bos_df_file.withColumn(\"Original_Fare\", Bos_df_file[\"Original_Fare\"].cast(DoubleType())).withColumn(\"Fare_amt\", Bos_df_file[\"Fare_amt\"].cast(DoubleType())).withColumn(\"Tax_Amt\", Bos_df_file[\"Tax_Amt\"].cast(DoubleType()))\\\n",
    "            .withColumn(\"Total_amt\", Bos_df_file[\"Total_amt\"].cast(DoubleType())) .withColumn(\"exch_rate\", Bos_df_file[\"exch_rate\"].cast(DoubleType()))\n",
    "\n",
    "Bos_df_file= Bos_df_file.withColumn(\"Commission_Amount\", Bos_df_file[\"Fare_amt\"].cast(DoubleType()))\n",
    "                        \n",
    "Bos_df_write = Bos_df_file.select(\"Transaction_Date\",\"Agency_code\",\"Source\",\"Booking_channel\",\"Ticket_No\",\"PNR\",\"Issue_date\",\"Tour_code\",\"Passenger_name\",\"Passenger_Count\",\"Coupon_used\",\"Country_code\",\"Legs\",\"Original_Fare\",\"Orginal_currency\",\"exch_rate\",\"Fare_amt\",\"Tax_Amt\",\"Total_amt\",\"curr_code\",\"FOP\",\"Tax\",\"Commission\",\"Fare_Cons\",\"agent_id\",\"id\",\"supplier_id\",\"sup_srv_map_id\",\"ticket_type\",\"version_no\",\"org_ticket_no\",\"Commission_Amount\",\"attributes\",\"file_path\", \"refund_legs\")\n",
    "\n",
    "\n",
    "Bos_df_write = Bos_df_write.withColumnRenamed(\"Transaction_Date\",\"transaction_date\").withColumnRenamed(\"Agency_code\",\"agency_code\").withColumnRenamed(\"Source\",\"source\").withColumnRenamed(\"id\",\"trans_file_id\")\\\n",
    "                .withColumnRenamed(\"Booking_channel\",\"booking_channel\").withColumnRenamed(\"Ticket_No\",\"ticket_number\").withColumnRenamed(\"PNR\",\"pnr\").withColumnRenamed(\"Issue_date\",\"issue_date\").withColumnRenamed(\"Tour_code\",\"tour_code\")\\\n",
    "                .withColumnRenamed(\"Passenger_name\",\"passenger_name\").withColumnRenamed(\"Passenger_Count\",\"passenger_count\").withColumnRenamed(\"Coupon_used\",\"coupon_used\").withColumnRenamed(\"Country_code\",\"country_code\")\\\n",
    "                .withColumnRenamed(\"Legs\",\"legs\").withColumnRenamed(\"Original_Fare\",\"original_fare\").withColumnRenamed(\"Orginal_currency\",\"original_currency\").withColumnRenamed(\"exch_rate\",\"exchange_rate\").withColumnRenamed(\"Fare_amt\",\"fare_amount\")\\\n",
    "                .withColumnRenamed(\"Commission_Amount\",\"commission_amount\").withColumnRenamed(\"Tax_Amt\",\"tax_amount\").withColumnRenamed(\"Total_amt\",\"total_amount\").withColumnRenamed(\"curr_code\",\"currency_code\").withColumnRenamed(\"FOP\",\"payment\")\\\n",
    "                .withColumnRenamed(\"Tax\",\"tax\") .withColumnRenamed(\"Commission\",\"commission\").withColumnRenamed(\"Fare_Cons\",\"fare_construction\").withColumnRenamed(\"file_path\",\"tax_on_commission\")\n"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "Bos_df_write_dyn=DynamicFrame.fromDF(Bos_df_write,glueContext,'Bos_df_write_dyn')\n",
    "\n",
    "df3=glueContext.write_dynamic_frame_from_options(\n",
    "    frame=Bos_df_write_dyn,\n",
    "    connection_type=\"postgresql\",\n",
    "    connection_options=my_conn_options2,\n",
    "    transformation_ctx=\"dynamic_frame\"\n",
    ")\n",
    "#df3.show()"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": "PythonException: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 211, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\n    for obj in iterator:\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 200, in _batched\n    for item in iterator:\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in mapper\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in <genexpr>\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 85, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/util.py\", line 87, in wrapper\n    return f(*args, **kwargs)\n  File \"<stdin>\", line 30, in fc_Fare\nUnboundLocalError: local variable 'fare' referenced before assignment\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# # mini batch test\n",
    "# from pyspark.sql import SQLContext\n",
    "# sqlContest = SQLContext(sc)\n",
    "\n",
    "# i = 0\n",
    "# k = 19000\n",
    "# j = 100\n",
    "\n",
    "# while (i+j < k):\n",
    "#     print(i)\n",
    "\n",
    "#     try:\n",
    "#         pdk = Bos_df_write.toPandas()\n",
    "#         pd1 = pdk.loc[i:i+j][:].fillna(0)\n",
    "#         spark_df = sqlContest.createDataFrame(pd1)\n",
    "        \n",
    "#         Bos_df_write_dyn1=DynamicFrame.fromDF(spark_df,glueContext,'Bos_df_write_dyn')\n",
    "\n",
    "#         df3=glueContext.write_dynamic_frame_from_options(\n",
    "#             frame=Bos_df_write_dyn1,\n",
    "#             connection_type=\"postgresql\",\n",
    "#             connection_options=my_conn_options2,\n",
    "#             transformation_ctx=\"dynamic_frame\"\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#     finally:\n",
    "#         i = i + j\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.37.3 \nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::251954244960:role/aws-glue-role\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: 94e43814-4481-46a2-bd42-9a375b67a951\nJob Type: glueetl\nApplying the following default arguments:\n--glue_kernel_version 0.37.3\n--enable-glue-datacatalog true\nWaiting for session 94e43814-4481-46a2-bd42-9a375b67a951 to get into ready status...\nSession 94e43814-4481-46a2-bd42-9a375b67a951 has been created.\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(type(datetime.now()) == '<class \\'datetime.datetime\\'>')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(datetime.now(), datetime)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "issue_date = ''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[219], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43missue_date\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mIndexError\u001B[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "issue_date[5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}