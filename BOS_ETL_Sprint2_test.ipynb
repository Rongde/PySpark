{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "Python_Glue_Session",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "pygments_lexer": "python3",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import csv\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.sql.functions import udf\n",
    "import re\n",
    "import time\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import length,col, explode, upper, to_date, date_sub, lag, coalesce, lit, array_sort, when, arrays_zip, size, date_format, explode_outer, from_json, concat, expr, array\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from operator import itemgetter\n",
    "import datetime, re, requests\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import concat, col, lit \n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# # read data from S3 to DataFrame\n",
    "# # input: S3\n",
    "# # output df['ROW_ID', 'BOS_FILE_EXTRACT', 'file_path', 'COLUMN_DEF']\n",
    "# def read_s3_to_df(day_path):\n",
    "#\n",
    "#     # parameter\n",
    "#     i = 0 # flag for initialize dataframe\n",
    "#\n",
    "#     # boto3 client\n",
    "#     s3 = boto3.client('s3')\n",
    "#     conn = client('s3')  # again assumes boto.cfg setup, assume AWS S3\n",
    "#\n",
    "#     # read data file by file\n",
    "#     for key in conn.list_objects(Bucket='bos-etl')['Contents']:\n",
    "#         path_key = key['Key']\n",
    "#         if path_key.endswith('cleansed'):\n",
    "#             if day_path in path_key:\n",
    "#                 file = s3.get_object(Bucket='bos-etl', Key=path_key)\n",
    "#                 txt = (file['Body'].read().decode('latin1'))\n",
    "#                 #st_re = txt.replace(\"\", \",\")\n",
    "#                 st_re_newline = txt.replace(\"!!! EOS !!!\", \"\\n\")\n",
    "#                 st_re_split = st_re_newline.split(\"\\n\")\n",
    "#                 df = pd.DataFrame(st_re_split)\n",
    "#                 df.index.name = 'ROW_ID'\n",
    "#                 df.rename({0:'BOS_FILE_EXTRACT'},axis='columns',inplace=True)\n",
    "#                 df[\"COLUMN_DEF\"]=df['BOS_FILE_EXTRACT'].replace(regex=r\"\\.*\",value=\"\")\n",
    "#                 rslt_dfRFT_temp = df[df['COLUMN_DEF'] =='PAX']\n",
    "#                 # rslt_dfRFT_temp = df\n",
    "#                 if ~rslt_dfRFT_temp.empty:\n",
    "#                     # print(path_key)\n",
    "#                     rslt_dfRFT_temp.insert(0,'file_path', path_key)\n",
    "#                     if (i ==0):\n",
    "#                         rslt_dfRFT = rslt_dfRFT_temp\n",
    "#                         i = 1\n",
    "#                     else:\n",
    "#                         rslt_dfRFT = pd.concat([rslt_dfRFT,rslt_dfRFT_temp])\n",
    "#     return rslt_dfRFT\n",
    "#\n",
    "#\n",
    "# # read data as DataFrame\n",
    "# #select day\n",
    "# day_path = 'date=2023-06-17'\n",
    "# # select current system day\n",
    "# # day_path = time.strftime('%Y-%m-%d')\n",
    "# rslt_dfRFT = read_s3_to_df(day_path)\n",
    "#\n",
    "# # test\n",
    "# #filter content\n",
    "# # check_list=['123','456']\n",
    "#\n",
    "# # for i in range():\n",
    "# #       rslt_dfRFT['BOS_FILE_EXTRACT'].filter(like=check_list[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# #test write to s3 csv\n",
    "# from io import StringIO\n",
    "# bucket = 'bos-etl' # already created on S3\n",
    "# csv_buffer = StringIO()\n",
    "# rslt_dfRFT.to_csv(csv_buffer)\n",
    "# s3_resource = boto3.resource('s3')\n",
    "# s3_resource.Object(bucket, 'write_back/df.csv').put(Body=csv_buffer.getvalue())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# read csv\n",
    "rslt_dfRFT = pd.read_csv(\"source/input/1_df_RFT_PAT_PAX.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from awsglue.transforms import *\n",
    "# from awsglue.utils import getResolvedOptions\n",
    "# from pyspark.context import SparkContext\n",
    "# from awsglue.context import GlueContext\n",
    "# from awsglue.job import Job\n",
    "#\n",
    "# ## @params: [JOB_NAME]\n",
    "# args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "#\n",
    "# sc = SparkContext()\n",
    "# glueContext = GlueContext(sc)\n",
    "# spark = glueContext.spark_session\n",
    "# job = Job(glueContext)\n",
    "# job.init(args['JOB_NAME'], args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Pyspark Dataframe\n",
    "from pyspark.sql import SparkSession\n",
    "#Create PySpark SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n",
    "#Create PySpark DataFrame from Pandas\n",
    "sparkDF=spark.createDataFrame(rslt_dfRFT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "# # Split Raw Data\n",
    "#\n",
    "# def split_raw_data(sparkDF):\n",
    "#     df1 = sparkDF.withColumn(\"split\", F.split(\"BOS_FILE_EXTRACT\", \"<\")).withColumn(\"ITI\", F.element_at(\"split\", 2)).withColumn(\"FAR\", F.element_at(\"split\", 3))\\\n",
    "#     .withColumn(\"FOP_AND_FAR2\", F.element_at(\"split\", 4)).withColumn(\"END\", F.element_at(\"split\", 5)).withColumn(\"CER\", F.element_at(\"split\", 6))\\\n",
    "#     .withColumn(\"EXC\", F.element_at(\"split\", 7))\\\n",
    "#     .withColumn(\"split2\", F.split(\"BOS_FILE_EXTRACT\", \"<\")).withColumn(\"DCI\", F.element_at(\"split2\", 1)).withColumn(\"SAL\", F.element_at(\"split2\", 2))\\\n",
    "#     .withColumn(\"EXS\", F.element_at(\"split2\", -1))\\\n",
    "#     .withColumn(\"split3\", F.split(\"BOS_FILE_EXTRACT\", \"<\")).withColumn(\"TAX2\", F.element_at(\"split3\", 2))\\\n",
    "#     .withColumn(\"split4\", F.split(\"BOS_FILE_EXTRACT\", \"<\")).withColumn(\"TAX1\", F.element_at(\"split4\", 2))\n",
    "#\n",
    "#     split_df = df1.select(\"COLUMN_DEF\",\"DCI\",\"SAL\",\"TAX1\",\"TAX2\",\"ITI\",\"FAR\",\"FOP_AND_FAR2\",\"END\",\"CER\",\"EXC\",\"EXS\",split(df1.TAX1, '<').alias('split_text'),split(df1.FOP_AND_FAR2,'N<').alias(\"Splittext3\"),\"file_path\",\"TAX2\",F.regexp_extract(df1.BOS_FILE_EXTRACT, '<.+',0).alias('RFT'))\n",
    "#     split_df_type=split_df.selectExpr(\"column_def\",\"DCI\",\"SAL\",\"concat(split_text[0],',',TAX2) as TAX\",\"ITI\",\"FAR\", \"Case when column_def=='PAT' then FOP_AND_FAR2 else Splittext3[1] end as FOP\",\"Case when column_def=='PAT' then CER else END end as END_T\",\"Case when column_def=='PAT' then EXC else CER end as CER_T\",\"Case when column_def=='PAT' then '' else EXC end as EXC\",\"Case when column_def=='PAT' then '' else CER end as EXS_T\",\"file_path\",\"TAX2\",\"RFT\")\n",
    "#\n",
    "#     return split_df_type\n",
    "#\n",
    "# split_df_type = split_raw_data(sparkDF)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Split Raw Data\n",
    "#  Start of repeat\n",
    "#  END REPEAT\n",
    "#  END of Data Set Indicator\n",
    "# <   Carrriage Return\n",
    "# DCI < SAL < TAX < ITI < FAR < FOP < END < CER < EXC < EXS <\n",
    "#     < REF <\n",
    "\n",
    "def split_raw_data(sparkDF):\n",
    "    split_df_type = sparkDF.withColumn(\"split\", F.split(\"BOS_FILE_EXTRACT\", \"\"))\\\n",
    "                 .withColumn(\"DCI_SAL\", F.element_at(\"split\", 1))\\\n",
    "                 .withColumn(\"split2\", F.split(\"DCI_SAL\", \"<\"))\\\n",
    "                 .withColumn(\"DCI\", F.element_at(\"split2\", 1))\\\n",
    "                 .withColumn(\"SAL\", F.element_at(\"split2\", 2))\\\n",
    "                 .withColumn(\"TAX\", F.element_at(\"split\", 2))\\\n",
    "                 .withColumn(\"ITI\", F.element_at(\"split\", 3))\\\n",
    "                 .withColumn(\"FAR\", F.element_at(\"split\", 4))\\\n",
    "                 .withColumn(\"FOP\", F.element_at(\"split\", 5))\\\n",
    "                 .withColumn(\"END\", F.element_at(\"split\", 6))\\\n",
    "                 .withColumn(\"CER\", F.element_at(\"split\", 7))\\\n",
    "                 .withColumn(\"EXC\", F.element_at(\"split\", 8))\\\n",
    "                 .withColumn(\"EXS\",  F.element_at(\"split\", 9))\\\n",
    "                 .withColumn(\"RFT\",  F.regexp_extract('BOS_FILE_EXTRACT', '<.+<',0))\n",
    "\n",
    "    return split_df_type\n",
    "\n",
    "split_df_type = split_raw_data(sparkDF)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(column_def='RFT', DCI='RFT\\x8022521623\\x8020230618\\x8023061805093326\\x80125\\x802161454822\\x804\\x8017JUN23\\x80\\x80IAR\\x80BA/D/ALLRECORDS/18JUN23\\x80103\\x80', SAL='\\x80\\x80\\x80\\x80\\x80953.65\\x800.00\\x800.00\\x80358.00\\x80595.65\\x800.00\\x800.00\\x800.00\\x800.00\\x80\\x80\\x80\\x81125\\x802161454822\\x801234\\x80', TAX='', ITI=None, FAR=None, FOP=None, END=None, CER=None, EXC=None, EXS=None, RFT='<\\x80\\x80\\x80\\x80\\x80953.65\\x800.00\\x800.00\\x80358.00\\x80595.65\\x800.00\\x800.00\\x800.00\\x800.00\\x80\\x80\\x80\\x81125\\x802161454822\\x801234\\x80<\\x82\\x80REDACTED REF NAME\\x80F\\x80-953.65\\x800.00\\x800.00\\x80\\x80-953.65\\x80CA\\x80CASH\\x80<\\x83'),\n Row(column_def='PAX', DCI='PAX\\x8022521623\\x8020230618\\x8023061805093326\\x80001\\x807976703339\\x800\\x8017JUN23\\x80\\x80IAR\\x80BA/D/ALLRECORDS/18JUN23\\x80103\\x80', SAL='\\x80\\x80\\x80\\x80\\x80\\x80FFVV\\x80203.20\\x80166.51\\x80USD\\x800.00\\x8036.69\\x801.00\\x800.60\\x80HNKNVK/AA\\x80REDACTED SAL NAME\\x80\\x80\\x80\\x800011\\x80/\\x80\\x80Y\\x80\\x80\\x800\\x80\\x80\\x8000\\x80', TAX='\\x8112.49\\x80US\\x80<9.60\\x80ZP\\x80<5.60\\x80AY\\x80<9.00\\x80XF\\x80<\\x82\\x81ORF\\x804.5\\x80<DCA\\x804.5\\x80<\\x82', ITI='\\x81\\x80\\x80X\\x80ORF\\x80DCA\\x80AA\\x805508\\x80S\\x8008JUL\\x80323P\\x80SUAIZNN1\\x80\\x80DCA\\x80GRR\\x80AA\\x805091\\x80S\\x8008JUL\\x80530P\\x80SUAIZNN1\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80<\\x82', FAR='\\x81ORF AA X/WAS AA GRS166.51USD166.51END ZPORFDCA XFORF4.5DCA4.5\\x80<\\x82', FOP='\\x81CA\\x80CASH\\x80N \\x80\\x80\\x80203.20\\x80\\x80\\x800.00\\x80\\x801.00\\x800.60\\x80N\\x80<CA\\x80CASH\\x80N\\x80\\x80\\x8025.00\\x80\\x80\\x800.00\\x80\\x801.00\\x800.60\\x80E\\x80<\\x82', END='\\x81USD166.51 NONREFUNDABLE/NONREF/FAREDIF/CXL BY FLT TIME OR NOVALUE\\x80<\\x82', CER='\\x81\\x80<\\x82', EXC='\\x81001\\x807976703339\\x800\\x80<\\x82\\x81001\\x807965804275\\x802\\x8020230430\\x8022521623\\x80C0010E0G6XH48Y\\x80143.26\\x80178.20\\x801.00\\x800.70\\x8034.94\\x800.00\\x800.00\\x80\\x8112\\x80<\\x82F\\x80REDACTED EXC NAME\\x80<\\x82', EXS='143.26\\x80166.51\\x8034.94\\x8036.69\\x80178.20\\x80203.20\\x8025.00\\x801.00\\x801.00\\x800.00\\x800.00\\x800.00\\x801\\x800.00\\x8025.00\\x80<', RFT='<\\x80\\x80\\x80\\x80\\x80\\x80FFVV\\x80203.20\\x80166.51\\x80USD\\x800.00\\x8036.69\\x801.00\\x800.60\\x80HNKNVK/AA\\x80REDACTED SAL NAME\\x80\\x80\\x80\\x800011\\x80/\\x80\\x80Y\\x80\\x80\\x800\\x80\\x80\\x8000\\x80<\\x83\\x8112.49\\x80US\\x80<9.60\\x80ZP\\x80<5.60\\x80AY\\x80<9.00\\x80XF\\x80<\\x82\\x81ORF\\x804.5\\x80<DCA\\x804.5\\x80<\\x82\\x83\\x81\\x80\\x80X\\x80ORF\\x80DCA\\x80AA\\x805508\\x80S\\x8008JUL\\x80323P\\x80SUAIZNN1\\x80\\x80DCA\\x80GRR\\x80AA\\x805091\\x80S\\x8008JUL\\x80530P\\x80SUAIZNN1\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80<\\x82\\x83\\x81ORF AA X/WAS AA GRS166.51USD166.51END ZPORFDCA XFORF4.5DCA4.5\\x80<\\x82\\x83\\x81CA\\x80CASH\\x80N \\x80\\x80\\x80203.20\\x80\\x80\\x800.00\\x80\\x801.00\\x800.60\\x80N\\x80<CA\\x80CASH\\x80N\\x80\\x80\\x8025.00\\x80\\x80\\x800.00\\x80\\x801.00\\x800.60\\x80E\\x80<\\x82\\x83\\x81USD166.51 NONREFUNDABLE/NONREF/FAREDIF/CXL BY FLT TIME OR NOVALUE\\x80<\\x82\\x83\\x81\\x80<\\x82\\x83\\x81001\\x807976703339\\x800\\x80<\\x82\\x81001\\x807965804275\\x802\\x8020230430\\x8022521623\\x80C0010E0G6XH48Y\\x80143.26\\x80178.20\\x801.00\\x800.70\\x8034.94\\x800.00\\x800.00\\x80\\x8112\\x80<\\x82F\\x80REDACTED EXC NAME\\x80<\\x82\\x83143.26\\x80166.51\\x8034.94\\x8036.69\\x80178.20\\x80203.20\\x8025.00\\x801.00\\x801.00\\x800.00\\x800.00\\x800.00\\x801\\x800.00\\x8025.00\\x80<\\x83'),\n Row(column_def='PAT', DCI='PAT\\x8022521623\\x8020230618\\x8023061805093326\\x80074\\x802100377105\\x803\\x8016JUN23\\x80\\x80IAR\\x80BA/D/ALLRECORDS/18JUN23\\x80103\\x80', SAL='\\x80\\x80\\x80\\x80\\x80\\x80FFVV\\x80302.20\\x80213.00\\x80USD\\x800.00\\x8089.20\\x800.00\\x800.00\\x80UOAGUL\\x80REDACTED SAL NAME\\x80ITAFKL\\x80\\x800005WS\\x800744\\x80/\\x80\\x807\\x80\\x80\\x800\\x80X\\x80\\x8000\\x80', TAX='\\x812.20\\x80YR\\x80<16.00\\x80CJ\\x80<22.50\\x80RN\\x80<28.60\\x80VV\\x80<15.70\\x80JD\\x80<0.70\\x80OG\\x80<3.50\\x80QV\\x80<\\x82\\x81\\x80\\x80<\\x82', ITI='\\x81\\x80\\x80O\\x80AMS\\x80MAD\\x80KL\\x801701\\x80Q\\x8024JUN\\x800930\\x80QH5UA5LG/XX\\x80O\\x80MAD\\x80AMS\\x80KL\\x801702\\x80E\\x8027JUN\\x801305\\x80EH5UA5LG\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80<\\x82', FAR='\\x81AMS KL MAD119.12KL AMS97.52NUC216.64END ROE0.907418XT22.50RN28.60VV15.70JD0.70OG3.50QV\\x80<\\x82', FOP='\\x81CA\\x80CASH\\x80N\\x80\\x80\\x80302.20\\x80\\x80\\x800.00\\x80\\x800.00\\x800.00\\x80N\\x80<\\x82', END='\\x81NDC BR 1.08168132\\x80<\\x82', CER='\\x81\\x80<\\x82', EXC='', EXS=None, RFT='<\\x80\\x80\\x80\\x80\\x80\\x80FFVV\\x80302.20\\x80213.00\\x80USD\\x800.00\\x8089.20\\x800.00\\x800.00\\x80UOAGUL\\x80REDACTED SAL NAME\\x80ITAFKL\\x80\\x800005WS\\x800744\\x80/\\x80\\x807\\x80\\x80\\x800\\x80X\\x80\\x8000\\x80<\\x83')]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df_type.select('column_def',\"DCI\",\"SAL\",\"TAX\",\"ITI\",\"FAR\",\"FOP\",\"END\",\"CER\",\"EXC\",\"EXS\",\"RFT\").head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(column_def='RFT', TAX=''),\n Row(column_def='PAX', TAX='\\x8112.49\\x80US\\x80<9.60\\x80ZP\\x80<5.60\\x80AY\\x80<9.00\\x80XF\\x80<\\x82\\x81ORF\\x804.5\\x80<DCA\\x804.5\\x80<\\x82'),\n Row(column_def='PAT', TAX='\\x812.20\\x80YR\\x80<16.00\\x80CJ\\x80<22.50\\x80RN\\x80<28.60\\x80VV\\x80<15.70\\x80JD\\x80<0.70\\x80OG\\x80<3.50\\x80QV\\x80<\\x82\\x81\\x80\\x80<\\x82')]"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df_type.select('column_def','TAX').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Common\n",
    "# etl main fc\n",
    "def etl_fc(df, fc, input, output):\n",
    "    # fc\n",
    "    fc = udf(fc, ArrayType(StringType()))\n",
    "\n",
    "    # input\n",
    "    fc_list = fc(*input)\n",
    "\n",
    "    # output\n",
    "    for i in range(len(output)):\n",
    "        df = df.withColumn(output[i], fc_list[i])\n",
    "\n",
    "    return df\n",
    "\n",
    "# data validation fc\n",
    "def dv_fc(name, msg, fc , *args):\n",
    "    if name == 'check_len':\n",
    "        print(*args)\n",
    "        print(len(args))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "# data validation fc\n",
    "def dv_fc(rule_name, args_name, args, msg, paras ):\n",
    "\n",
    "    #rules\n",
    "    if rule_name == 'check_len':\n",
    "        # ValueOutOfRange\n",
    "        (args, msg) = (args, msg) if (len(str(x).split('.')[0]) < (paras[0] - paras[1])) & (len(str(x).split('.')[1]) < paras[1]) else ('NULL', msg + ' # ' + args_name +'OutOfRange: ' + str(args) + ' out of (' + str(paras[0]) + ',' + str(paras[1])  + ') # ')\n",
    "\n",
    "\n",
    "    if rule_name == 'check_match':\n",
    "        # Value1MismatchValue2\n",
    "        msg = msg if str(args[0]) == str(args[1]) else msg + ' # ' + args_name[0] +'MisMatch' + args_name[1] + ': (' + args_name[0] + ' , ' + args_name[1]  + ') : (' + str(args[0]) + ' , '  + str(args[1]) + ') # '\n",
    "\n",
    "    if rule_name == 'check_total':\n",
    "        #ValueCheckTotalFail\n",
    "        msg = msg if float(args[0]) == sum([float(x) for x in args[1]]) else  ' # ' + args_name[0] +'MisMatch' + args_name[1] + ': (' + args_name[0] + ' , ' + args_name[1]  + ') : (' + str(float(args[0])) + ' , '  + str(sum([float(x) for x in args[1]])) + ') # '\n",
    "\n",
    "    return (args, msg)\n",
    "\n",
    "\n",
    "\n",
    "# ExchangeRate = '12.345'\n",
    "# (args, msg) = dv_fc(rule_name = 'check_len', args_name = 'ExchangeRate', args = ExchangeRate, msg = '', paras=(6, 5))\n",
    "# print(msg)\n",
    "# print(args)\n",
    "# (args, msg) = dv_fc(rule_name = 'check_match', args_name = ('leg','fare'), args = (2,2), msg = '', paras = None)\n",
    "# print(args)\n",
    "# print(msg)\n",
    "# (args, msg) = dv_fc(rule_name = 'check_total', args_name = ('leg','fare'), args = (7,[1,'2','3']), msg = '', paras = None)\n",
    "# print(args)\n",
    "# print(msg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Custom\n",
    "# PAT/PAX/REF : [transaction_date, source, booking_channel, version_no, currency_code, ticket_type]\n",
    "\n",
    "def fc_custom(data):\n",
    "\n",
    "    # var\n",
    "    transaction_date = current_timestamp() # <<File Generated Date>>\n",
    "    source = 'BOS' # BOS\n",
    "    booking_channel = 'WEB' # WEB\n",
    "    version_no = 1\n",
    "    currency_code = 'USD' # always “USD”\n",
    "\n",
    "    ''' ticket_type :\n",
    "         line starts with PAT → ticket type = TKTT\n",
    "         line starts with PAX→ ticket type = EXCH-TKTT\n",
    "         line starts with RFT → ticket type = RFND\n",
    "         '''\n",
    "\n",
    "    # insert var\n",
    "    data = data.withColumn('transaction_date', transaction_date)\\\n",
    "               .withColumn('source', F.lit(source)) \\\n",
    "               .withColumn('booking_channel', F.lit(booking_channel))\\\n",
    "               .withColumn('version_no', F.lit(version_no))\\\n",
    "               .withColumn('ticket_type', when(col('column_def') == 'PAT', 'TKTT').\\\n",
    "                                          when(col('column_def') == 'PAX', 'EXCH-TKTT').\\\n",
    "                                          when(col('column_def') == 'RFT', 'RFND').\\\n",
    "                                          otherwise(''))\\\n",
    "               .withColumn('currency_code', F.lit(currency_code))\n",
    "\n",
    "    return data\n",
    "\n",
    "bos_df_csv = fc_custom(split_df_type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+---------------+-----------+----------+\n",
      "|column_def|    transaction_date|source|booking_channel|ticket_type|version_no|\n",
      "+----------+--------------------+------+---------------+-----------+----------+\n",
      "|       RFT|2023-07-30 22:51:...|   BOS|            WEB|       RFND|         1|\n",
      "|       PAX|2023-07-30 22:51:...|   BOS|            WEB|  EXCH-TKTT|         1|\n",
      "|       PAT|2023-07-30 22:51:...|   BOS|            WEB|       TKTT|         1|\n",
      "+----------+--------------------+------+---------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bos_df_csv.select('column_def','transaction_date' , 'source', 'booking_channel', 'ticket_type','version_no').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# DCI\n",
    "# PAT/PAX/REF : ['agency_code', 'ticket_number', 'issue_date']\n",
    "input  = ['DCI']\n",
    "output = ['agency_code', 'ticket_number', 'issue_date']\n",
    "\n",
    "def fc(DCI):\n",
    "\n",
    "    # 1.split\n",
    "    # print(DCI)\n",
    "    DCI_split = DCI.split(\"\")\n",
    "    # print(DCI_split)\n",
    "\n",
    "    # 2.var\n",
    "    # BRE\n",
    "    agency_code = DCI_split[1] # 2nd field from 1st group (VLNC-DCI)\n",
    "    ticket_number = DCI_split[4] + DCI_split[5] # 5th field + 6th field from 1st group (BACN-DCI+ BDNR-DCI)\n",
    "    issue_date = datetime.strptime(DCI_split[7],'%d%b%y').strftime(\"%Y-%m-%d\") # 8th field from 1st group (DAIS-DCI). Field is reported as YYMMDD\n",
    "\n",
    "    return [agency_code, ticket_number, issue_date]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------------+----------+\n",
      "|column_def|agency_code|ticket_number|issue_date|\n",
      "+----------+-----------+-------------+----------+\n",
      "|       RFT|   22521623|1252161454822|2023-06-17|\n",
      "|       PAX|   22521623|0017976703339|2023-06-17|\n",
      "|       PAT|   22521623|0742100377105|2023-06-16|\n",
      "+----------+-----------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bos_df_csv.select('column_def','agency_code','ticket_number','issue_date').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# SAL\n",
    "# PAT/PAX : ['pnr', 'tour_code', 'passenger_name', 'coupon_used', 'original_fare', 'fare_amount', 'exchange_rate', 'commission_amount', 'original_currency', 'tax_amount', 'total_amount', 'commission']\n",
    "\n",
    "input  = ['column_def', 'SAL']\n",
    "output = ['pnr', 'tour_code', 'passenger_name', 'coupon_used', 'original_fare', 'fare_amount', 'exchange_rate', 'commission_amount', 'original_currency', 'tax_amount', 'total_amount', 'commission']\n",
    "\n",
    "def fc(column_def, SAL):\n",
    "\n",
    "    # 1.split\n",
    "    if column_def != 'RFT':\n",
    "        # print(SAL)\n",
    "        SAL_split = SAL.split(\"\") if column_def != 'RFT' else None\n",
    "        # print(SAL_split)\n",
    "\n",
    "    # 2.var\n",
    "    # BRE\n",
    "    pnr = SAL_split[14] if column_def != 'RFT' else None # 15th field from 2nd group (PNRR-SAL). Note: it will be empty for RFND.\n",
    "    tour_code = SAL_split[16] if column_def != 'RFT' else None # 17th field from 2nd group (TOUR-SAL). Note: it will be empty for RFND.\n",
    "    passenger_name = SAL_split[15] if column_def != 'RFT' else None # 16th field from 2nd group (PXNM-SAL) for non-RFND.\n",
    "    coupon_used = SAL_split[15] if column_def != 'RFT' else None # 7th field from 2nd group (CPUI-SAL) for non-RFND\n",
    "    original_fare = SAL_split[8] if column_def != 'RFT' else None # 9th field from 2nd group\n",
    "    original_currency = SAL_split[9] if column_def != 'RFT' else None# 10th field from 2nd group (CUOF-SAL)\n",
    "    tax_amount = SAL_split[11] if column_def != 'RFT' else None # 12th field from 2nd group (TTAX-SAL)\n",
    "    total_amount = SAL_split[7] if column_def != 'RFT' else None # 8th field from 2nd group (TDAM-SAL)\n",
    "\n",
    "    fare_amount = None\n",
    "    exchange_rate = None\n",
    "    commission_amount = None\n",
    "    commission = None\n",
    "    if column_def != 'RFT':\n",
    "        fare_amount = SAL_split[10] if SAL_split[10] != '0.00' else original_fare # 11th field from 2nd group (EQFR-SAL)… Note: if is 0.00, use the same as ORIGINAL_FARE\n",
    "\n",
    "        exchange_rate = round(float(fare_amount) / float(original_fare),3) if original_fare != '0.00' else None # FARE_AMOUNT / ORIGINAL_FARE\n",
    "        commission_amount = fare_amount # same as FARE_AMOUNT\n",
    "\n",
    "        ''' COMMISSION:\n",
    "        #JSON. Example: [{\"type\":\"BASE\",\"amount\":4.26,\"currency\":\"CAD\",\"commissionRate\":3.0}]\n",
    "                       amount: 13th field from 2nd group (COAM-SAL)\n",
    "                       commissionRate: 14th field from 2nd group (CORT-SAL)'''\n",
    "        amount = SAL_split[12]\n",
    "        commissionRate = SAL_split[13]\n",
    "        type1 = 'BASE'\n",
    "        currency = 'CAD'\n",
    "        commission = '[{' + f'\"type\":\"{type1}\",\"amount\":{amount},\"currency\":\"{currency}\",\"commissionRate\":{commissionRate}' + '}]'\n",
    "\n",
    "    return [pnr, tour_code, passenger_name, coupon_used, original_fare, fare_amount, exchange_rate, commission_amount, original_currency, tax_amount, total_amount, commission]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(column_def='RFT', pnr=None, tour_code=None, passenger_name=None, original_fare=None, fare_amount=None, exchange_rate=None, commission_amount=None, original_currency=None, tax_amount=None, total_amount=None, commission=None),\n Row(column_def='PAX', pnr='HNKNVK/AA', tour_code='', passenger_name='REDACTED SAL NAME', original_fare='166.51', fare_amount='166.51', exchange_rate='1.0', commission_amount='166.51', original_currency='USD', tax_amount='36.69', total_amount='203.20', commission='[{\"type\":\"BASE\",\"amount\":1.00,\"currency\":\"CAD\",\"commissionRate\":0.60}]'),\n Row(column_def='PAT', pnr='UOAGUL', tour_code='ITAFKL', passenger_name='REDACTED SAL NAME', original_fare='213.00', fare_amount='213.00', exchange_rate='1.0', commission_amount='213.00', original_currency='USD', tax_amount='89.20', total_amount='302.20', commission='[{\"type\":\"BASE\",\"amount\":0.00,\"currency\":\"CAD\",\"commissionRate\":0.00}]')]"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv.select('column_def','pnr','tour_code', 'passenger_name', 'original_fare', 'fare_amount','exchange_rate','commission_amount','original_currency','tax_amount','total_amount','commission').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(column_def='RFT', TAX=''),\n Row(column_def='PAX', TAX='\\x8112.49\\x80US\\x80<9.60\\x80ZP\\x80<5.60\\x80AY\\x80<9.00\\x80XF\\x80<\\x82\\x81ORF\\x804.5\\x80<DCA\\x804.5\\x80<\\x82'),\n Row(column_def='PAT', TAX='\\x812.20\\x80YR\\x80<16.00\\x80CJ\\x80<22.50\\x80RN\\x80<28.60\\x80VV\\x80<15.70\\x80JD\\x80<0.70\\x80OG\\x80<3.50\\x80QV\\x80<\\x82\\x81\\x80\\x80<\\x82')]"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv.select('column_def','TAX').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    " # # Template\n",
    "# # PAT/PAX : []\n",
    "#\n",
    "# input  = ['column_def', 'TAX']\n",
    "# output = ['df']\n",
    "#\n",
    "# def fc(column_def, TAX):\n",
    "#\n",
    "#     # split\n",
    "#     print(TAX_split)\n",
    "#     TAX_split = TAX.split(\"\")\n",
    "#     # print(DCI_split)\n",
    "#\n",
    "#     # var\n",
    "#     df = ''\n",
    "#\n",
    "#\n",
    "#\n",
    "#     return [df]\n",
    "#\n",
    "# bos_df_csv2 = etl_fc(bos_df_csv, fc, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# TAX\n",
    "# PAT/PAX : ['tax']\n",
    "\n",
    "input  = ['column_def', 'TAX', 'original_currency']\n",
    "output = ['tax']\n",
    "\n",
    "def fc(column_def, TAX, original_currency):\n",
    "\n",
    "    # split\n",
    "    if column_def != 'RFT':\n",
    "        # print(TAX)\n",
    "        TAX_split = TAX.split('<')[0].replace('','').split('<')\n",
    "        # print(TAX_split)\n",
    "\n",
    "    # var\n",
    "    # BRE\n",
    "    ''' TAX:\n",
    "            Field will be <null> if is RFND\n",
    "            Note: this group may have a loop\n",
    "            JSON. Example: [{\"type\":\"CA\",\"amount\":7.12,\"currency\":\"CAD\"},{\"type\":\"YR\",\"amount\":16.00,\"currency\":\"CAD\"}]\n",
    "            type: 2nd field of the loop from 3rd group (TMFT-TAX)\n",
    "            amount: 1st field of the loop from 3rd group (TMFA-TAX)\n",
    "            currency: 10th field from 2nd group (CUOF-SAL)'''\n",
    "    tax = None\n",
    "    if column_def != 'RFT':\n",
    "        tax = ''\n",
    "        for i in range(len(TAX_split)):\n",
    "            # split\n",
    "            element = TAX_split[i].split('')\n",
    "            # print(element)\n",
    "\n",
    "            # element\n",
    "            type1 = element[1]\n",
    "            amount = element[0]\n",
    "            currency = original_currency\n",
    "\n",
    "            # tax\n",
    "            s = ',' if i != 0 else '['\n",
    "            tax = tax + s + '{' + f'\"type\":\"{type1}\",\"amount\":{amount},\"currency\":\"{currency}\"' + '}'\n",
    "\n",
    "        tax = tax + ']'\n",
    "\n",
    "    return [tax]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(column_def='RFT', tax=None),\n Row(column_def='PAX', tax='[{\"type\":\"US\",\"amount\":12.49,\"currency\":\"USD\"},{\"type\":\"ZP\",\"amount\":9.60,\"currency\":\"USD\"},{\"type\":\"AY\",\"amount\":5.60,\"currency\":\"USD\"},{\"type\":\"XF\",\"amount\":9.00,\"currency\":\"USD\"}]'),\n Row(column_def='PAT', tax='[{\"type\":\"YR\",\"amount\":2.20,\"currency\":\"USD\"},{\"type\":\"CJ\",\"amount\":16.00,\"currency\":\"USD\"},{\"type\":\"RN\",\"amount\":22.50,\"currency\":\"USD\"},{\"type\":\"VV\",\"amount\":28.60,\"currency\":\"USD\"},{\"type\":\"JD\",\"amount\":15.70,\"currency\":\"USD\"},{\"type\":\"OG\",\"amount\":0.70,\"currency\":\"USD\"},{\"type\":\"QV\",\"amount\":3.50,\"currency\":\"USD\"}]')]"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv.select('column_def', 'tax').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# ITI\n",
    "# PAT/PAX : ['legs']\n",
    "\n",
    "input  = ['column_def', 'ITI', 'ticket_number', 'currency_code', 'original_currency', 'issue_date', 'FAR']\n",
    "output = ['legs']\n",
    "\n",
    "def fc(column_def, ITI, ticket_number, currency_code, original_currency, issue_date, FAR):\n",
    "\n",
    "    # split\n",
    "    # ITI\n",
    "    if column_def != 'RFT' :\n",
    "        # print(ITI)\n",
    "        ITI_split = ITI.replace('','').replace('<','').split('<')\n",
    "        # print(ITI_split)\n",
    "        if (len(ITI_split)>1):\n",
    "            # if two more than two ticket legs, direction from right -> left\n",
    "            ITI_split.reverse()\n",
    "    # FAR\n",
    "        FAR_split = re.findall(r'[A-PR-Z]\\d+\\.\\d+', FAR.split(\"END\")[0]) # filter startswith 'Q'\n",
    "        FAR_split = [x[1:] for x in FAR_split ] # filter start alpha\n",
    "        if (len(FAR_split) > 1):\n",
    "            # if two more than two ticket legs, direction from right -> left\n",
    "            FAR_split.reverse()\n",
    "        # toal_far\n",
    "        fare_total = FAR_split[0]\n",
    "        # leg far\n",
    "        fare_legs = FAR_split[1:]\n",
    "\n",
    "    # var\n",
    "    '''LEGS:\n",
    "        NOTE: If the ticket type is RFND, LEGS field needs to be empty\n",
    "\n",
    "        Note: this info is provided in the ITI group. Each ticket may have 4 legs max. After the 5th leg, the ticket is considered as conjunction. In the file, if there is a loop, the ticket has a conjunction ticket.Example: 1st leg, 2nd leg, 3rd leg, 4th leg + loop + 5th leg…If the leg is empty, it means that the ticket stopped in the previous leg. Don’t load empty values in the Json.\n",
    "\n",
    "        JSON. example: [{\"departure\":\"FLR\",\"destination\":\"YYZ\",\"seatClass\":\"C\",\"conjunction\":\"1111234567890\",\"carrier\":\"AC\",\"tripCode\":\"876\",\"departureOn\":\"2022-12-30\",\"designator\":\"\",\"stopOver\":\"X\",\"flyerCode\":\"\",\"fare\":259.25,\"currency\": \"CAD\",\"originalFare\":259.25,\"originalCurrency\":\"CAD\"}]\n",
    "        departure: from 4th group (ORAC-ITI) → Leg 1: 4th field | Leg 2: 13th field | Leg 3: 22nd field | Leg 4: 31st field\n",
    "        destination: from 4th group (DSTC-ITI) → Leg 1: 5th field | Leg 2: 14th field | Leg 3: 23rd field | Leg 4: 32nd field\n",
    "        seatClass: 4th group (CLSC-ITI) → Leg 1: 8th field | Leg 2: 17th field | Leg 3: 26th field | Leg 4: 35th field\n",
    "        conjunction: 1st field from 4th group (CJNR-ITI). If is empty, use the same as TICKET_NUMBER\n",
    "\n",
    "        if the ticket includes more than 4 legs: in ITI section, the 39th field (the field after 4th repeat’s designator) will give a new BDNR (10 digits), use the BACN from DCI + new BDNR as conjunction for the following legs\n",
    "\n",
    "        carrier: from 4th group (CARR-ITI) → Leg 1: 6th field | Leg 2: 15th field | Leg 3: 24th field | Leg 4: 33rd field\n",
    "        tripCode: 4th group (FTNR-ITI) → Leg 1: 7th field | Leg 2: 16th field | Leg 3: 25th field | Leg 4: 34th field\n",
    "\n",
    "        departured on: 4th group (FTDA-ITI) → Leg 1: 9th field | Leg 2: 18th field | Leg 3: 27th field | Leg 4: 36th field. NOTE: you need to store this format in the databse: YYYY-MM-DD but the file has JAN01 for example. Use the same procedure/logic from CAT file loader in order to convert into date\n",
    "\n",
    "        Check the logic from CAT (Java code) with Haibinhg and Santhosh because there are some tricks in the code but the logic is:\n",
    "        File will come as JUL01 (they don’t report the year) → convert into 2023-07-01\n",
    "        If the departure date is before the issue date, the year will be ISSUE_DATE +1 year. Example: issue date is 2023-07-01 and departure date is JUN01, then the departure date will be 2024-06-01\n",
    "        If the departure date is after or equals to the issue date, the year will be the same as Issue Date. Example: issue date is 2023-07-01 and departure date is DEC01, then the departure date will be 2023-12-01\n",
    "        If the departure date is after the issue date (but after december 31st), the year will be the same as Issue Date + 1 year. Example: issue date is 2023-07-01 and departure date is JAN01, then the departure date will be 2024-01-01\n",
    "        designator: 4th group (FBTD-ITI) → Leg 1: 11th field | Leg 2: 20th field | Leg 3: 29th field | Leg 4: 38th field\n",
    "        stopOver: from 4th group (STPO-ITI) → Leg 1: 3rd field | Leg 2: 12th field | Leg 3: 21st field | Leg 4: 30th field\n",
    "        flyerCode: <empty>\n",
    "\n",
    "        fare: you need to check the fare construction group and then apply the same logic as CAT loader (use the same rules applied on these stories: FTS-1518, FTS-1188 item 2, FTS-1188 and FTS-1502)\n",
    "        currency: same as CURRENCY_CODE\n",
    "\n",
    "        originalFare: you need to check the fare construction group and then apply the same logic as CAT loader (use the same rules applied on these stories: FTS-1518 and FTS-1188 item 2)\n",
    "        originalCurrency: same as ORIGINAL_CURRENCY'''\n",
    "\n",
    "    legs = None\n",
    "    if column_def != 'RFT':\n",
    "        legs = ''\n",
    "        for i in range(len(ITI_split)):\n",
    "            # split\n",
    "            element = ITI_split[i].split('')\n",
    "\n",
    "            # segment\n",
    "            j = 30 # index for element\n",
    "            k = 0 # index for fare_legs\n",
    "            conjunction = ticket_number if len(element[0]) == 0 else (ticket_number[0:3] + element[0])\n",
    "            currency = currency_code\n",
    "            originalCurrency = original_currency\n",
    "            while (j > 0):\n",
    "                if len(element[j]) != 0:\n",
    "                    # element\n",
    "                    departure = element[j]\n",
    "                    destination = element[j+1]\n",
    "                    seatClass = element[j+4]\n",
    "                    carrier = element[j+2]\n",
    "                    tripCode = element[j+3]\n",
    "                    designator = element[j+7]\n",
    "                    stopOver = element[j-1]\n",
    "                    flyerCode = ''\n",
    "\n",
    "                    # fare\n",
    "                    # far if 'X' != 0, take one from fare_leg\n",
    "                    if (stopOver == 'X'):\n",
    "                        fare = str('0.00')\n",
    "                    else:\n",
    "                        if (fare_legs == 0):\n",
    "                            fare = 'NULL'\n",
    "                        elif (k < len(fare_legs)):\n",
    "                            fare = fare_legs[k]\n",
    "                            k = k + 1\n",
    "                        else:\n",
    "                            fare = 'NULL'\n",
    "\n",
    "                    originalFare = fare\n",
    "\n",
    "                    # departureOn\n",
    "                    # dep_on_date(issue_year-mm-dd)if dep_on_date(mm-dd) > issue_data(mm-dd) else dep_on_date((issue_year+1)-mm-dd))\n",
    "                    dep_on_date = element[j+5]\n",
    "                    issue_year = issue_date[0:4]\n",
    "                    dep_day = datetime.strptime(dep_on_date + '2024','%d%b%Y').strftime(\"%m-%d\") # 2024 is leap year to avoid '02-28', just for transformation, not use it afterward\n",
    "                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(issue_year)+ 1)\n",
    "                    departureOn = str(pd.datetime.strptime(dep_on_date + dep_year,'%d%b%Y'))[0:10]\n",
    "                    # departureOn = ''\n",
    "\n",
    "                    # legs\n",
    "                    s = '[' if ((i == len(ITI_split) - 1) and (j == 3)) else ','\n",
    "                    legs = s + '{' + f'\"departure\":\"{departure}\",\"destination\":\"{destination}\",\"seatClass\":\"{seatClass}\",\"conjunction\":\"{conjunction}\",\"carrier\":\"{carrier}\",\"tripCode\":\"{tripCode}\",\"departureOn\":\"{departureOn}\",\"designator\":\"{designator}\",\"stopOver\":\"{stopOver}\",\"flyerCode\":\"{flyerCode}\",\"fare\":{fare},\"currency\":\"{currency}\",\"originalFare\":{originalFare},\"originalCurrency\":\"{originalCurrency}\"' + '}' + legs\n",
    "\n",
    "                j = j - 9\n",
    "\n",
    "        legs = legs + ']'\n",
    "\n",
    "    return [legs]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XORFDCAAA5508S08JUL323PSUAIZNN1DCAGRRAA5091S08JUL530PSUAIZNN1VV<\n",
      "['\\x80\\x80X\\x80ORF\\x80DCA\\x80AA\\x805508\\x80S\\x8008JUL\\x80323P\\x80SUAIZNN1\\x80\\x80DCA\\x80GRR\\x80AA\\x805091\\x80S\\x8008JUL\\x80530P\\x80SUAIZNN1\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80']\n",
      "/var/folders/d9/871p0v1d2cn4c6y7bj_xghhh0000gn/T/ipykernel_2543/71694976.py:109: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "OAMSMADKL1701Q24JUN0930QH5UA5LG/XXOMADAMSKL1702E27JUN1305EH5UA5LGVV<\n",
      "['\\x80\\x80O\\x80AMS\\x80MAD\\x80KL\\x801701\\x80Q\\x8024JUN\\x800930\\x80QH5UA5LG/XX\\x80O\\x80MAD\\x80AMS\\x80KL\\x801702\\x80E\\x8027JUN\\x801305\\x80EH5UA5LG\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80V\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80\\x80']\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(column_def='RFT', legs=None),\n Row(column_def='PAX', legs='[{\"departure\":\"ORF\",\"destination\":\"DCA\",\"seatClass\":\"S\",\"conjunction\":\"0017976703339\",\"carrier\":\"AA\",\"tripCode\":\"5508\",\"departureOn\":\"2023-07-08\",\"designator\":\"SUAIZNN1\",\"stopOver\":\"X\",\"flyerCode\":\"\",\"fare\":0.00,\"currency\":\"USD\",\"originalFare\":0.00,\"originalCurrency\":\"USD\"},{\"departure\":\"DCA\",\"destination\":\"GRR\",\"seatClass\":\"S\",\"conjunction\":\"0017976703339\",\"carrier\":\"AA\",\"tripCode\":\"5091\",\"departureOn\":\"2023-07-08\",\"designator\":\"SUAIZNN1\",\"stopOver\":\"\",\"flyerCode\":\"\",\"fare\":166.51,\"currency\":\"USD\",\"originalFare\":166.51,\"originalCurrency\":\"USD\"}]'),\n Row(column_def='PAT', legs='[{\"departure\":\"AMS\",\"destination\":\"MAD\",\"seatClass\":\"Q\",\"conjunction\":\"0742100377105\",\"carrier\":\"KL\",\"tripCode\":\"1701\",\"departureOn\":\"2023-06-24\",\"designator\":\"QH5UA5LG/XX\",\"stopOver\":\"O\",\"flyerCode\":\"\",\"fare\":119.12,\"currency\":\"USD\",\"originalFare\":119.12,\"originalCurrency\":\"USD\"},{\"departure\":\"MAD\",\"destination\":\"AMS\",\"seatClass\":\"E\",\"conjunction\":\"0742100377105\",\"carrier\":\"KL\",\"tripCode\":\"1702\",\"departureOn\":\"2023-06-27\",\"designator\":\"EH5UA5LG\",\"stopOver\":\"O\",\"flyerCode\":\"\",\"fare\":97.52,\"currency\":\"USD\",\"originalFare\":97.52,\"originalCurrency\":\"USD\"}]')]"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv.select('column_def','legs').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# FAR\n",
    "# PAT/PAX : [fare_construction]\n",
    "\n",
    "input  = ['column_def', 'FAR']\n",
    "output = ['fare_construction']\n",
    "\n",
    "def fc(column_def, FAR):\n",
    "\n",
    "    # split\n",
    "    if column_def != 'RFT':\n",
    "        # print(FAR)\n",
    "        FAR_split =FAR.replace('','').replace('<','').split('<') # filter the last one which is ''\n",
    "        # print(FAR_split)\n",
    "\n",
    "    # var\n",
    "    '''FARE_CONSTRUCTION:\n",
    "        Note: the FAR group might have a loop, that’s why we need to use sequence 1, sequence 2, etc.\n",
    "        JSON. Example: [{\"sequence\":1,\"content\":\"AX373911153791006*0626/ 122948\"},{\"sequence\":2,\"content\":\"YHZ PD YMQ54.56CAD54.56END\"}]\n",
    "        content: 1st field from 5th group (FRCA-FAR)'''\n",
    "    fare_construction = None\n",
    "    if column_def != 'RFT':\n",
    "        fare_construction = ''\n",
    "        for i in range(len(FAR_split)):\n",
    "            element = FAR_split[i].split('')\n",
    "            content = element[0]\n",
    "            s = ',' if i != 0 else '['\n",
    "            fare_construction = fare_construction + s + '{' + f'\"sequence\":{i+1},\"content\":\"{content}\"' +'}'\n",
    "\n",
    "        fare_construction = fare_construction + ']'\n",
    "\n",
    "    return [fare_construction]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(fare_construction=None),\n Row(fare_construction='[{\"sequence\":1,\"content\":\"ORF AA X/WAS AA GRS166.51USD166.51END ZPORFDCA XFORF4.5DCA4.5\"}]'),\n Row(fare_construction='[{\"sequence\":1,\"content\":\"AMS KL MAD119.12KL AMS97.52NUC216.64END ROE0.907418XT22.50RN28.60VV15.70JD0.70OG3.50QV\"}]')]"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv.select('fare_construction').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "# FOP\n",
    "# PAT/PAX : [payment]\n",
    "\n",
    "input  = ['column_def', 'FOP', 'currency_code', 'EXC']\n",
    "output = ['payment', 'first_payment_accountNumber']\n",
    "\n",
    "def fc(column_def, FOP, currency_code, EXC):\n",
    "\n",
    "    # split\n",
    "    # FOP\n",
    "    print(column_def)\n",
    "    if column_def != 'RFT':\n",
    "        # print(FOP)\n",
    "        FOP_split = FOP.replace('','').replace('<','').split('<')\n",
    "        # print(FOP_split)\n",
    "\n",
    "    # EXC\n",
    "    if column_def == 'PAX':\n",
    "        EXC_split = EXC.split('<')\n",
    "        EXC1_split = EXC_split[0].replace('','').split('<')# loop of NACN+NDNR+NCDT\n",
    "        EXC3_split = EXC_split[2].replace('','').split('<') # loop of RCPU + PXNM\n",
    "\n",
    "    # var\n",
    "    '''PAYMENT:\n",
    "        JSON. Example: [{\"mode\":\"CC\",\"type\":\"CCXX\",\"amount\":0.00,\"accountNumber\":\"\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"CAD\"}]\n",
    "        mode: 1st field of the loop from 7th group (FPTP-FOP). Use only the first 2 chars\n",
    "        type: 1st field of the loop from 7th group (FPTP-FOP)\n",
    "        amount: 6th field of the loop from 7th group (FPAM-FOP)\n",
    "        accountNumber: 2nd field of the loop from 7th group (FPAC-FOP)\n",
    "        approvalCode: 5th field of the loop from 7th group (APLC-FOP)\n",
    "        invoiceNumber: <empty>\n",
    "        currency: same as CURRENCY_CODE\n",
    "\n",
    "        for EXCH, the PAYMENT will be like the example below:\n",
    "        Besides the regular FOP above, we need to add the EX info. Example: [{\"mode\":\"EX\",\"type\":\"EX\",\"amount\":0.00,\"accountNumber\":\"451123456789001\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"CAD\"},{\"mode\":\"CC\",\"type\":\"CCXX\",\"amount\":250.00,\"accountNumber\":\"\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"CAD\"}]\n",
    "        accountNumber: 1st field + 2nd field + 3rd field + 19th field from 10th group (NACN-EXC+ NDNR-EXC + NCDT-EXC + RCPU-EXC). Note: RCPU is char and needs to be converted as number (use the same logic as “coupons field” from refund_legs.\n",
    "        amount: 0.00'''\n",
    "\n",
    "    payment = None\n",
    "    if column_def != 'RFT':\n",
    "        payment = ''\n",
    "        currency = currency_code\n",
    "        for i in range(len(FOP_split)):\n",
    "            # split\n",
    "            FOP_element = FOP_split[i].split(\"\")\n",
    "            # print(FOP_element)\n",
    "            EXC1_element, EXC3_element = 'NULL', 'NULL'\n",
    "            if column_def == 'PAX':\n",
    "                EXC1_element = EXC1_split[0].split(\"\")\n",
    "                EXC3_element = EXC3_split[0].split(\"\")\n",
    "\n",
    "            # payment\n",
    "            # element\n",
    "            mode , type1, accountNumber = '', '', ''\n",
    "            accountNumber = ''\n",
    "            if column_def == 'PAT':\n",
    "                mode = FOP_element[0][:2]\n",
    "                type1 = FOP_element[0]\n",
    "                accountNumber = FOP_element[1]\n",
    "\n",
    "            if column_def == 'PAX':\n",
    "                mode = 'EX'\n",
    "                type1 = 'EX'\n",
    "                accountNumber = EXC1_element[0] + EXC1_element[1] + EXC1_element[2] + EXC3_element[0]\n",
    "                first_payment_accountNumber = accountNumber if i == 0\n",
    "\n",
    "            amount = FOP_element[5]\n",
    "            approvalCode = FOP_element[5]\n",
    "            invoiceNumber = ''\n",
    "\n",
    "            s = ',' if i != 0 else '['\n",
    "            payment = payment + s + '{' + f'\"mode\":\"{mode}\",\"type\":\"{type1}\",\"amount\":{amount},\"accountNumber\":\"{accountNumber}\",\"approvalCode\":\"{approvalCode}\",\"invoiceNumber\":\"{invoiceNumber}\",\"currency\":\"{currency}\"' +'}'\n",
    "\n",
    "        payment = payment + ']'\n",
    "\n",
    "    return [payment, first_payment_accountNumber]\n",
    "\n",
    "bos_df_csv = etl_fc(bos_df_csv, fc, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RFT\n",
      "PAX\n",
      "CACASHN 203.200.001.000.60N<CACASHN25.000.001.000.60E<\n",
      "['CA\\x80CASH\\x80N \\x80\\x80\\x80203.20\\x80\\x80\\x800.00\\x80\\x801.00\\x800.60\\x80N\\x80', 'CA\\x80CASH\\x80N\\x80\\x80\\x8025.00\\x80\\x80\\x800.00\\x80\\x801.00\\x800.60\\x80E\\x80']\n",
      "PAT\n",
      "CACASHN302.200.000.000.00N<\n",
      "['CA\\x80CASH\\x80N\\x80\\x80\\x80302.20\\x80\\x80\\x800.00\\x80\\x800.00\\x800.00\\x80N\\x80']\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(column_def='RFT', payment=None),\n Row(column_def='PAX', payment='[{\"mode\":\"EX\",\"type\":\"EX\",\"amount\":203.20,\"accountNumber\":\"00179767033390F\",\"approvalCode\":\"203.20\",\"invoiceNumber\":\"\",\"currency\":\"USD\"},{\"mode\":\"EX\",\"type\":\"EX\",\"amount\":25.00,\"accountNumber\":\"00179767033390F\",\"approvalCode\":\"25.00\",\"invoiceNumber\":\"\",\"currency\":\"USD\"}]'),\n Row(column_def='PAT', payment='[{\"mode\":\"CA\",\"type\":\"CA\",\"amount\":302.20,\"accountNumber\":\"CASH\",\"approvalCode\":\"302.20\",\"invoiceNumber\":\"\",\"currency\":\"USD\"}]')]"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv.select('column_def', 'payment').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "# RFT\n",
    "# RFT : [refund_legs]\n",
    "\n",
    "input  = ['column_def', 'RFT', 'ticket_number', 'first_payment_accountNumber']\n",
    "output = ['refund_legs', 'org_ticket_no']\n",
    "\n",
    "def fc(column_def, RFT, ticket_number, first_payment_accountNumber):\n",
    "\n",
    "    # split\n",
    "    if column_def == 'RFT':\n",
    "        # print(RFT)\n",
    "        RFT_split = RFT.split('')\n",
    "        # print(RFT_split)\n",
    "        RFT_split_1 = re.search('.+<',RFT).group().replace('','').replace('<','').split('<')\n",
    "        # print(RFT_split_1)\n",
    "        # loop RACN + RDNR + RCPN\n",
    "        RFT_split_2 = RFT_split[1] # ODOI\n",
    "        # print(RFT_split_1)\n",
    "        # print(RFT_split_2)\n",
    "\n",
    "    # var\n",
    "    # BRE\n",
    "    # refund_legs\n",
    "    '''REFUND_LEGS:\n",
    "        note: to be populated if ticket_type is RFND only\n",
    "        JSON. example: [{\"sequence\":1,\"ticketNumber\":\"0011259634355\",\"coupons\":\"1000\",\"issueDate\":\"2022-05-03\"}]\n",
    "        ticketNumber: 17th field + 18th fied from 2nd group (RACN-REF+ RDNR-REF). Note: it may have a loop here, so you need to use the sequence 1, sequence 2, etc in the JSON\n",
    "        issueDate: 20th fied from 2nd group (ODOI-REF).\n",
    "        coupons: 19th fied from 2nd group (RCPN-REF). Note: we receive this field as chars. You need to convert into numbers, use the same logic as CAT Loader (for example, the field comes as RR, you need to convert into “1200”. Or might come as VRRV, for example, you need to convert into “0230”. You need to apply the number/sequence only for the letter R; to the other letters (or blank) you need to put “0”)'''\n",
    "\n",
    "    # element\n",
    "    refund_legs = None\n",
    "    if column_def == 'RFT':\n",
    "        issueDate = RFT_split_2.split(\"\")[0]\n",
    "        for i in range(len(RFT_split_1)):\n",
    "            element = RFT_split_1[i].split(\"\")\n",
    "\n",
    "            # element\n",
    "            ticketNumber = element[0] + element[1]\n",
    "            coupons = element[2]\n",
    "            first_refund_legs_ticketNumber = ticketNumber if i == 0 else 'NULL'\n",
    "\n",
    "            # refund_legs\n",
    "            refund_legs = ''\n",
    "            s = ',' if i != 0 else '['\n",
    "            refund_legs = refund_legs + s + '{' + f'\"sequence\":{str(i+1)},\"ticketNumber\":\"{ticketNumber}\",\"coupons\":\"{coupons}\",\"issueDate\":\"{issueDate}\"' +'}'\n",
    "\n",
    "        refund_legs = refund_legs + ']'\n",
    "\n",
    "    # org_ticket_no\n",
    "    '''ORG_TICKET_NO:\n",
    "            TKTT → same as TICKET_NUMBER\n",
    "            EXCH → same as 1st accountNumber from PAYMENT (with mode = “EX” and only the first 13 chars only)\n",
    "            RFND → same as 1st ticketNumber from REFUND_LEGS'''\n",
    "    if column_def == 'PAT':\n",
    "        org_ticket_no = ticket_number\n",
    "    elif column_def == 'PAX':\n",
    "        org_ticket_no = first_payment_accountNumber\n",
    "    elif column_def == 'RFT':\n",
    "        org_ticket_no = first_refund_legs_ticketNumber\n",
    "    else:\n",
    "        org_ticket_no = 'NULL'\n",
    "\n",
    "\n",
    "    return [refund_legs, org_ticket_no]\n",
    "\n",
    "bos_df_csv2 = etl_fc(bos_df_csv, fc, input, output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "ename": "error",
     "evalue": "multiple repeat at position 19",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[117], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEX\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEX\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamount\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:203.20,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccountNumber\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m00179767033390F\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapprovalCode\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m203.20\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minvoiceNumber\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcurrency\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSD\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m},\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEX\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEX\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamount\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:25.00,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccountNumber\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m00179767033390F\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapprovalCode\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m25.00\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minvoiceNumber\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcurrency\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSD\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m}]\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 3\u001B[0m \u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfindall\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maccountNumber\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m:\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.+\u001B[39;49m\u001B[38;5;132;43;01m{15}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/pyspark/lib/python3.8/re.py:241\u001B[0m, in \u001B[0;36mfindall\u001B[0;34m(pattern, string, flags)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfindall\u001B[39m(pattern, string, flags\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m    234\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001B[39;00m\n\u001B[1;32m    235\u001B[0m \n\u001B[1;32m    236\u001B[0m \u001B[38;5;124;03m    If one or more capturing groups are present in the pattern, return\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    239\u001B[0m \n\u001B[1;32m    240\u001B[0m \u001B[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_compile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpattern\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mfindall(string)\n",
      "File \u001B[0;32m~/anaconda3/envs/pyspark/lib/python3.8/re.py:304\u001B[0m, in \u001B[0;36m_compile\u001B[0;34m(pattern, flags)\u001B[0m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m sre_compile\u001B[38;5;241m.\u001B[39misstring(pattern):\n\u001B[1;32m    303\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfirst argument must be string or compiled pattern\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 304\u001B[0m p \u001B[38;5;241m=\u001B[39m \u001B[43msre_compile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpattern\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (flags \u001B[38;5;241m&\u001B[39m DEBUG):\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(_cache) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m _MAXCACHE:\n\u001B[1;32m    307\u001B[0m         \u001B[38;5;66;03m# Drop the oldest item\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/pyspark/lib/python3.8/sre_compile.py:764\u001B[0m, in \u001B[0;36mcompile\u001B[0;34m(p, flags)\u001B[0m\n\u001B[1;32m    762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m isstring(p):\n\u001B[1;32m    763\u001B[0m     pattern \u001B[38;5;241m=\u001B[39m p\n\u001B[0;32m--> 764\u001B[0m     p \u001B[38;5;241m=\u001B[39m \u001B[43msre_parse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    765\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    766\u001B[0m     pattern \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/pyspark/lib/python3.8/sre_parse.py:948\u001B[0m, in \u001B[0;36mparse\u001B[0;34m(str, flags, state)\u001B[0m\n\u001B[1;32m    945\u001B[0m state\u001B[38;5;241m.\u001B[39mstr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m\n\u001B[1;32m    947\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 948\u001B[0m     p \u001B[38;5;241m=\u001B[39m \u001B[43m_parse_sub\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m&\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mSRE_FLAG_VERBOSE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    949\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m Verbose:\n\u001B[1;32m    950\u001B[0m     \u001B[38;5;66;03m# the VERBOSE flag was switched on inside the pattern.  to be\u001B[39;00m\n\u001B[1;32m    951\u001B[0m     \u001B[38;5;66;03m# on the safe side, we'll parse the whole thing again...\u001B[39;00m\n\u001B[1;32m    952\u001B[0m     state \u001B[38;5;241m=\u001B[39m State()\n",
      "File \u001B[0;32m~/anaconda3/envs/pyspark/lib/python3.8/sre_parse.py:443\u001B[0m, in \u001B[0;36m_parse_sub\u001B[0;34m(source, state, verbose, nested)\u001B[0m\n\u001B[1;32m    441\u001B[0m start \u001B[38;5;241m=\u001B[39m source\u001B[38;5;241m.\u001B[39mtell()\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 443\u001B[0m     itemsappend(\u001B[43m_parse\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnested\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    444\u001B[0m \u001B[43m                       \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnested\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mitems\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    445\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m sourcematch(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    446\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/pyspark/lib/python3.8/sre_parse.py:671\u001B[0m, in \u001B[0;36m_parse\u001B[0;34m(source, state, verbose, nested, first)\u001B[0m\n\u001B[1;32m    668\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m source\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnothing to repeat\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    669\u001B[0m                        source\u001B[38;5;241m.\u001B[39mtell() \u001B[38;5;241m-\u001B[39m here \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlen\u001B[39m(this))\n\u001B[1;32m    670\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m item[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m _REPEATCODES:\n\u001B[0;32m--> 671\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m source\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiple repeat\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    672\u001B[0m                        source\u001B[38;5;241m.\u001B[39mtell() \u001B[38;5;241m-\u001B[39m here \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlen\u001B[39m(this))\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m item[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m SUBPATTERN:\n\u001B[1;32m    674\u001B[0m     group, add_flags, del_flags, p \u001B[38;5;241m=\u001B[39m item[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[0;31merror\u001B[0m: multiple repeat at position 19"
     ]
    }
   ],
   "source": [
    "s = '[{\"mode\":\"EX\",\"type\":\"EX\",\"amount\":203.20,\"accountNumber\":\"00179767033390F\",\"approvalCode\":\"203.20\",\"invoiceNumber\":\"\",\"currency\":\"USD\"},{\"mode\":\"EX\",\"type\":\"EX\",\"amount\":25.00,\"accountNumber\":\"00179767033390F\",\"approvalCode\":\"25.00\",\"invoiceNumber\":\"\",\"currency\":\"USD\"}]'\n",
    "\n",
    "re.findall(r'\"accountNumber\":\".+{15}\"',s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<953.650.000.00358.00595.650.000.000.000.0012521614548221234<REDACTED REF NAMEF-953.650.000.00-953.65CACASH<\n",
      "['<\\x80\\x80\\x80\\x80\\x80953.65\\x800.00\\x800.00\\x80358.00\\x80595.65\\x800.00\\x800.00\\x800.00\\x800.00\\x80\\x80\\x80\\x81125\\x802161454822\\x801234\\x80<', '\\x80REDACTED REF NAME\\x80F\\x80-953.65\\x800.00\\x800.00\\x80\\x80-953.65\\x80CA\\x80CASH\\x80<\\x83']\n",
      "['125\\x802161454822\\x801234\\x80']\n",
      "['125\\x802161454822\\x801234\\x80']\n",
      "REDACTED REF NAMEF-953.650.000.00-953.65CACASH<\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(column_def='RFT', refund_legs='[{\"sequence\":1,\"ticketNumber\":\"1252161454822\",\"coupons\":\"1234\",\"issueDate\":\"\"}]'),\n Row(column_def='PAX', refund_legs=None),\n Row(column_def='PAT', refund_legs=None)]"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv2.select('column_def','refund_legs').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s = '12521614548221234<'\n",
    "s.split('<')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# FTS - 2610  Commision: \"CAD\" - > \"USD\"\n",
    "# input: Dataframe\n",
    "# output: ['Transaction_Date','Source','Booking_channel','DCI_split','DCI','Agency_code',]\n",
    "\n",
    "def split_col(split_df_type):\n",
    "    data=split_df_type.withColumn(\"Transaction_Date\",current_timestamp()).withColumn(\"Source\",F.lit('BOS')).withColumn(\"Booking_channel\",F.lit('WEB')).withColumn(\"DCI_split\", F.split(\"DCI\", \"\")).withColumn(\"Agency_code\", F.element_at(\"DCI_split\", 2)).withColumn(\"Ticket_No\", concat(F.element_at(\"DCI_split\", 5),F.element_at(\"DCI_split\", 6))).withColumn(\"Issue_Date\", F.to_date(F.element_at(\"DCI_split\", 8),\"ddMMMyy\"))\\\n",
    "    .withColumn(\"SAL_split\", F.split(\"SAL\", \"\")).withColumn(\"PNR\", F.element_at(\"SAL_split\", 15)).withColumn(\"Tour_code\", F.regexp_replace(F.element_at(\"SAL_split\", 17),'','')).withColumn(\"Passenger\", F.element_at(\"SAL_split\", 16)).withColumn(\"Coupon_used\", F.element_at(\"SAL_split\", 7)).withColumn(\"Original_Fare\", F.element_at(\"SAL_split\", 9)).withColumn(\"Fare\", F.element_at(\"SAL_split\", 11)).withColumn(\"Org_currency\", F.element_at(\"SAL_split\", 10)).withColumn(\"Tax_Amt\", F.element_at(\"SAL_split\", 12)).withColumn(\"Total_amt\", F.element_at(\"SAL_split\", 8))\\\n",
    "    .withColumn(\"ITI_split\", F.split(\"ITI\", \"<\"))\\\n",
    "    .withColumn(\"Leg2\", F.element_at(\"ITI_split\", 13)).withColumn(\"Leg3\", F.element_at(\"ITI_split\", 22)).withColumn(\"Leg4\", F.element_at(\"ITI_split\", 31))\\\n",
    "    .withColumn(\"FOP_split\", F.split(\"FOP_T\", \"\"))\\\n",
    "    .withColumn(\"TAX_split\", F.split(\"tax\", \"<\"))\\\n",
    "    .withColumn(\"Commission\", concat(F.lit('[{\"type\":\"BASE\",\"amount\":'),F.element_at(\"SAL_split\", 13),f.lit(',\"currency\":\"USD\",\"commissionRate\":'),F.element_at(\"SAL_split\", 14),f.lit('}]')))\\\n",
    "    .withColumn(\"Fare_split\", F.split(\"FAR\", \"<\")).withColumn(\"FOP_split\", F.split(\"FOP_T\", \"<\")).withColumn(\"SAL2_split\", F.split(\"TAX2\", \"\")).withColumn(\"Passenger_rfnd\", F.element_at(\"SAL2_split\", 2))\n",
    "\n",
    "    return data\n",
    "\n",
    "bos_df = split_col(split_df_type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # df2.write.options\n",
    "# split_df_type.coalesce(1).write.format('csv').option('header','true').mode(\"overwrite\").save(\"s3://bos-etl/write_back/\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "### FTS - 2607\n",
    "bos_df_csv=bos_df.selectExpr(\"ITI_split\",\"column_def\",\"Transaction_Date\",\"Agency_code\",\"'06.07_DCALLRECORDSAM' as Filename\",\"Source\",\"Booking_channel\",\"case when column_def=='PAX' then 'EXCH-TKTT' when column_def=='PAT' then 'TKTT' else 'RFND' end as ticket_type\", \"1 as version_no\",\"Ticket_No\",\"Issue_date\",\"PNR\",\"Tour_code\",\"case when column_def=='RFT' then passenger_rfnd else Passenger end as Passenger_name\",\"1 as Passenger_Count\",\"Coupon_used\",\"'USA' AS Country_code\",\"Original_Fare\",\"case when Fare==0 then original_fare else fare end as Fare_amt\",\"Org_currency\",\"round((case when Fare==0 then original_fare else fare end)/Original_Fare,3) as exch_rate\",\"case when Fare==0 then original_fare else fare end as comm_amt\",\"Tax_Amt\",\"Total_amt\",\"'USD' as curr_code\",\"ticket_no as org_ticket_no\",\"Commission\",\"TAX_split\",\"FOP_split\",\"Fare_split\",\"file_path\",\"REF_LG\",\"SAL2_split\",\"EXC_T\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(column_def='RFT', DCI='RFT\\x8022521623\\x8020230618\\x8023061805093326\\x80125\\x802161454822\\x804\\x8017JUN23\\x80\\x80IAR\\x80BA/D/ALLRECORDS/18JUN23\\x80103\\x80', SAL='\\x80\\x80\\x80\\x80\\x80953.65\\x800.00\\x800.00\\x80358.00\\x80595.65\\x800.00\\x800.00\\x800.00\\x800.00\\x80\\x80\\x80\\x81125\\x802161454822\\x801234\\x80', TAX=None, ITI=None, FAR=None, FOP_T=None, END_T=None, CER_T=None, EXC_T=None, EXS_T=None, file_path='data/date=2023-06-17/DCALLRECORDSAM.pgp.asc_3e5155823ea22a963da362086c693cf3_cleansed', TAX2='\\x80REDACTED REF NAME\\x80F\\x80-953.65\\x800.00\\x800.00\\x80\\x80-953.65\\x80CA\\x80CASH\\x80<\\x83', REF_LG='125\\x802161454822\\x801234\\x80<\\x82\\x80REDACTED REF NAME\\x80F\\x80-953.65\\x800.00\\x800.00\\x80\\x80-953.65\\x80CA\\x80CASH\\x80<\\x83', Transaction_Date=datetime.datetime(2023, 7, 28, 16, 37, 42, 198614), Source='BOS', Booking_channel='WEB', DCI_split=['RFT', '22521623', '20230618', '23061805093326', '125', '2161454822', '4', '17JUN23', '', 'IAR', 'BA/D/ALLRECORDS/18JUN23', '103', ''], Agency_code='22521623', Ticket_No='1252161454822', Issue_Date=datetime.date(2023, 6, 17), SAL_split=['', '', '', '', '', '953.65', '0.00', '0.00', '358.00', '595.65', '0.00', '0.00', '0.00', '0.00', '', '', '\\x81125', '2161454822', '1234', ''], PNR='', Tour_code='125', Passenger='', Coupon_used='0.00', Original_Fare='358.00', Fare='0.00', Org_currency='595.65', Tax_Amt='0.00', Total_amt='0.00', ITI_split=None, Leg2=None, Leg3=None, Leg4=None, FOP_split=None, TAX_split=None, Commission='[{\"type\":\"BASE\",\"amount\":0.00,\"currency\":\"USD\",\"commissionRate\":0.00}]', Fare_split=None, SAL2_split=['', 'REDACTED REF NAME', 'F', '-953.65', '0.00', '0.00', '', '-953.65', 'CA', 'CASH', '<\\x83'], Passenger_rfnd='REDACTED REF NAME')]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df.head(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# BOS - 116 RFT\n",
    "def fc_Ref(Fare_amt, column_def, Original_Fare, Tax_Amt, Org_currency,Total_amt):\n",
    "    if column_def == 'RFT':\n",
    "        #RFT fare_amount commission_amount: 9th field from REF * (-1)\n",
    "        Fare_amt = float(Original_Fare) * -1\n",
    "\n",
    "        #RFT tax_amount: 10th field from REF * (-1)\n",
    "        Tax_Amt = float(Org_currency) * -1\n",
    "\n",
    "        #RFT total_amount: 8th field from REF * (-1)\n",
    "        Total_amt = float(Total_amt) * -1\n",
    "\n",
    "    return [Fare_amt, Tax_Amt, Total_amt]\n",
    "\n",
    "fc_Ref = udf(fc_Ref, ArrayType(StringType()))\n",
    "fc_Ref_list = fc_Ref('Fare_amt', 'column_def', 'Original_Fare','Tax_Amt','Org_currency','Total_amt')\n",
    "bos_df_csv = bos_df_csv.withColumn('Fare_amt', fc_Ref_list[0])\\\n",
    "                        .withColumn('Tax_Amt', fc_Ref_list[1])\\\n",
    "                        .withColumn('Total_amt', fc_Ref_list[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+---------+\n",
      "|Fare_amt|Tax_Amt|Total_amt|\n",
      "+--------+-------+---------+\n",
      "|  -358.0|-595.65|     -0.0|\n",
      "|  166.51|  36.69|   203.20|\n",
      "|  213.00|  89.20|   302.20|\n",
      "+--------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bos_df_csv.select('Fare_amt', 'Tax_Amt', 'Total_amt').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# FTS - 2609\n",
    "def fc_Fare(li, column_def):\n",
    "    fare_v = ''\n",
    "    fare = ''\n",
    "    fare_end_v = ''\n",
    "    if column_def != 'RFT':\n",
    "        fare_v = ''\n",
    "        if li is not None:\n",
    "            # FTS - 2609\n",
    "            fare_end_v = ''\n",
    "            fare_v = '['\n",
    "            i = 0\n",
    "            # print (fare_v)\n",
    "            for ii in li:\n",
    "                i = i + 1\n",
    "                ii_split = ii.split(\"\")\n",
    "\n",
    "                if i > 1:\n",
    "                    fare_v = fare_v + ',{\"sequence\":' + str(i) + ',\"content\":\"' + ii_split[0] + '\"}'\n",
    "                    fare = fare + ',' + ii_split[0]\n",
    "                else:\n",
    "                    fare_v = fare_v + '{\"sequence\":' + str(i) + ',\"content\":\"' + ii_split[0] + '\"}'\n",
    "                    fare = ii_split[0]\n",
    "            fare_v = fare_v + ']'\n",
    "        # FTS - 2609 spilt by \"END\" + \" \"\n",
    "        # fare_split = fare.split(\" \")\n",
    "        fare_split = fare.split(\"END\" + \" \")[0].split(\" \")\n",
    "        # print(fare_split)\n",
    "\n",
    "        for element in fare_split:\n",
    "            # FTS - 2609 add ~(element.startswith(\"Q\") & element[1].isdigit())\n",
    "            # if element.endswith(\"END\"):\n",
    "            if len(element) > 1:\n",
    "                if (False if (element.startswith(\"Q\") & element[1].isdigit()) else True):\n",
    "                    # FTS - 2609 list -> str\n",
    "                    fare_end_v = fare_end_v + element\n",
    "\n",
    "    return [fare_v, fare, fare_end_v]\n",
    "\n",
    "fc_Fare = udf(fc_Fare, ArrayType(StringType()))\n",
    "fc_Fare_list = fc_Fare('Fare_split', 'column_def')\n",
    "bos_df_csv = bos_df_csv.withColumn('Fare_Cons', fc_Fare_list[0])\\\n",
    "    .withColumn(\"Fare\", fc_Fare_list[1]).withColumn(\"Fare_end\",fc_Fare_list[2]).withColumn(\"Fare_split\", F.split(\"Fare\", \" \"))\n"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|           Fare_Cons|            Fare_end|          Fare_split|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|                    |                    |                  []|\n",
      "|[{\"sequence\":1,\"c...|ORFAAX/WASAAGRR16...|[ORF, AA, X/WAS, ...|\n",
      "|[{\"sequence\":1,\"c...|AMSKLMAD119.12KLA...|[AMS, KL, MAD119....|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bos_df_csv.select('Fare_Cons', \"Fare_end\", \"Fare_split\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# FTS - 2607\n",
    "# tax\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "def fc(li, column_def):\n",
    "    tax_v = ''\n",
    "    if column_def != 'RFT':\n",
    "        tax_v =''\n",
    "        if li is not None:\n",
    "            #print(li)\n",
    "            tax_v ='['\n",
    "            i=0\n",
    "            for ii in li:\n",
    "                ii_split = ii.split(\",\")\n",
    "                # FTS 2607 Bug 2 & 3 : filter string which not start with digit\n",
    "                ii_split = [x for x in ii_split if x[0].isdigit()]\n",
    "                #print(ii_split)\n",
    "                for i1 in ii_split:\n",
    "                    i=i+1\n",
    "                    i1_split = i1.split(\"\")\n",
    "                    #print(i1_split)\n",
    "                    if i>1:\n",
    "                        # FTS-2607 Bug 1\n",
    "                        tax_v = tax_v+ ',{\"type\":\"'+ i1_split[1] +'\",\"amount\":'+i1_split[0] +',\"currency\":\"' +  \"Org_currency\" + '\"}'\n",
    "                    else:\n",
    "                        # FTS-2607 Bug 1\n",
    "                        tax_v = tax_v+ '{\"type\":\"'+ i1_split[1] +'\",\"amount\":'+i1_split[0] +',\"currency\":\"' +   \"Org_currency\" + '\"}'\n",
    "            tax_v=tax_v+']'\n",
    "    return tax_v\n",
    "\n",
    "fc = udf(fc, StringType())\n",
    "bos_df_csv = bos_df_csv.withColumn('Tax_v', fc('TAX_split', 'column_def'))\n",
    "bos_df_csv=bos_df_csv.selectExpr(\"ITI_split\",\"Fare_end\",\"column_def\",\"Transaction_Date\",\"Agency_code\",\"Filename\",\"Source\",\"Booking_channel\",\"ticket_type\", \"version_no\",\"Ticket_No\",\"Issue_date\",\"PNR\",\"Tour_code\",\"Passenger_name\",\"Passenger_Count\",\"Coupon_used\",\"Country_code\",\"Original_Fare\",\"Fare_amt\",\"Org_currency\",\"exch_rate\",\"comm_amt\",\"Tax_Amt\",\"Total_amt\",\"curr_code\",\"org_ticket_no\",\"Commission\",\"Fare_Cons\",\"case when column_def !='RFT' then replace(Tax_v,'Org_currency',Org_currency) end as Tax\",'FOP_split',\"file_path\",\"REF_LG\",\"SAL2_split\",\"EXC_T\")"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# FTS - 2606\n",
    "# PAT - FOP : payment\n",
    "# PAX - EXC : payment\n",
    "def fc_FOP(FOP_split, column_def):\n",
    "    fop_v =''\n",
    "    if column_def == 'PAT' :\n",
    "        if FOP_split is not None:\n",
    "            fop_v =''\n",
    "            i=0\n",
    "            for ii in FOP_split:\n",
    "                ii_split = ii.split(\",\")\n",
    "                for i1 in ii_split:\n",
    "                    i1_split = i1.split(\"\") #FOP\n",
    "                    mode = i1_split[0][:2] # 1st field of the loop from 7th group (FPTP-FOP). Use only the first 2 chars\n",
    "                    type1 = i1_split[0] # 1st field of the loop from 7th group (FPTP-FOP)\n",
    "                    amount = i1_split[5] # 6th field of the loop from 7th group (FPAM-FOP)\n",
    "                    accountNumber = i1_split[1] # 2nd field of the loop from 7th group (FPAC-FOP)\n",
    "                    approvalCode = i1_split[4] # 5th field of the loop from 7th group (APLC-FOP)\n",
    "                    invoiceNumber = '' # <empty>\n",
    "                    currency = \"USD\" # same as CURRENCY_CODE “USD”\n",
    "\n",
    "                    s = ',' if i != 0 else '['\n",
    "                    fop_v = fop_v + s + '{'  + f'\"mode\":\"{mode}\",\"type\":\"{type1}\",\"amount\":{amount},\"accountNumber\":\"{accountNumber}\",\"approvalCode\":\"{approvalCode}\",\"invoiceNumber\":\"{invoiceNumber}\",\"currency\":\"{currency}\"' + '}'\n",
    "\n",
    "                    i=i+1\n",
    "\n",
    "            fop_v = fop_v+']'\n",
    "\n",
    "    return [fop_v]\n",
    "\n",
    "fc_FOP = udf(fc_FOP, ArrayType(StringType()))\n",
    "fc_FOP_list = fc_FOP('FOP_split', \"column_def\")\n",
    "bos_df_csv2 = bos_df_csv.withColumn('FOP', fc_FOP_list[0])\n",
    "bos_df_csv2=bos_df_csv2.selectExpr(\"ITI_split\",\"Fare_end\",\"column_def\",\"Transaction_Date\",\"Agency_code\",\"Filename\",\"Source\",\"Booking_channel\",\"ticket_type\", \"version_no\",\"Ticket_No\",\"Issue_date\",\"PNR\",\"Tour_code\",\"Passenger_name\",\"Passenger_Count\",\"Coupon_used\",\"Country_code\",\"Original_Fare\",\"Fare_amt\",\"Org_currency\",\"exch_rate\",\"comm_amt\",\"Tax_Amt\",\"Total_amt\",\"curr_code\",\"org_ticket_no\",\"Commission\",\"Fare_Cons\",\"Tax\",\"FOP\",\"file_path\",\"REF_LG\",\"SAL2_split\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(Fop='', column_def='RFT'),\n Row(Fop='', column_def='PAX'),\n Row(Fop='[{\"mode\":\"CA\",\"type\":\"CA\",\"amount\":302.20,\"accountNumber\":\"CASH\",\"approvalCode\":\"\",\"invoiceNumber\":\"\",\"currency\":\"USD\"}]', column_def='PAT')]"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv2.select('Fop','column_def').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "# FTS - 2608 rewrtie function\n",
    "# FTS - 2608 \"currency\": \"CAD\" -> \"currency\": \"USD\"\n",
    "def fc_LEG(li, fare_row, ticket_no, issue_date, column_def):\n",
    "    leg_v =''\n",
    "    attributes = ''\n",
    "    if column_def != 'RFT':\n",
    "        if re.match(r'^\\d{4}-\\d{2}-\\d{2}$',str(issue_date)):\n",
    "            issue_year = issue_date.year\n",
    "            issue_date = issue_date.strftime('%Y-%m-%d')\n",
    "            leap_year = '2024' # not use this value just avoid error from strptime\n",
    "            if li is not None:\n",
    "                #print(li)\n",
    "                leg_v ='[' # segment 1\n",
    "                leg_v_1 = '[' #segment 2\n",
    "                # i=0\n",
    "                # FTS - 2608\n",
    "                i = 0\n",
    "                j = 1 # index of fare , max len 2\n",
    "                fareval = []\n",
    "                if (len(li) > 1): # if two segment, reverse, direction right to left\n",
    "                    li.reverse()\n",
    "                    i = 3\n",
    "                for ii in li:\n",
    "                    ii_split = ii.split(\",\")\n",
    "                    #print(ii_split)\n",
    "                    for i1 in ii_split:\n",
    "                        fareval = re.findall(r'\\d+.\\d+', str(fare_row))\n",
    "                        if len(fareval)==0:\n",
    "                            total_fareval = '0.00'\n",
    "                            fareval=['0.00','0.00','0.00','0.00']\n",
    "                        else:\n",
    "                            total_fareval = fareval[-1]\n",
    "                            fareval = fareval[:-1]\n",
    "                        #print(fareval)\n",
    "                        i = i - 1 # reverse\n",
    "                        i1_split = i1.split(\"\")\n",
    "                        if len(i1_split[0])!=0:\n",
    "                            conj= ticket_no[0:3] + i1_split[0]\n",
    "                        else:\n",
    "                            conj='CONJ'\n",
    "\n",
    "                        if i>1:\n",
    "                           if len(i1_split[30])!=0:\n",
    "                                if len(i1_split[35])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[35] +  leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(   issue_year)    + 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[35]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[29]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "                                leg_v_1 = ',{\"departure\":\"'+ i1_split[30] +'\",\"destination\":\"'+i1_split[31]         +'\",\"seatClass\":\"' +  i1_split[34] +'\",\"conjunction\":\"'+  conj      +'\",\"carrier\":\"'+i1_split[32]+'\",\"tripCode\":\"'+i1_split[    33]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[   37]+'\",\"stopOver\":\"'+i1_split[   29]+'\",\"flyerCode\":\"\",\"fare\":'+ fare +    ',\"currency\": \"USD\",\"originalFare\":'+ fare     +',\"originalCurrency\":\"'+'org_currency'+'\"}'\n",
    "\n",
    "                           if len(i1_split[21])!=0:\n",
    "                                if len(i1_split[26])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[26] +  leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(   issue_year)    + 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[26]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[20]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "                                leg_v_1 = '' if leg_v_1 == '[' else leg_v_1\n",
    "                                leg_v_1 = ',{\"departure\":\"'+ i1_split[21] +'\",\"destination\":\"'+i1_split[22]         +'\",\"seatClass\":\"' + i1_split[25] +'\",\"conjunction\":\"'+  conj       +'\",\"carrier\":\"'+i1_split[23]+'\",\"tripCode\":\"'+i1_split[    24]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[  28]+'\",\"stopOver\":\"'+i1_split[    20]+'\",\"flyerCode\":\"\",\"fare\":'+ fare    +',\"currency\": \"USD\",\"originalFare\":'+ fare        +',\"originalCurrency\":\"'+'org_currency'+'\"}' + leg_v_1\n",
    "\n",
    "                           if len(i1_split[12])!=0:\n",
    "                                if len(i1_split[17])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[17] +  leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(   issue_year)    + 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[17]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[11]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "                                leg_v_1 = '' if leg_v_1 == '[' else leg_v_1\n",
    "                                leg_v_1 = ',{\"departure\":\"'+ i1_split[12] +'\",\"destination\":\"'+i1_split[13]         +'\",\"seatClass\":\"' + i1_split[16] +'\",\"conjunction\":\"'+  conj       +'\",\"carrier\":\"'+i1_split[14]+'\",\"tripCode\":\"'+i1_split[    15]+'\",\"departureOn\":\"'+ dep_on+'\",\"designator\":\"'+i1_split[  19]+'\",\"stopOver\":\"'+i1_split[    11]+'\",\"flyerCode\":\"\",\"fare\":'+ fare    +',\"currency\": \"USD\",\"originalFare\":'+ fare        +',\"originalCurrency\":\"'+'org_currency'+'\"}' + leg_v_1\n",
    "\n",
    "                           if len(i1_split[3])!=0:\n",
    "                                if len(i1_split[8])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[8] +   leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(   issue_year)    + 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[8]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[2]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "\n",
    "                                leg_v_1 = '' if leg_v_1 == '[' else leg_v_1\n",
    "                                leg_v_1 = ',{\"departure\":\"'+ i1_split[3] +'\",\"destination\":\"'+i1_split[4]       +'\",\"seatClass\":\"' + i1_split[7] +'\",\"conjunction\":\"'+  conj    +'\",\"carrier\":\"'+i1_split[5]+'\",\"tripCode\":\"'+i1_split[6]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[  10]+'\",\"stopOver\":\"'+i1_split[ 2]+'\",\"flyerCode\":\"\",\"fare\":'+ fare +',\"currency\":     \"USD\",\"originalFare\":'+ fare  +',\"originalCurrency\":\"'+'org_currency'+'\"}' +    leg_v_1\n",
    "\n",
    "                        else:\n",
    "                            if len(i1_split[30])!=0:\n",
    "                                if len(i1_split[35])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[35] +  leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(issue_year)+ 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[35]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[29]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "\n",
    "                                leg_v = ',{\"departure\":\"'+ i1_split[30] +'\",\"destination\":\"'+i1_split[31]       +'\",\"seatClass\":\"' + i1_split[34] +'\",\"conjunction\":\"'+  conj       +'\",\"carrier\":\"'+i1_split[32]+'\",\"tripCode\":\"'+i1_split[33]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[  37]+'\",\"stopOver\":\"'+i1_split[  29]+'\",\"flyerCode\":\"\",\"fare\":'+ fare +    ',\"currency\": \"USD\",\"originalFare\":'+ fare         +',\"originalCurrency\":\"'+'org_currency'+'\"}'\n",
    "\n",
    "                            if len(i1_split[21])!=0:\n",
    "                                if len(i1_split[26])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[26] +  leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(issue_year)    + 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[26]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[20]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "                                leg_v = '' if leg_v == '[' else leg_v\n",
    "                                leg_v =  ',{\"departure\":\"'+ i1_split[21] +'\",\"destination\":\"'+i1_split[22]      +'\",\"seatClass\":\"' + i1_split[25] +'\",\"conjunction\":\"'+  conj       +'\",\"carrier\":\"'+i1_split[23]+'\",\"tripCode\":\"'+i1_split[24]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[    28]+'\",\"stopOver\":\"'+i1_split[ 20]+'\",\"flyerCode\":\"\",\"fare\":'+ fare     +',\"currency\": \"USD\",\"originalFare\":'+ fare         +',\"originalCurrency\":\"'+'org_currency'+'\"}' + leg_v\n",
    "\n",
    "                            if len(i1_split[12])!=0:\n",
    "                                if len(i1_split[17])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[17] +  leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(issue_year)+ 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[17]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[11]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "                                leg_v = '' if leg_v == '[' else leg_v\n",
    "                                leg_v =   ',{\"departure\":\"'+ i1_split[12] +'\",\"destination\":\"'+i1_split[13]         +'\",\"seatClass\":\"' + i1_split[16] +'\",\"conjunction\":\"'+  conj       +'\",\"carrier\":\"'+i1_split[14]+'\",\"tripCode\":\"'+i1_split[    15]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[  19]+'\",\"stopOver\":\"'+i1_split[    11]+'\",\"flyerCode\":\"\",\"fare\":'+ fare    +',\"currency\": \"USD\",\"originalFare\":'+ fare        +',\"originalCurrency\":\"'+'org_currency'+'\"}' + leg_v\n",
    "\n",
    "                            if len(i1_split[3])!=0:\n",
    "                                #print(conj)\n",
    "                                if len(i1_split[8])!=0:\n",
    "                                    dep_day = datetime.strptime(i1_split[8] +   leap_year,'%d%b%Y').strftime(\"%m-%d\")\n",
    "                                    dep_year = str(issue_year) if dep_day >= issue_date[5:] else str(int(   issue_year)    + 1)\n",
    "                                    dep_on = str(pd.datetime.strptime(i1_split[8]+ dep_year,'%d%b%Y'))[0:10]\n",
    "                                else:\n",
    "                                    dep_on= 'NULL'\n",
    "                                if i1_split[2]=='X':\n",
    "                                    fare = str('0.00')\n",
    "                                else:\n",
    "                                    if (len(fareval) == 0):\n",
    "                                        fare ='NULL'\n",
    "                                    elif (j <= len(fareval)):\n",
    "                                        fare = fareval[-j]\n",
    "                                        j = j + 1\n",
    "                                    else:\n",
    "                                        fare = 'NULL'\n",
    "                                        j = j + 1\n",
    "                                leg_v = '' if leg_v == '[' else leg_v\n",
    "                                leg_v = '[{\"departure\":\"'+ i1_split[3] +'\",\"destination\":\"'+i1_split[4]         +'\",\"seatClass\":\"' + i1_split[7] +'\",\"conjunction\":\"'+conj+'\",\"carrier\":\"'+i1_split[5]+'\",\"tripCode\":\"'+i1_split[6]+'\",\"departureOn\":\"'+dep_on+'\",\"designator\":\"'+i1_split[  10]+'\",\"stopOver\":\"'+i1_split[   2]+'\",\"flyerCode\":\"\",\"fare\":'+ fare  +',\"currency\": \"USD\",\"originalFare\":'+ fare      +',\"originalCurrency\":\"'+'org_currency'+'\"}' + leg_v\n",
    "\n",
    "                            # segment 1 + segment2\n",
    "                            leg_v_1 = '' if leg_v_1 == '[' else leg_v_1\n",
    "                            leg_v = leg_v + leg_v_1\n",
    "                        #print(pd.datetime.strptime(i1_split[8]+ str(datetime.now().year),'%d%b%Y'))\n",
    "                leg_v=leg_v+']'\n",
    "\n",
    "                # attributes: len(leg) > len(fare)\n",
    "                attributes = '' if j == len(fareval) + 1 else ' # ' + 'FareLegMismatch: leg: ' + str(j-1) +  ' does not match fare: ' + str(len(fareval)) + ' # '\n",
    "\n",
    "                # atributes: total_fareval <> leg: fareval\n",
    "                leg_fer_sum = '%.2f'%sum([float(x[7:]) for x in re.findall(r'\\\"fare\\\"\\:\\d+\\.\\d+', leg_v)])\n",
    "                attributes = attributes if total_fareval == leg_fer_sum else '#' + 'FareAmountMismatch: Leg sum amount: ' + str(leg_fer_sum) + ' does not match fare amount: ' + str(total_fareval)  + ' # '\n",
    "\n",
    "        else:\n",
    "            # issue_date is not datatime\n",
    "            attributes = attributes + '#' + 'Issue_dateNotDatetime: issue_date: ' +  str(issue_date)  + ' # '\n",
    "\n",
    "    return [leg_v, attributes]\n",
    "\n",
    "fc_LEG = udf(fc_LEG, ArrayType(StringType()))\n",
    "fc_LEG_list = fc_LEG('ITI_split','Fare_end','Ticket_no','Issue_date','column_def')\n",
    "bos_df_csv = bos_df_csv.withColumn('Leg_v1', fc_LEG_list[0]).withColumn('attributes', fc_LEG_list[1])\n",
    "bos_df_csv=bos_df_csv.selectExpr(\"FOP\",\"column_def\",\"Transaction_Date\",\"Agency_code\",\"Filename\",\"Source\",\"Booking_channel\",\"ticket_type\", \"version_no\",\"Ticket_No\",\"Issue_date\",\"PNR\",\"Tour_code\",\"Passenger_name\",\"Passenger_Count\",\"Coupon_used\",\"Country_code\",\"Original_Fare\",\"Fare_amt\",\"Org_currency\",\"exch_rate\",\"comm_amt\",\"Tax_Amt\",\"Total_amt\",\"curr_code\",\"org_ticket_no\",\"Commission\",\"Fare_Cons\",\"Tax\",\"case when column_def !='RFT' then replace(replace(Leg_v1,'CONJ',Ticket_no),'org_currency',Org_currency) end as Legs\",\"attributes\",\"file_path\",\"REF_LG\",\"SAL2_split\")"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 86,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|Legs|\n",
      "+----+\n",
      "|null|\n",
      "+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bos_df_csv.select('Legs').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "bos_df_csv2 = bos_df_csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# Refund_Legs\n",
    "# ONLY for RFT\n",
    "def fc_refund_legs (REF_LG, column_def,SAL2_split, org_ticket_no, Coupon_used):\n",
    "    refund_legs = ''\n",
    "    if column_def == 'RFT':\n",
    "        REF_LG_split = REF_LG.split('')[0].split('<')[:-1]\n",
    "        org_date = SAL2_split[0]\n",
    "        i = 1 # flag if it is the first & sequence\n",
    "        for lg_split in REF_LG_split:\n",
    "            s = ',' if i != 0 else '['\n",
    "            lg_split_split = lg_split.split('')\n",
    "            ticketNumber = lg_split_split[0] + lg_split_split[1]\n",
    "            coupons = lg_split_split[2]\n",
    "            issueDate = org_date\n",
    "            refund_legs = refund_legs + s + '{' + f'\"sequence\":{i},\"ticketNumber\":\"{ticketNumber}\",\"coupons\":\"{coupons}\",\"issueDate\":\"{issueDate}\"' + '}'\n",
    "\n",
    "            # RFT ORG_TICKET_NO\n",
    "            # RFT Coupon_used\n",
    "            if i == 1:\n",
    "                org_ticket_no = ticketNumber\n",
    "                Coupon_used = coupons\n",
    "\n",
    "            i = i + 1\n",
    "\n",
    "        refund_legs = refund_legs + ']'\n",
    "\n",
    "    return [refund_legs, org_ticket_no, Coupon_used]\n",
    "\n",
    "fc_fefund_legs = udf(fc_refund_legs, ArrayType(StringType()))\n",
    "fc_fefund_legs_list = fc_fefund_legs(\"REF_LG\",\"column_def\",\"SAL2_split\",\"org_ticket_no\",\"Coupon_used\")\n",
    "bos_df_csv = bos_df_csv.withColumn('refund_legs', fc_fefund_legs_list[0])\\\n",
    "                         .withColumn('org_ticket_no', fc_fefund_legs_list[1])\\\n",
    "                         .withColumn('Coupon_used', fc_fefund_legs_list[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['', 'REDACTED REF NAME', 'F', '-953.65', '0.00', '0.00', '', '-953.65', 'CA', 'CASH', '<\\x83']\n",
      "['125', '2161454822', '1234', '']\n",
      "['', 'REDACTED REF NAME', 'F', '-953.65', '0.00', '0.00', '', '-953.65', 'CA', 'CASH', '<\\x83']\n",
      "['125', '2161454822', '1234', '']\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(refund_legs=',{\"sequence\":1,\"ticketNumber\":\"1252161454822\",\"coupons\":\"1234\",\"issueDate\":\"\"}]', org_ticket_no='1252161454822', Coupon_used='1234')]"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos_df_csv2.select('refund_legs','org_ticket_no','Coupon_used').head(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ticketNumber = 'ticketNumber'\n",
    "coupons = 'coupons'\n",
    "issueDate = 'issueDate'\n",
    "refund_legs = '[{' + f'\"sequence\":1,\"ticketNumber\":\"{ticketNumber}\",\"coupons\":\"{coupons}\",\"issueDate\":\"{issueDate}\"' + '}]'\n",
    "print(refund_legs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data Validation\n",
    "# def\n",
    "def check_float(data, msg, header, length, decimal = 0):\n",
    "    try:\n",
    "        data_1 = data\n",
    "        data = data if len(str(data).split('.')[0]) <= (length - decimal) else 'NULL'\n",
    "        msg = msg if str(data) == str(data_1) else msg + ' # ' + header + 'OutOfRange: ' + str(data_1) + 'is out of range of (' +  str(length) + ',' + str(decimal) + ') # '\n",
    "    except Exception as e:\n",
    "        data = 'NULL'\n",
    "        msg = msg + '# ERROR ' + str(e) + ' # '\n",
    "    return data, msg\n",
    "\n",
    "\n",
    "def fc_DV(attributes,original_fare, exchange_rate,fare_amount,tax_amount,total_amount):\n",
    "\n",
    "    # attributes\n",
    "    attributes = '' if attributes is None else attributes\n",
    "\n",
    "    # original_fare\n",
    "    # numeric(12, 5)\n",
    "    original_fare, attributes = check_float(data = original_fare, msg = attributes , header = 'original_fare', length = 12, decimal = 5)\n",
    "\n",
    "    # exchange_rate\n",
    "    # numeric(12, 5)\n",
    "    exchange_rate, attributes = check_float(data = exchange_rate, msg = attributes , header = 'exchange_rate', length = 12, decimal = 5)\n",
    "\n",
    "    # fare_amount\n",
    "    # numeric(12, 5)\n",
    "    fare_amount, attributes = check_float(data = fare_amount, msg = attributes , header = 'fare_amount', length = 12, decimal = 5)\n",
    "\n",
    "    # tax_amount\n",
    "    # numeric(12, 5)\n",
    "    tax_amount, attributes = check_float(data = tax_amount, msg = attributes , header = 'tax_amount', length = 12, decimal = 5)\n",
    "\n",
    "    # total_amount\n",
    "    # numeric(12, 5)\n",
    "    total_amount, attributes = check_float(data = total_amount, msg = attributes , header = 'total_amount', length = 12, decimal = 5)\n",
    "\n",
    "    return [attributes,original_fare,exchange_rate,fare_amount,tax_amount,total_amount]\n",
    "\n",
    "fc_DV = udf(fc_DV, ArrayType(StringType()))\n",
    "fc_DV_list = fc_DV('attributes', 'Original_Fare', 'exch_rate', 'Fare_amt', 'Tax_Amt', 'Total_amt')\n",
    "bos_df_csv = bos_df_csv\\\n",
    "    .withColumn('attributes', fc_DV_list[0])\\\n",
    "    .withColumn('Original_Fare', fc_DV_list[1])\\\n",
    "    .withColumn('exch_rate', fc_DV_list[2])\\\n",
    "    .withColumn('Fare_amt', fc_DV_list[3])\\\n",
    "    .withColumn('Tax_Amt', fc_DV_list[4])\\\n",
    "    .withColumn('Total_amt', fc_DV_list[5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def fc_DV_2(attributes, Agency_code,Source,ticket_type,Coupon_used):\n",
    "\n",
    "    # attributes\n",
    "    attributes = '' if attributes is None else attributes\n",
    "\n",
    "    # Agency_code\n",
    "    # numeric(10, 0)\n",
    "    Agency_code, attributes = check_float(data = Agency_code, msg = attributes , header = 'Agency_code', length = 10, decimal = 0)\n",
    "\n",
    "    # Source\n",
    "    # numeric(10, 0)\n",
    "    Source, attributes = check_float(data = Source, msg = attributes , header = 'Source', length = 10, decimal = 0)\n",
    "\n",
    "    # ticket_type\n",
    "    # numeric(10, 0)\n",
    "    ticket_type, attributes = check_float(data = ticket_type, msg = attributes , header = 'ticket_type', length = 10, decimal = 0)\n",
    "\n",
    "\n",
    "    # Coupon_used\n",
    "    # numeric(10, 0)\n",
    "    Coupon_used, attributes = check_float(data = Coupon_used, msg = attributes , header = 'Coupon_used', length = 10, decimal = 0)\n",
    "\n",
    "\n",
    "    return [attributes,Agency_code,Source,ticket_type,Coupon_used]\n",
    "\n",
    "fc_DV_2 = udf(fc_DV_2, ArrayType(StringType()))\n",
    "fc_DV_2_list = fc_DV_2('attributes', 'Agency_code','Source','ticket_type','Coupon_used')\n",
    "bos_df_csv = bos_df_csv\\\n",
    "    .withColumn('attributes', fc_DV_2_list[0])\\\n",
    "    .withColumn('Agency_code', fc_DV_2_list[1])\\\n",
    "    .withColumn('Source', fc_DV_2_list[2])\\\n",
    "    .withColumn('ticket_type', fc_DV_2_list[3])\\\n",
    "    .withColumn('Coupon_used', fc_DV_2_list[4])"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "sc = SparkContext.getOrCreate();\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "\n",
    "my_conn_options = {\n",
    "    \"dbtable\": \"flextravel.fx_trans_file\",\n",
    "    \"database\": \"fts_cp_uat\",\n",
    "    \"url\": \"jdbc:postgresql://flextravel-uat-serverless-pg.chzjoncadzav.ca-central-1.rds.amazonaws.com:5432/fts_cp_uat\",\n",
    "    \"customJdbcDriverS3Path\":\"s3://flex-data-uat-canda-central/DEV/postgresql-42.6.0.jar\",\n",
    "    \"customJdbcDriverClassName\":\"org.postgresql.Driver\",\n",
    "    \"user\":\"flexuatuser\",\n",
    "    \"password\":\"flexnewyearpwd@2022\"\n",
    "}\n",
    "\n",
    "my_conn_options1 = {\n",
    "    \"dbtable\": \"flextravel.general_info\",\n",
    "    \"database\": \"fts_cp_uat\",\n",
    "    \"url\": \"jdbc:postgresql://flextravel-uat-serverless-pg.chzjoncadzav.ca-central-1.rds.amazonaws.com:5432/fts_cp_uat\",\n",
    "    \"customJdbcDriverS3Path\":\"s3://flex-data-uat-canda-central/DEV/postgresql-42.6.0.jar\",\n",
    "    \"customJdbcDriverClassName\":\"org.postgresql.Driver\",\n",
    "    \"user\":\"flexuatuser\",\n",
    "    \"password\":\"flexnewyearpwd@2022\"\n",
    "}\n",
    "\n",
    "my_conn_options2 = {\n",
    "    \"dbtable\": \"public.fx_trans_bre_interim_bos_sprint2_test\",\n",
    "    \"database\": \"fts_cp_uat\",\n",
    "    \"url\": \"jdbc:postgresql://flextravel-uat-serverless-pg.chzjoncadzav.ca-central-1.rds.amazonaws.com:5432/fts_cp_uat\",\n",
    "    \"customJdbcDriverS3Path\":\"s3://flex-data-uat-canda-central/DEV/postgresql-42.6.0.jar\",\n",
    "    \"customJdbcDriverClassName\":\"org.postgresql.Driver\",\n",
    "    \"user\":\"flexuatuser\",\n",
    "    \"password\":\"flexnewyearpwd@2022\"\n",
    "}\n",
    "\n",
    "df = glueContext.create_dynamic_frame.from_options(\n",
    "    connection_type=\"postgresql\",\n",
    "    connection_options=my_conn_options,\n",
    "    transformation_ctx=\"df\",\n",
    ")\n",
    "\n",
    "df_GI = glueContext.create_dynamic_frame.from_options(\n",
    "    connection_type=\"postgresql\",\n",
    "    connection_options=my_conn_options1,\n",
    "    transformation_ctx=\"df\",\n",
    ")\n",
    "GI_df = df_GI.toDF().select(\"id\",\"tids_code\")  \n",
    "\n",
    "\n",
    "\n",
    "bos_df_csv=  bos_df_csv.withColumn( \"Orginal_currency\",F.when(length(col(\"Org_currency\"))>5,'').otherwise(bos_df_csv.Org_currency))\n",
    "\n",
    "\n",
    "bos_df_final = bos_df_csv.select(\"ticket_type\",\"org_ticket_no\",\"version_no\",\"Filename\",\"Transaction_Date\",\"Agency_code\",\"Source\",\"Booking_channel\",\"Ticket_No\",\"PNR\",\"Issue_date\",\"Tour_code\",\"Passenger_name\",\"Passenger_Count\",\"Coupon_used\",\"Country_code\",\"Legs\",\"Original_Fare\",\"Orginal_currency\",\"exch_rate\",\"Fare_amt\",\"Tax_Amt\",\"Total_amt\",\"curr_code\",\"FOP\",\"Tax\",\"Commission\",\"Fare_Cons\",\"attributes\",\"file_path\", \"refund_legs\")\n",
    "                                                           \n",
    "Bos_df_GI= bos_df_final.join(GI_df,\n",
    "               bos_df_csv.Agency_code == GI_df.tids_code, \n",
    "               \"left\")  \n",
    "\n",
    "\n",
    "Bos_df_GI=Bos_df_GI.withColumnRenamed(\"id\",\"agent_id\")\n",
    "\n",
    "#Bos_df_GI.show(2, truncate=False)\n",
    "\n",
    "# df1 = df.toDF().select(\"id\", \"supplier_id\",\"sup_srv_map_id\",\"file_name\").where(df[\"file_name\"] =='06.07_DCALLRECORDSAM')\n",
    "# #df2=df1.withColumnRenamed(\"sup_srv_map_id\",\"col0\").withColumnRenamed(\"file_name\",\"col1\")\n",
    "# # df1 = df.filter(f=lambda x: x[\"sup_srv_map_id\"] in [65])\n",
    "\n",
    "df1 = df.toDF()[\"id\", \"supplier_id\",\"sup_srv_map_id\",\"file_name\"]\n",
    "df1 = df1[df1[\"file_name\"] =='06.07_DCALLRECORDSAM']\n",
    "\n",
    "\n",
    "#df1.show()\n",
    "\n",
    "Bos_df_file= Bos_df_GI.join(df1,\n",
    "               bos_df_csv.Filename == df1.file_name, \n",
    "               \"left\")    \n",
    "\n",
    "# Bos_df_file.show()\n",
    "\n",
    "# FTS - 2598 [\"Tax_Amt\"].cast(IntegerType()) -> DoubleType, [\"Total_amt\"].cast(IntegerType()) -> DoubleType\n",
    "Bos_df_file= Bos_df_file.withColumn(\"Original_Fare\", Bos_df_file[\"Original_Fare\"].cast(DoubleType())).withColumn(\"Fare_amt\", Bos_df_file[\"Fare_amt\"].cast(DoubleType())).withColumn(\"Tax_Amt\", Bos_df_file[\"Tax_Amt\"].cast(DoubleType()))\\\n",
    "            .withColumn(\"Total_amt\", Bos_df_file[\"Total_amt\"].cast(DoubleType())) .withColumn(\"exch_rate\", Bos_df_file[\"exch_rate\"].cast(DoubleType()))\n",
    "\n",
    "Bos_df_file= Bos_df_file.withColumn(\"Commission_Amount\", Bos_df_file[\"Fare_amt\"].cast(DoubleType()))\n",
    "                        \n",
    "Bos_df_write = Bos_df_file.select(\"Transaction_Date\",\"Agency_code\",\"Source\",\"Booking_channel\",\"Ticket_No\",\"PNR\",\"Issue_date\",\"Tour_code\",\"Passenger_name\",\"Passenger_Count\",\"Coupon_used\",\"Country_code\",\"Legs\",\"Original_Fare\",\"Orginal_currency\",\"exch_rate\",\"Fare_amt\",\"Tax_Amt\",\"Total_amt\",\"curr_code\",\"FOP\",\"Tax\",\"Commission\",\"Fare_Cons\",\"agent_id\",\"id\",\"supplier_id\",\"sup_srv_map_id\",\"ticket_type\",\"version_no\",\"org_ticket_no\",\"Commission_Amount\",\"attributes\",\"file_path\", \"refund_legs\")\n",
    "\n",
    "\n",
    "Bos_df_write = Bos_df_write.withColumnRenamed(\"Transaction_Date\",\"transaction_date\").withColumnRenamed(\"Agency_code\",\"agency_code\").withColumnRenamed(\"Source\",\"source\").withColumnRenamed(\"id\",\"trans_file_id\")\\\n",
    "                .withColumnRenamed(\"Booking_channel\",\"booking_channel\").withColumnRenamed(\"Ticket_No\",\"ticket_number\").withColumnRenamed(\"PNR\",\"pnr\").withColumnRenamed(\"Issue_date\",\"issue_date\").withColumnRenamed(\"Tour_code\",\"tour_code\")\\\n",
    "                .withColumnRenamed(\"Passenger_name\",\"passenger_name\").withColumnRenamed(\"Passenger_Count\",\"passenger_count\").withColumnRenamed(\"Coupon_used\",\"coupon_used\").withColumnRenamed(\"Country_code\",\"country_code\")\\\n",
    "                .withColumnRenamed(\"Legs\",\"legs\").withColumnRenamed(\"Original_Fare\",\"original_fare\").withColumnRenamed(\"Orginal_currency\",\"original_currency\").withColumnRenamed(\"exch_rate\",\"exchange_rate\").withColumnRenamed(\"Fare_amt\",\"fare_amount\")\\\n",
    "                .withColumnRenamed(\"Commission_Amount\",\"commission_amount\").withColumnRenamed(\"Tax_Amt\",\"tax_amount\").withColumnRenamed(\"Total_amt\",\"total_amount\").withColumnRenamed(\"curr_code\",\"currency_code\").withColumnRenamed(\"FOP\",\"payment\")\\\n",
    "                .withColumnRenamed(\"Tax\",\"tax\") .withColumnRenamed(\"Commission\",\"commission\").withColumnRenamed(\"Fare_Cons\",\"fare_construction\").withColumnRenamed(\"file_path\",\"tax_on_commission\")\n"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "Bos_df_write_dyn=DynamicFrame.fromDF(Bos_df_write,glueContext,'Bos_df_write_dyn')\n",
    "\n",
    "df3=glueContext.write_dynamic_frame_from_options(\n",
    "    frame=Bos_df_write_dyn,\n",
    "    connection_type=\"postgresql\",\n",
    "    connection_options=my_conn_options2,\n",
    "    transformation_ctx=\"dynamic_frame\"\n",
    ")\n",
    "#df3.show()"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": "PythonException: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 211, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\n    for obj in iterator:\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 200, in _batched\n    for item in iterator:\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in mapper\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in <genexpr>\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 85, in <lambda>\n    return lambda *a: f(*a)\n  File \"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/util.py\", line 87, in wrapper\n    return f(*args, **kwargs)\n  File \"<stdin>\", line 30, in fc_Fare\nUnboundLocalError: local variable 'fare' referenced before assignment\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# # mini batch test\n",
    "# from pyspark.sql import SQLContext\n",
    "# sqlContest = SQLContext(sc)\n",
    "\n",
    "# i = 0\n",
    "# k = 19000\n",
    "# j = 100\n",
    "\n",
    "# while (i+j < k):\n",
    "#     print(i)\n",
    "\n",
    "#     try:\n",
    "#         pdk = Bos_df_write.toPandas()\n",
    "#         pd1 = pdk.loc[i:i+j][:].fillna(0)\n",
    "#         spark_df = sqlContest.createDataFrame(pd1)\n",
    "        \n",
    "#         Bos_df_write_dyn1=DynamicFrame.fromDF(spark_df,glueContext,'Bos_df_write_dyn')\n",
    "\n",
    "#         df3=glueContext.write_dynamic_frame_from_options(\n",
    "#             frame=Bos_df_write_dyn1,\n",
    "#             connection_type=\"postgresql\",\n",
    "#             connection_options=my_conn_options2,\n",
    "#             transformation_ctx=\"dynamic_frame\"\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#     finally:\n",
    "#         i = i + j\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.37.3 \nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::251954244960:role/aws-glue-role\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: 94e43814-4481-46a2-bd42-9a375b67a951\nJob Type: glueetl\nApplying the following default arguments:\n--glue_kernel_version 0.37.3\n--enable-glue-datacatalog true\nWaiting for session 94e43814-4481-46a2-bd42-9a375b67a951 to get into ready status...\nSession 94e43814-4481-46a2-bd42-9a375b67a951 has been created.\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(type(datetime.now()) == '<class \\'datetime.datetime\\'>')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(datetime.now(), datetime)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "issue_date = ''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[219], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43missue_date\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mIndexError\u001B[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "issue_date[5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}